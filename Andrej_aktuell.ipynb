{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries and Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import iqr\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFECV\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "import mord as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_predict, LeaveOneOut, train_test_split, KFold, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, log_loss, recall_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import graphviz\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "def confusion_matrix_report(y_true, y_pred):    \n",
    "    cm, labels = confusion_matrix(y_true, y_pred), unique_labels(y_true, y_pred)\n",
    "    column_width = max([len(str(x)) for x in labels] + [5])  # 5 is value length\n",
    "    report = \" \" * column_width + \" \" + \"{:_^{}}\".format(\"Prediction\", column_width * len(labels))+ \"\\n\"\n",
    "    report += \" \" * column_width + \" \".join([\"{:>{}}\".format(label, column_width) for label in labels]) + \"\\n\"\n",
    "    for i, label1 in enumerate(labels):\n",
    "        report += \"{:>{}}\".format(label1, column_width) + \" \".join([\"{:{}d}\".format(cm[i, j], column_width) for j in range(len(labels))]) + \"\\n\"\n",
    "    return report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "red = pd.read_csv(\"./data/winequality-red1.csv\")\n",
    "white = pd.read_csv(\"./data/winequality-white1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data = deepcopy(red)\n",
    "white_data = deepcopy(white)\n",
    "\n",
    "conditions_red = [(red_data['quality'] <= 5),\n",
    "              (red_data['quality'] >= 7)]\n",
    "conditions_white = [(white_data['quality'] <= 5),\n",
    "              (white_data['quality'] >= 7)]\n",
    "\n",
    "choices = ['1 - low', '3 - high']\n",
    "\n",
    "red_data['quality class'] = np.select(conditions_red, choices, default = '2 - middle')\n",
    "white_data['quality class'] = np.select(conditions_white, choices, default = '2 - middle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_data.pop(\"quality\")\n",
    "red_label = red_data.pop(\"quality class\")\n",
    "\n",
    "white_data.pop(\"quality\")\n",
    "white_label = white_data.pop(\"quality class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1599.000000\n",
       "mean        0.270976\n",
       "std         0.194801\n",
       "min         0.000000\n",
       "25%         0.090000\n",
       "50%         0.260000\n",
       "75%         0.420000\n",
       "max         1.000000\n",
       "Name: citric acid, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red[\"citric acid\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Removing outliers ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bayes = GaussianNB()\n",
    "\n",
    "prediction_bayes = cross_val_predict(model_bayes, red_data, red_label, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving Power of NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Transform data to get a normal distribution via logarithm ###\n",
    "\n",
    "red_data_log = np.log(red_data[[\"fixed acidity\", \"volatile acidity\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]])\n",
    "red_data_log[\"citric acid\"] = red_data[\"citric acid\"]\n",
    "\n",
    "prediction_bayes_log = cross_val_predict(model_bayes, red_data_log, red_label, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Remove highly correlated variables ###\n",
    "red_data_corrout = deepcopy(red_data)\n",
    "red_data_corrout.pop(\"free sulfur dioxide\") #Higly correlated with total sulfur dioxide, but little correlation with alcohol\n",
    "red_data_corrout.pop(\"pH\")\n",
    "#red_data_corrout.pop(\"density\") # Highly correlated with alcohol\n",
    "red_data_corrout.pop(\"citric acid\") # Highly correlated with fixed acidity, volatile acidity and pH, but little correlation with alcohol\n",
    "red_data_corrout.pop(\"fixed acidity\") # Highly correlated with density and citric acid, but little correlation with alcohol\n",
    "red_data_corrout.pop(\"residual sugar\")\n",
    "red_data_corrout.pop(\"chlorides\")\n",
    "#red_data_corrout.pop(\"total sulfur dioxide\")\n",
    "#red_data_corrout.pop(\"sulphates\")\n",
    "#red_data_corrout.pop(\"volatile acidity\")\n",
    "prediction_bayes_corrout = cross_val_predict(model_bayes, red_data_corrout, red_label, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic feature selection \n",
    "https://machinelearningmastery.com/feature-selection-machine-learning-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.69      0.73      0.71       744\n",
      " 2 - middle       0.53      0.51      0.52       638\n",
      "   3 - high       0.50      0.46      0.48       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Univariate selection ###\n",
    "\n",
    "selection = SelectKBest(score_func=chi2, k=5)\n",
    "fit = selection.fit(red_data, red_label)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "#print(fit.scores_)\n",
    "features = pd.DataFrame(fit.transform(red_data))\n",
    "# summarize selected features\n",
    "#print(features)\n",
    "prediction = cross_val_predict(model_bayes, features, red_label, cv=10)\n",
    "print(classification_report(red_label, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.61      0.74      0.67       744\n",
      " 2 - middle       0.49      0.42      0.45       638\n",
      "   3 - high       0.42      0.28      0.34       217\n",
      "\n",
      "avg / total       0.54      0.55      0.54      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "### Univariate selection + log ###\n",
    "\n",
    "selection = SelectKBest(score_func=chi2, k=5)\n",
    "fit = selection.fit(red_data, red_label)\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "#print(fit.scores_)\n",
    "features = pd.DataFrame(fit.transform(red_data))\n",
    "# summarize selected features\n",
    "#print(features)\n",
    "prediction = cross_val_predict(model_bayes, features, red_label, cv=10)\n",
    "print(classification_report(red_label, prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sns.heatmap(red_data_corrout.corr(),cmap='coolwarm',annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Combine logarithm and removal of correlated variables\n",
    "\n",
    "red_data_corrout_log = np.log(red_data_corrout[[\"volatile acidity\", \"residual sugar\", \"chlorides\", \"total sulfur dioxide\", \"pH\", \"sulphates\", \"alcohol\"]])\n",
    "\n",
    "prediction_bayes_corrout_log = cross_val_predict(model_bayes, red_data_corrout_log, red_label, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalisation ### \n",
    "red_data_normalised = pd.DataFrame(\n",
    "    preprocessing.MinMaxScaler().fit_transform(red_data),\n",
    "    columns=[\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"\n",
    "]\n",
    ")\n",
    "\n",
    "prediction_bayes_normalised = cross_val_predict(model_bayes, red_data_normalised, red_label, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Standardisation ###\n",
    "scaler = StandardScaler()  \n",
    "scaler.fit(red_data)\n",
    "\n",
    "red_data_standardised = pd.DataFrame(scaler.transform(red_data))  \n",
    "\n",
    "prediction_bayes_standardised = cross_val_predict(model_bayes, red_data_standardised, red_label, cv=10)\n",
    "#print(classification_report(red_label, prediction_bayes_standardised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PCA ###\n",
    "\n",
    "pca = PCA()\n",
    "red_data_pca = pca.fit_transform(red_data)\n",
    "\n",
    "prediction_bayes_pca = cross_val_predict(model_bayes, red_data_pca, red_label, cv=10)\n",
    "\n",
    "#print(classification_report(red_label, prediction_bayes_pca))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Box-Cox-Transformation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes (default):\n",
      "           __________Prediction__________\n",
      "             1 - low 2 - middle   3 - high\n",
      "   1 - low       515        202         27\n",
      "2 - middle       212        303        123\n",
      "  3 - high        12         85        120\n",
      "\n",
      "0.5866166353971232\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.70      0.69      0.69       744\n",
      " 2 - middle       0.51      0.47      0.49       638\n",
      "   3 - high       0.44      0.55      0.49       217\n",
      "\n",
      "avg / total       0.59      0.59      0.59      1599\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "Naive Bayes (logarithm):\n",
      "           __________Prediction__________\n",
      "             1 - low 2 - middle   3 - high\n",
      "   1 - low       587        130         27\n",
      "2 - middle       267        266        105\n",
      "  3 - high        21         75        121\n",
      "\n",
      "0.6091307066916823\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.67      0.79      0.73       744\n",
      " 2 - middle       0.56      0.42      0.48       638\n",
      "   3 - high       0.48      0.56      0.51       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "Naive Bayes (without highly correlated variables):\n",
      "           __________Prediction__________\n",
      "             1 - low 2 - middle   3 - high\n",
      "   1 - low       584        153          7\n",
      "2 - middle       238        345         55\n",
      "  3 - high        15        130         72\n",
      "\n",
      "0.6260162601626016\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.70      0.78      0.74       744\n",
      " 2 - middle       0.55      0.54      0.55       638\n",
      "   3 - high       0.54      0.33      0.41       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "Naive Bayes (without highly correlated variables and logarithm):\n",
      "           __________Prediction__________\n",
      "             1 - low 2 - middle   3 - high\n",
      "   1 - low       592        139         13\n",
      "2 - middle       244        322         72\n",
      "  3 - high        17        102         98\n",
      "\n",
      "0.632895559724828\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.69      0.80      0.74       744\n",
      " 2 - middle       0.57      0.50      0.54       638\n",
      "   3 - high       0.54      0.45      0.49       217\n",
      "\n",
      "avg / total       0.62      0.63      0.63      1599\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "Naive Bayes (normalised data):\n",
      "           __________Prediction__________\n",
      "             1 - low 2 - middle   3 - high\n",
      "   1 - low       512        202         30\n",
      "2 - middle       209        304        125\n",
      "  3 - high        13         81        123\n",
      "\n",
      "0.5872420262664165\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.70      0.69      0.69       744\n",
      " 2 - middle       0.52      0.48      0.50       638\n",
      "   3 - high       0.44      0.57      0.50       217\n",
      "\n",
      "avg / total       0.59      0.59      0.59      1599\n",
      "\n",
      "-------------------------------------------------------------------------\n",
      "Naive Bayes (standardised data):\n",
      "           __________Prediction__________\n",
      "             1 - low 2 - middle   3 - high\n",
      "   1 - low       512        202         30\n",
      "2 - middle       209        304        125\n",
      "  3 - high        13         81        123\n",
      "\n",
      "0.5872420262664165\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.70      0.69      0.69       744\n",
      " 2 - middle       0.52      0.48      0.50       638\n",
      "   3 - high       0.44      0.57      0.50       217\n",
      "\n",
      "avg / total       0.59      0.59      0.59      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Naive Bayes (default):\")\n",
    "print(confusion_matrix_report(red_label, prediction_bayes))\n",
    "print(accuracy_score(red_label, prediction_bayes))\n",
    "print(classification_report(red_label, prediction_bayes))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(\"Naive Bayes (logarithm):\")\n",
    "print(confusion_matrix_report(red_label, prediction_bayes_log))\n",
    "print(accuracy_score(red_label, prediction_bayes_log))\n",
    "print(classification_report(red_label, prediction_bayes_log))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(\"Naive Bayes (without highly correlated variables):\")\n",
    "print(confusion_matrix_report(red_label, prediction_bayes_corrout))\n",
    "print(accuracy_score(red_label, prediction_bayes_corrout))\n",
    "print(classification_report(red_label, prediction_bayes_corrout))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(\"Naive Bayes (without highly correlated variables and logarithm):\")\n",
    "print(confusion_matrix_report(red_label, prediction_bayes_corrout_log))\n",
    "print(accuracy_score(red_label, prediction_bayes_corrout_log))\n",
    "print(classification_report(red_label, prediction_bayes_corrout_log))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(\"Naive Bayes (normalised data):\")\n",
    "print(confusion_matrix_report(red_label, prediction_bayes_normalised))\n",
    "print(accuracy_score(red_label, prediction_bayes_normalised))\n",
    "print(classification_report(red_label, prediction_bayes_normalised))\n",
    "print(\"-------------------------------------------------------------------------\")\n",
    "print(\"Naive Bayes (standardised data):\")\n",
    "print(confusion_matrix_report(red_label, prediction_bayes_standardised))\n",
    "print(accuracy_score(red_label, prediction_bayes_standardised))\n",
    "print(classification_report(red_label, prediction_bayes_standardised))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest:\n",
      "           __________Prediction__________\n",
      "             1 - low 2 - middle   3 - high\n",
      "   1 - low       528        207          9\n",
      "2 - middle       256        330         52\n",
      "  3 - high        18        130         69\n",
      "\n",
      "0.5797373358348968\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.66      0.71      0.68       744\n",
      " 2 - middle       0.49      0.52      0.51       638\n",
      "   3 - high       0.53      0.32      0.40       217\n",
      "\n",
      "avg / total       0.58      0.58      0.57      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_rfc = RandomForestClassifier(n_estimators=25, random_state=12)\n",
    "\n",
    "prediction_rfc = cross_val_predict(model_rfc, red_data_standardised, red_label, cv=10)\n",
    "\n",
    "print(\"Random Forest:\")\n",
    "print(confusion_matrix_report(red_label, prediction_rfc))\n",
    "print(accuracy_score(red_label, prediction_rfc))\n",
    "print(classification_report(red_label, prediction_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
      "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
      "       'pH', 'sulphates', 'alcohol'],\n",
      "      dtype='object')\n",
      "[0.078 0.108 0.069 0.069 0.08  0.066 0.094 0.091 0.074 0.114 0.157]\n"
     ]
    }
   ],
   "source": [
    "# Import a supervised learning model that has 'feature_importances_'\n",
    "model = RandomForestClassifier(max_depth=None, random_state=None)\n",
    "# Train the supervised model on the training set using .fit(X_train, y_train)\n",
    "model = model.fit(red_data, red_label)\n",
    "# Extract the feature importances using .feature_importances_ \n",
    "importances = model.feature_importances_\n",
    "print(red_data.columns)\n",
    "print(importances)\n",
    "# Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 10 (0.157352)\n",
      "2. feature 9 (0.114213)\n",
      "3. feature 1 (0.108305)\n",
      "4. feature 6 (0.093736)\n",
      "5. feature 7 (0.091070)\n",
      "6. feature 4 (0.080185)\n",
      "7. feature 0 (0.077919)\n",
      "8. feature 8 (0.073789)\n",
      "9. feature 3 (0.068803)\n",
      "10. feature 2 (0.068754)\n",
      "11. feature 5 (0.065873)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "std = np.std([tree.feature_importances_ for tree in model.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(red_data.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(red_data.shape[1]), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(red_data.shape[1]), indices)\n",
    "plt.xlim([-1, red_data.shape[1]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  \n",
       "0      9.4  \n",
       "1      9.8  \n",
       "2      9.8  \n",
       "3      9.8  \n",
       "4      9.4  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mord as m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_out = deepcopy(red)\n",
    "#q1 = red_out[\"alcohol\"].quantile(0.25)\n",
    "#q3 = red_out[\"alcohol\"].quantile(0.75)\n",
    "#iqr = q3 - q1\n",
    "column = [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subset_by_IQR(df,column):\n",
    "    q1 = column.quantile(0.25)\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - q1 \n",
    "    outliers = (column >= (1.5*iqr)) & (column <= 1.5*iqr)\n",
    "    return df.loc[outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "red_out_new = get_subset_by_IQR(red_out, red_out[\"alcohol\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "count            0.0               0.0          0.0             0.0   \n",
       "mean             NaN               NaN          NaN             NaN   \n",
       "std              NaN               NaN          NaN             NaN   \n",
       "min              NaN               NaN          NaN             NaN   \n",
       "25%              NaN               NaN          NaN             NaN   \n",
       "50%              NaN               NaN          NaN             NaN   \n",
       "75%              NaN               NaN          NaN             NaN   \n",
       "max              NaN               NaN          NaN             NaN   \n",
       "\n",
       "       chlorides  free sulfur dioxide  total sulfur dioxide  density   pH  \\\n",
       "count        0.0                  0.0                   0.0      0.0  0.0   \n",
       "mean         NaN                  NaN                   NaN      NaN  NaN   \n",
       "std          NaN                  NaN                   NaN      NaN  NaN   \n",
       "min          NaN                  NaN                   NaN      NaN  NaN   \n",
       "25%          NaN                  NaN                   NaN      NaN  NaN   \n",
       "50%          NaN                  NaN                   NaN      NaN  NaN   \n",
       "75%          NaN                  NaN                   NaN      NaN  NaN   \n",
       "max          NaN                  NaN                   NaN      NaN  NaN   \n",
       "\n",
       "       sulphates  alcohol  quality  \n",
       "count        0.0      0.0      0.0  \n",
       "mean         NaN      NaN      NaN  \n",
       "std          NaN      NaN      NaN  \n",
       "min          NaN      NaN      NaN  \n",
       "25%          NaN      NaN      NaN  \n",
       "50%          NaN      NaN      NaN  \n",
       "75%          NaN      NaN      NaN  \n",
       "max          NaN      NaN      NaN  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_out_new.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers_iqr(i, column):\n",
    "    q1 = column.quantile(0.25)\n",
    "    q3 = column.quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    low_border = q1 - 1.5 * iqr\n",
    "    high_border = q3 + 1.5 * iqr\n",
    "    outlier = data.loc[(data[column] > low_border) & (data[column] < high_border)]\n",
    "    return outlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Cannot index with multidimensional key",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-80-045b77c6de3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mremove_outliers_iqr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mred_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-79-3f2198024f3f>\u001b[0m in \u001b[0;36mremove_outliers_iqr\u001b[1;34m(data, column)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mlow_border\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0miqr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mhigh_border\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq3\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0miqr\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0moutlier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mlow_border\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m&\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mhigh_border\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0moutlier\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1478\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1897\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1898\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'ndim'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1899\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Cannot index with multidimensional key'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1900\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1901\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_iterable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot index with multidimensional key"
     ]
    }
   ],
   "source": [
    "print(boston_df_o1 < (Q1 - 1.5 * IQR)) |(boston_df_o1 > (Q3 + 1.5 * IQR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"pH\", \"sulphates\", \"alcohol\"]\n",
    "count = 0\n",
    "for i in red_out[\"alcohol\"]:\n",
    "    if i > 1.5*(red_out[\"alcohol\"].quantile(0.75) - (red_out[\"alcohol\"].quantile(0.25))):\n",
    "        i == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1599.000000\n",
       "mean       10.422983\n",
       "std         1.065668\n",
       "min         8.400000\n",
       "25%         9.500000\n",
       "50%        10.200000\n",
       "75%        11.100000\n",
       "max        14.900000\n",
       "Name: alcohol, dtype: float64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "red_out[\"alcohol\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "KNeighborsClassifier\n",
      "****Results****\n",
      "Accuracy: 49.2183%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.55      0.61      0.58       744\n",
      " 2 - middle       0.43      0.41      0.42       638\n",
      "   3 - high       0.44      0.31      0.36       217\n",
      "\n",
      "avg / total       0.49      0.49      0.49      1599\n",
      "\n",
      "==============================\n",
      "SVC\n",
      "****Results****\n",
      "Accuracy: 46.5291%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.47      1.00      0.64       744\n",
      " 2 - middle       0.00      0.00      0.00       638\n",
      "   3 - high       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.22      0.47      0.30      1599\n",
      "\n",
      "==============================\n",
      "DecisionTreeClassifier\n",
      "****Results****\n",
      "Accuracy: 51.6573%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.61      0.63      0.62       744\n",
      " 2 - middle       0.44      0.43      0.43       638\n",
      "   3 - high       0.41      0.39      0.40       217\n",
      "\n",
      "avg / total       0.51      0.52      0.51      1599\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================\n",
      "RandomForestClassifier\n",
      "****Results****\n",
      "Accuracy: 58.2239%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.64      0.75      0.69       744\n",
      " 2 - middle       0.52      0.47      0.49       638\n",
      "   3 - high       0.51      0.35      0.42       217\n",
      "\n",
      "avg / total       0.57      0.58      0.57      1599\n",
      "\n",
      "==============================\n",
      "AdaBoostClassifier\n",
      "****Results****\n",
      "Accuracy: 60.5378%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.68      0.75      0.71       744\n",
      " 2 - middle       0.54      0.51      0.53       638\n",
      "   3 - high       0.50      0.37      0.43       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "==============================\n",
      "GradientBoostingClassifier\n",
      "****Results****\n",
      "Accuracy: 61.2883%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.69      0.74      0.72       744\n",
      " 2 - middle       0.54      0.54      0.54       638\n",
      "   3 - high       0.53      0.40      0.45       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "==============================\n",
      "GaussianNB\n",
      "****Results****\n",
      "Accuracy: 58.6617%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.70      0.69      0.69       744\n",
      " 2 - middle       0.51      0.47      0.49       638\n",
      "   3 - high       0.44      0.55      0.49       217\n",
      "\n",
      "avg / total       0.59      0.59      0.59      1599\n",
      "\n",
      "==============================\n",
      "LinearDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 62.3515%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.70      0.77      0.73       744\n",
      " 2 - middle       0.55      0.52      0.54       638\n",
      "   3 - high       0.52      0.43      0.47       217\n",
      "\n",
      "avg / total       0.62      0.62      0.62      1599\n",
      "\n",
      "==============================\n",
      "QuadraticDiscriminantAnalysis\n",
      "****Results****\n",
      "Accuracy: 58.2239%\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    1 - low       0.71      0.65      0.68       744\n",
      " 2 - middle       0.50      0.55      0.52       638\n",
      "   3 - high       0.44      0.46      0.45       217\n",
      "\n",
      "avg / total       0.59      0.58      0.59      1599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"rbf\", C=0.025, probability=True),\n",
    "    DecisionTreeClassifier(),\n",
    "    RandomForestClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    GaussianNB(),\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    QuadraticDiscriminantAnalysis()]\n",
    "\n",
    "\n",
    "# Logging for Visual Comparison\n",
    "log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "log = pd.DataFrame(columns=log_cols)\n",
    "\n",
    "for clf in classifiers:\n",
    "    prediction_val = cross_val_predict(clf, red_data, red_label, cv=10)\n",
    "    name = clf.__class__.__name__\n",
    "\n",
    "    \n",
    "    print(\"=\"*30)\n",
    "    print(name)\n",
    "    \n",
    "    print('****Results****')\n",
    "    acc = accuracy_score(red_label, prediction_val)\n",
    "    print(\"Accuracy: {:.4%}\".format(acc))\n",
    "    print(classification_report(red_label, prediction_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/:\n",
    "\n",
    "Pros:\n",
    "\n",
    "- It is easy and fast to predict class of test data set. It also perform well in multi class prediction\n",
    "- When assumption of independence holds, a Naive Bayes classifier performs better compare to other models like logistic regression and you need less training data.\n",
    "- It perform well in case of categorical input variables compared to numerical variable(s). For numerical variable, normal distribution is assumed (bell curve, which is a strong assumption).\n",
    "\n",
    "Cons:\n",
    "\n",
    "- If categorical variable has a category (in test data set), which was not observed in training data set, then model will assign a 0 (zero) probability and will be unable to make a prediction. This is often known as Zero Frequency. To solve this, we can use the smoothing technique. One of the simplest smoothing techniques is called Laplace estimation.\n",
    "- On the other side naive Bayes is also known as a bad estimator, so the probability outputs from predict_proba are not to be taken too seriously.\n",
    "- Another limitation of Naive Bayes is the assumption of independent predictors. In real life, it is almost impossible that we get a set of predictors which are completely independent.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying to improve the power of Naive Bayes\n",
    "\n",
    "https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/:\n",
    "\n",
    "- If continuous features do not have normal distribution, we should use transformation or different methods to convert it in normal distribution.\n",
    "- If test data set has zero frequency issue, apply smoothing techniques Laplace Correction to predict the class of test data set.\n",
    "- Remove correlated features, as the highly correlated features are voted twice in the model and it can lead to over inflating importance.\n",
    "- Naive Bayes classifiers has limited options for parameter tuning like alpha=1 for smoothing, fit_prior=[True|False] to learn class prior probabilities or not and some other options (look at detail here). I would recommend to focus on your  pre-processing of data and the feature selection.\n",
    "- You might think to apply some classifier combination technique like ensembling, bagging and boosting but these methods would not help. Actually, ensembling, boosting, bagging wont help since their purpose is to reduce variance. Naive Bayes has no variance to minimize.\n",
    "\n",
    "Naive Bayes verbessern:\n",
    "- Fisher method\n",
    "- One against many approach bei classess\n",
    "- Tuning\n",
    "- Ensembling, Boosting, bagging, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test-split vs. Stratified 10-fold Cross-Validation vs. LOOCV\n",
    "\n",
    "k-fold-CrossValidation\n",
    "-\tImportantly, each observation in the data sample is assigned to an individual group and stays in that group for the duration of the procedure. This means that each sample is given the opportunity to be used in the hold out set 1 time and used to train the model k-1 times.\n",
    "-\tIt is also important that any preparation of the data prior to fitting the model occur on the CV-assigned training dataset within the loop rather than on the broader data set. This also applies to any tuning of hyperparameters. A failure to perform these operations within the loop may result in data leakage and an optimistic estimate of the model skill.\n",
    "\n",
    "Configuration of k\n",
    "- A poorly chosen value for k may result in a mis-representative idea of the skill of the model, such as a score with a high variance (that may change a lot based on the data used to fit the model), or a high bias, (such as an overestimate of the skill of the model).\n",
    "\n",
    "Three common tactics for choosing a value for k are as follows:\n",
    "-\tRepresentative: The value for k is chosen such that each train/test group of data samples is large enough to be statistically representative of the broader dataset.\n",
    "-\tk=10: The value for k is fixed to 10, a value that has been found through experimentation to generally result in a model skill estimate with low bias a modest variance.\n",
    "-\tk=n: The value for k is fixed to n, where n is the size of the dataset to give each test sample an opportunity to be used in the hold out dataset. This approach is called leave-one-out cross-validation.\n",
    "It is preferable to split the data sample into k groups with the same number of samples, such that the sample of model skill scores are all equivalent!\n",
    "\n",
    "Reasons for cross-validation:\n",
    "-\tavoids overfitting\n",
    "-\tall available data is used for training, equal splits because stratified, everyone is represented\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further questions?:\n",
    "- Is the classifier better in detecting average, good or bad wines? What could be the reason?\n",
    "- What can this classifier be used for in reality? What benefits does it have?\n",
    "- Comparison to regression techniques?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
