{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initializing</h2>\n",
    "<p>Import Libraries, add variables for attribute strings (to save '') and load data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import interp\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "import math\n",
    "\n",
    "fixed_acidity = 'fixed acidity'\n",
    "volatile_acidity = 'volatile acidity'\n",
    "citric_acid = 'citric acid'\n",
    "residual_sugar = 'residual sugar'\n",
    "chlorides = 'chlorides'\n",
    "free_sulfur_dioxide = 'free sulfur dioxide'\n",
    "total_sulfur_dioxide = 'total sulfur dioxide'\n",
    "density = 'density'\n",
    "ph = 'pH'\n",
    "sulphates = 'sulphates'\n",
    "alcohol = 'alcohol'\n",
    "quality = 'quality'\n",
    "qclass = 'qclass'\n",
    "ratio_to_fixed = 'ratio_to_fixed'\n",
    "ratio_to_volatile = 'ratio_to_volatile'\n",
    "ph_acidity = 'ph_acidity'\n",
    "ratio_to_ph = 'ratio_to_ph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_report(y_true, y_pred):\n",
    "    cm, labels = confusion_matrix(y_true, y_pred), unique_labels(y_true, y_pred)\n",
    "    column_width = max([len(str(x)) for x in labels] + [5])  # 5 is value length\n",
    "    report = \" \" * column_width + \" \" + \"{:_^{}}\".format(\"Prediction\", column_width * len(labels))+ \"\\n\"\n",
    "    report += \" \" * column_width + \" \".join([\"{:>{}}\".format(label, column_width) for label in labels]) + \"\\n\"\n",
    "    for i, label1 in enumerate(labels):\n",
    "        report += \"{:>{}}\".format(label1, column_width) + \" \".join([\"{:{}d}\".format(cm[i, j], column_width) for j in range(len(labels))]) + \"\\n\"\n",
    "    return report\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return math.sqrt(np.mean((y_pred - y_true)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Import red and white dataset.<br/>\n",
    "Split into input matrix (independent vars) and output vector (target vars).<br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>sort for kNN (https://scikit-learn.org/stable/modules/neighbors.html#unsupervised-nearest-neighbors) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = pd.read_csv(\"data/winequality-white1.csv\")\n",
    "red = pd.read_csv(\"data/winequality-red1.csv\")\n",
    "white.sort_values(by='quality',inplace=True)\n",
    "red.sort_values(by='quality',inplace=True)\n",
    "white_target = white[quality]\n",
    "red_target = red[quality]\n",
    "white_input = white.drop(quality,axis=1)\n",
    "red_input = red.drop(quality,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ratio of acidity to sugar as attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#white[ph_acidity] = 7 - white[ph]\n",
    "#red[ph_acidity] = 7 - red[ph]\n",
    "#white_input[ratio_to_fixed]=white[residual_sugar]/white[fixed_acidity]\n",
    "#white_input[ratio_to_volatile]=white[residual_sugar]/white[volatile_acidity]\n",
    "#white_input[ratio_to_ph]=white[residual_sugar]/white[ph_acidity]\n",
    "#red_input[ratio_to_fixed]=red[residual_sugar]/red[fixed_acidity]\n",
    "#red_input[ratio_to_volatile]=red[residual_sugar]/red[volatile_acidity]\n",
    "#red_input[ratio_to_ph]=red[residual_sugar]/red[ph_acidity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>using log.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_white_norm=np.log(white_input+1)\n",
    "log_red_norm=np.log(red_input+1)\n",
    "f_log_white=log_white_norm.drop([fixed_acidity,sulphates,chlorides,citric_acid,ph,density,total_sulfur_dioxide,residual_sugar],axis=1)\n",
    "f_log_red=log_red_norm.drop([free_sulfur_dioxide,ph,residual_sugar,chlorides,citric_acid,fixed_acidity,density],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Normalize using MinMax Normalizer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_white_norm=(white_input-white_input.min())/(white_input.max()-white_input.min())\n",
    "mm_red_norm=(red_input-red_input.min())/(red_input.max()-red_input.min())\n",
    "f_mm_white = mm_white_norm.drop([fixed_acidity,sulphates,chlorides,citric_acid,ph,density,total_sulfur_dioxide,residual_sugar],axis=1)\n",
    "f_mm_red = mm_red_norm.drop([free_sulfur_dioxide,ph,residual_sugar,chlorides,citric_acid,fixed_acidity,density],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Normalize using Mean Normalizer.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_norm=(white_input-white_input.mean())/(white_input.std())\n",
    "red_norm=(red_input-red_input.mean())/(red_input.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Correlation Matrices</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col0 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col1 {\n",
       "            background-color:  #e8e4f0;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col2 {\n",
       "            background-color:  #a1bbda;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col3 {\n",
       "            background-color:  #a7bddb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col4 {\n",
       "            background-color:  #c5cce3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col5 {\n",
       "            background-color:  #e4e1ef;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col6 {\n",
       "            background-color:  #a7bddb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col7 {\n",
       "            background-color:  #4897c4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col8 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col9 {\n",
       "            background-color:  #fdf5fa;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col10 {\n",
       "            background-color:  #a8bedc;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col11 {\n",
       "            background-color:  #e7e3f0;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col0 {\n",
       "            background-color:  #c5cce3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col1 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col2 {\n",
       "            background-color:  #fdf5fa;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col3 {\n",
       "            background-color:  #adc1dd;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col4 {\n",
       "            background-color:  #b9c6e0;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col5 {\n",
       "            background-color:  #ede7f2;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col6 {\n",
       "            background-color:  #a7bddb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col7 {\n",
       "            background-color:  #86b0d3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col8 {\n",
       "            background-color:  #c8cde4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col9 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col10 {\n",
       "            background-color:  #7eadd1;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col11 {\n",
       "            background-color:  #f2ecf5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col0 {\n",
       "            background-color:  #73a9cf;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col1 {\n",
       "            background-color:  #faf2f8;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col2 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col3 {\n",
       "            background-color:  #a5bddb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col4 {\n",
       "            background-color:  #afc1dd;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col5 {\n",
       "            background-color:  #c8cde4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col6 {\n",
       "            background-color:  #9fbad9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col7 {\n",
       "            background-color:  #69a5cc;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col8 {\n",
       "            background-color:  #dfddec;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col9 {\n",
       "            background-color:  #f1ebf4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col10 {\n",
       "            background-color:  #9ebad9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col11 {\n",
       "            background-color:  #d5d5e8;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col0 {\n",
       "            background-color:  #abbfdc;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col1 {\n",
       "            background-color:  #d8d7e9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col2 {\n",
       "            background-color:  #d7d6e9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col3 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col4 {\n",
       "            background-color:  #b5c4df;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col5 {\n",
       "            background-color:  #8cb3d5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col6 {\n",
       "            background-color:  #4897c4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col7 {\n",
       "            background-color:  #03517e;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col8 {\n",
       "            background-color:  #e4e1ef;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col9 {\n",
       "            background-color:  #fef6fa;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col10 {\n",
       "            background-color:  #dfddec;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col11 {\n",
       "            background-color:  #e4e1ef;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col0 {\n",
       "            background-color:  #bbc7e0;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col1 {\n",
       "            background-color:  #d7d6e9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col2 {\n",
       "            background-color:  #d2d3e7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col3 {\n",
       "            background-color:  #a7bddb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col4 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col5 {\n",
       "            background-color:  #c6cce3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col6 {\n",
       "            background-color:  #89b1d4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col7 {\n",
       "            background-color:  #4a98c5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col8 {\n",
       "            background-color:  #d3d4e7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col9 {\n",
       "            background-color:  #f8f1f8;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col10 {\n",
       "            background-color:  #d3d4e7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col11 {\n",
       "            background-color:  #f4edf6;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col0 {\n",
       "            background-color:  #cccfe5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col1 {\n",
       "            background-color:  #f3edf5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col2 {\n",
       "            background-color:  #d7d6e9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col3 {\n",
       "            background-color:  #6ba5cd;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col4 {\n",
       "            background-color:  #b3c3de;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col5 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col6 {\n",
       "            background-color:  #0a73b2;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col7 {\n",
       "            background-color:  #4094c3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col8 {\n",
       "            background-color:  #c0c9e2;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col9 {\n",
       "            background-color:  #f1ebf5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col10 {\n",
       "            background-color:  #c0c9e2;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col11 {\n",
       "            background-color:  #d2d3e7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col0 {\n",
       "            background-color:  #abbfdc;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col1 {\n",
       "            background-color:  #d3d4e7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col2 {\n",
       "            background-color:  #d2d2e7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col3 {\n",
       "            background-color:  #4897c4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col4 {\n",
       "            background-color:  #97b7d7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col5 {\n",
       "            background-color:  #1b7eb7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col6 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col7 {\n",
       "            background-color:  #0a73b2;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col8 {\n",
       "            background-color:  #c0c9e2;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col9 {\n",
       "            background-color:  #e3e0ee;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col10 {\n",
       "            background-color:  #dfddec;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col11 {\n",
       "            background-color:  #f0eaf4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col0 {\n",
       "            background-color:  #79abd0;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col1 {\n",
       "            background-color:  #dfddec;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col2 {\n",
       "            background-color:  #cacee5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col3 {\n",
       "            background-color:  #045687;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col4 {\n",
       "            background-color:  #86b0d3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col5 {\n",
       "            background-color:  #8eb3d5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col6 {\n",
       "            background-color:  #2383ba;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col7 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col8 {\n",
       "            background-color:  #d4d4e8;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col9 {\n",
       "            background-color:  #efe9f3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col10 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col11 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col0 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col1 {\n",
       "            background-color:  #eae6f1;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col2 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col3 {\n",
       "            background-color:  #e0deed;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col4 {\n",
       "            background-color:  #dcdaeb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col5 {\n",
       "            background-color:  #dbdaeb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col6 {\n",
       "            background-color:  #bcc7e1;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col7 {\n",
       "            background-color:  #a2bcda;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col8 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col9 {\n",
       "            background-color:  #dfddec;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col10 {\n",
       "            background-color:  #71a8ce;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col11 {\n",
       "            background-color:  #bcc7e1;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col0 {\n",
       "            background-color:  #c4cbe3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col1 {\n",
       "            background-color:  #eae6f1;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col2 {\n",
       "            background-color:  #dddbec;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col3 {\n",
       "            background-color:  #c2cbe2;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col4 {\n",
       "            background-color:  #c8cde4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col5 {\n",
       "            background-color:  #d1d2e6;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col6 {\n",
       "            background-color:  #9ab8d8;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col7 {\n",
       "            background-color:  #7dacd1;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col8 {\n",
       "            background-color:  #99b8d8;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col9 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col10 {\n",
       "            background-color:  #91b5d6;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col11 {\n",
       "            background-color:  #c8cde4;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col0 {\n",
       "            background-color:  #d9d8ea;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col1 {\n",
       "            background-color:  #d7d6e9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col2 {\n",
       "            background-color:  #f4edf6;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col3 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col4 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col5 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col6 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col7 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col8 {\n",
       "            background-color:  #a2bcda;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col9 {\n",
       "            background-color:  #fdf5fa;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col10 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col11 {\n",
       "            background-color:  #529bc7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col0 {\n",
       "            background-color:  #d7d6e9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col1 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col2 {\n",
       "            background-color:  #ebe6f2;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col3 {\n",
       "            background-color:  #d2d2e7;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col4 {\n",
       "            background-color:  #eee9f3;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col5 {\n",
       "            background-color:  #dad9ea;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col6 {\n",
       "            background-color:  #dedcec;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col7 {\n",
       "            background-color:  #cacee5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col8 {\n",
       "            background-color:  #a8bedc;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col9 {\n",
       "            background-color:  #f2ecf5;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col10 {\n",
       "            background-color:  #2081b9;\n",
       "        }    #T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col11 {\n",
       "            background-color:  #023858;\n",
       "        }</style>  \n",
       "<table id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058c\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >fixed acidity</th> \n",
       "        <th class=\"col_heading level0 col1\" >volatile acidity</th> \n",
       "        <th class=\"col_heading level0 col2\" >citric acid</th> \n",
       "        <th class=\"col_heading level0 col3\" >residual sugar</th> \n",
       "        <th class=\"col_heading level0 col4\" >chlorides</th> \n",
       "        <th class=\"col_heading level0 col5\" >free sulfur dioxide</th> \n",
       "        <th class=\"col_heading level0 col6\" >total sulfur dioxide</th> \n",
       "        <th class=\"col_heading level0 col7\" >density</th> \n",
       "        <th class=\"col_heading level0 col8\" >pH</th> \n",
       "        <th class=\"col_heading level0 col9\" >sulphates</th> \n",
       "        <th class=\"col_heading level0 col10\" >alcohol</th> \n",
       "        <th class=\"col_heading level0 col11\" >quality</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row0\" class=\"row_heading level0 row0\" >fixed acidity</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col0\" class=\"data row0 col0\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col1\" class=\"data row0 col1\" >-0.0227</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col2\" class=\"data row0 col2\" >0.289</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col3\" class=\"data row0 col3\" >0.089</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col4\" class=\"data row0 col4\" >0.0231</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col5\" class=\"data row0 col5\" >-0.0494</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col6\" class=\"data row0 col6\" >0.0911</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col7\" class=\"data row0 col7\" >0.265</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col8\" class=\"data row0 col8\" >-0.426</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col9\" class=\"data row0 col9\" >-0.0171</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col10\" class=\"data row0 col10\" >-0.121</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow0_col11\" class=\"data row0 col11\" >-0.114</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row1\" class=\"row_heading level0 row1\" >volatile acidity</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col0\" class=\"data row1 col0\" >-0.0227</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col1\" class=\"data row1 col1\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col2\" class=\"data row1 col2\" >-0.149</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col3\" class=\"data row1 col3\" >0.0643</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col4\" class=\"data row1 col4\" >0.0705</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col5\" class=\"data row1 col5\" >-0.097</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col6\" class=\"data row1 col6\" >0.0893</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col7\" class=\"data row1 col7\" >0.0271</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col8\" class=\"data row1 col8\" >-0.0319</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col9\" class=\"data row1 col9\" >-0.0357</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col10\" class=\"data row1 col10\" >0.0677</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow1_col11\" class=\"data row1 col11\" >-0.195</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row2\" class=\"row_heading level0 row2\" >citric acid</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col0\" class=\"data row2 col0\" >0.289</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col1\" class=\"data row2 col1\" >-0.149</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col2\" class=\"data row2 col2\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col3\" class=\"data row2 col3\" >0.0942</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col4\" class=\"data row2 col4\" >0.114</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col5\" class=\"data row2 col5\" >0.0941</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col6\" class=\"data row2 col6\" >0.121</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col7\" class=\"data row2 col7\" >0.15</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col8\" class=\"data row2 col8\" >-0.164</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col9\" class=\"data row2 col9\" >0.0623</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col10\" class=\"data row2 col10\" >-0.0757</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow2_col11\" class=\"data row2 col11\" >-0.00921</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row3\" class=\"row_heading level0 row3\" >residual sugar</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col0\" class=\"data row3 col0\" >0.089</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col1\" class=\"data row3 col1\" >0.0643</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col2\" class=\"data row3 col2\" >0.0942</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col3\" class=\"data row3 col3\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col4\" class=\"data row3 col4\" >0.0887</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col5\" class=\"data row3 col5\" >0.299</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col6\" class=\"data row3 col6\" >0.401</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col7\" class=\"data row3 col7\" >0.839</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col8\" class=\"data row3 col8\" >-0.194</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col9\" class=\"data row3 col9\" >-0.0267</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col10\" class=\"data row3 col10\" >-0.451</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow3_col11\" class=\"data row3 col11\" >-0.0976</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row4\" class=\"row_heading level0 row4\" >chlorides</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col0\" class=\"data row4 col0\" >0.0231</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col1\" class=\"data row4 col1\" >0.0705</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col2\" class=\"data row4 col2\" >0.114</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col3\" class=\"data row4 col3\" >0.0887</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col4\" class=\"data row4 col4\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col5\" class=\"data row4 col5\" >0.101</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col6\" class=\"data row4 col6\" >0.199</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col7\" class=\"data row4 col7\" >0.257</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col8\" class=\"data row4 col8\" >-0.0904</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col9\" class=\"data row4 col9\" >0.0168</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col10\" class=\"data row4 col10\" >-0.36</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow4_col11\" class=\"data row4 col11\" >-0.21</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row5\" class=\"row_heading level0 row5\" >free sulfur dioxide</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col0\" class=\"data row5 col0\" >-0.0494</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col1\" class=\"data row5 col1\" >-0.097</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col2\" class=\"data row5 col2\" >0.0941</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col3\" class=\"data row5 col3\" >0.299</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col4\" class=\"data row5 col4\" >0.101</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col5\" class=\"data row5 col5\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col6\" class=\"data row5 col6\" >0.616</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col7\" class=\"data row5 col7\" >0.294</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col8\" class=\"data row5 col8\" >-0.000618</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col9\" class=\"data row5 col9\" >0.0592</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col10\" class=\"data row5 col10\" >-0.25</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow5_col11\" class=\"data row5 col11\" >0.00816</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row6\" class=\"row_heading level0 row6\" >total sulfur dioxide</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col0\" class=\"data row6 col0\" >0.0911</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col1\" class=\"data row6 col1\" >0.0893</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col2\" class=\"data row6 col2\" >0.121</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col3\" class=\"data row6 col3\" >0.401</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col4\" class=\"data row6 col4\" >0.199</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col5\" class=\"data row6 col5\" >0.616</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col6\" class=\"data row6 col6\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col7\" class=\"data row6 col7\" >0.53</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col8\" class=\"data row6 col8\" >0.00232</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col9\" class=\"data row6 col9\" >0.135</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col10\" class=\"data row6 col10\" >-0.449</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow6_col11\" class=\"data row6 col11\" >-0.175</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row7\" class=\"row_heading level0 row7\" >density</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col0\" class=\"data row7 col0\" >0.265</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col1\" class=\"data row7 col1\" >0.0271</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col2\" class=\"data row7 col2\" >0.15</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col3\" class=\"data row7 col3\" >0.839</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col4\" class=\"data row7 col4\" >0.257</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col5\" class=\"data row7 col5\" >0.294</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col6\" class=\"data row7 col6\" >0.53</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col7\" class=\"data row7 col7\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col8\" class=\"data row7 col8\" >-0.0936</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col9\" class=\"data row7 col9\" >0.0745</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col10\" class=\"data row7 col10\" >-0.78</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow7_col11\" class=\"data row7 col11\" >-0.307</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row8\" class=\"row_heading level0 row8\" >pH</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col0\" class=\"data row8 col0\" >-0.426</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col1\" class=\"data row8 col1\" >-0.0319</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col2\" class=\"data row8 col2\" >-0.164</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col3\" class=\"data row8 col3\" >-0.194</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col4\" class=\"data row8 col4\" >-0.0904</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col5\" class=\"data row8 col5\" >-0.000618</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col6\" class=\"data row8 col6\" >0.00232</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col7\" class=\"data row8 col7\" >-0.0936</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col8\" class=\"data row8 col8\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col9\" class=\"data row8 col9\" >0.156</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col10\" class=\"data row8 col10\" >0.121</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow8_col11\" class=\"data row8 col11\" >0.0994</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row9\" class=\"row_heading level0 row9\" >sulphates</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col0\" class=\"data row9 col0\" >-0.0171</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col1\" class=\"data row9 col1\" >-0.0357</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col2\" class=\"data row9 col2\" >0.0623</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col3\" class=\"data row9 col3\" >-0.0267</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col4\" class=\"data row9 col4\" >0.0168</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col5\" class=\"data row9 col5\" >0.0592</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col6\" class=\"data row9 col6\" >0.135</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col7\" class=\"data row9 col7\" >0.0745</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col8\" class=\"data row9 col8\" >0.156</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col9\" class=\"data row9 col9\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col10\" class=\"data row9 col10\" >-0.0174</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow9_col11\" class=\"data row9 col11\" >0.0537</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row10\" class=\"row_heading level0 row10\" >alcohol</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col0\" class=\"data row10 col0\" >-0.121</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col1\" class=\"data row10 col1\" >0.0677</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col2\" class=\"data row10 col2\" >-0.0757</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col3\" class=\"data row10 col3\" >-0.451</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col4\" class=\"data row10 col4\" >-0.36</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col5\" class=\"data row10 col5\" >-0.25</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col6\" class=\"data row10 col6\" >-0.449</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col7\" class=\"data row10 col7\" >-0.78</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col8\" class=\"data row10 col8\" >0.121</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col9\" class=\"data row10 col9\" >-0.0174</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col10\" class=\"data row10 col10\" >1</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow10_col11\" class=\"data row10 col11\" >0.436</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058clevel0_row11\" class=\"row_heading level0 row11\" >quality</th> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col0\" class=\"data row11 col0\" >-0.114</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col1\" class=\"data row11 col1\" >-0.195</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col2\" class=\"data row11 col2\" >-0.00921</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col3\" class=\"data row11 col3\" >-0.0976</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col4\" class=\"data row11 col4\" >-0.21</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col5\" class=\"data row11 col5\" >0.00816</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col6\" class=\"data row11 col6\" >-0.175</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col7\" class=\"data row11 col7\" >-0.307</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col8\" class=\"data row11 col8\" >0.0994</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col9\" class=\"data row11 col9\" >0.0537</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col10\" class=\"data row11 col10\" >0.436</td> \n",
       "        <td id=\"T_932cd5b6_f0ac_11e8_bace_5ce0c5fe058crow11_col11\" class=\"data row11 col11\" >1</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20b6bcb48d0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wcorr = white.corr()\n",
    "wcorr.style.background_gradient().set_precision(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col0 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col1 {\n",
       "            background-color:  #dedcec;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col2 {\n",
       "            background-color:  #0569a5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col3 {\n",
       "            background-color:  #dfddec;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col4 {\n",
       "            background-color:  #c5cce3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col5 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col6 {\n",
       "            background-color:  #f4edf6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col7 {\n",
       "            background-color:  #056ba7;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col8 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col9 {\n",
       "            background-color:  #adc1dd;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col10 {\n",
       "            background-color:  #c2cbe2;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col11 {\n",
       "            background-color:  #a8bedc;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col0 {\n",
       "            background-color:  #d0d1e6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col1 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col2 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col3 {\n",
       "            background-color:  #f3edf5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col4 {\n",
       "            background-color:  #cdd0e5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col5 {\n",
       "            background-color:  #ede7f2;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col6 {\n",
       "            background-color:  #d4d4e8;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col7 {\n",
       "            background-color:  #b0c2de;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col8 {\n",
       "            background-color:  #5ea0ca;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col9 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col10 {\n",
       "            background-color:  #dcdaeb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col11 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col0 {\n",
       "            background-color:  #0566a0;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col1 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col2 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col3 {\n",
       "            background-color:  #d9d8ea;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col4 {\n",
       "            background-color:  #a8bedc;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col5 {\n",
       "            background-color:  #f3edf5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col6 {\n",
       "            background-color:  #dbdaeb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col7 {\n",
       "            background-color:  #4e9ac6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col8 {\n",
       "            background-color:  #f2ecf5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col9 {\n",
       "            background-color:  #86b0d3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col10 {\n",
       "            background-color:  #9ab8d8;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col11 {\n",
       "            background-color:  #8bb2d4;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col0 {\n",
       "            background-color:  #7eadd1;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col1 {\n",
       "            background-color:  #acc0dd;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col2 {\n",
       "            background-color:  #89b1d4;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col3 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col4 {\n",
       "            background-color:  #d0d1e6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col5 {\n",
       "            background-color:  #c1cae2;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col6 {\n",
       "            background-color:  #b3c3de;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col7 {\n",
       "            background-color:  #529bc7;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col8 {\n",
       "            background-color:  #adc1dd;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col9 {\n",
       "            background-color:  #d9d8ea;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col10 {\n",
       "            background-color:  #abbfdc;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col11 {\n",
       "            background-color:  #c2cbe2;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col0 {\n",
       "            background-color:  #83afd3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col1 {\n",
       "            background-color:  #9ebad9;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col2 {\n",
       "            background-color:  #79abd0;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col3 {\n",
       "            background-color:  #ebe6f2;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col4 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col5 {\n",
       "            background-color:  #e9e5f1;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col6 {\n",
       "            background-color:  #d9d8ea;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col7 {\n",
       "            background-color:  #81aed2;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col8 {\n",
       "            background-color:  #d1d2e6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col9 {\n",
       "            background-color:  #73a9cf;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col10 {\n",
       "            background-color:  #dfddec;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col11 {\n",
       "            background-color:  #dedcec;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col0 {\n",
       "            background-color:  #bbc7e0;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col1 {\n",
       "            background-color:  #afc1dd;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col2 {\n",
       "            background-color:  #b9c6e0;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col3 {\n",
       "            background-color:  #d0d1e6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col4 {\n",
       "            background-color:  #d9d8ea;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col5 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col6 {\n",
       "            background-color:  #0f76b3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col7 {\n",
       "            background-color:  #b9c6e0;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col8 {\n",
       "            background-color:  #89b1d4;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col9 {\n",
       "            background-color:  #d1d2e6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col10 {\n",
       "            background-color:  #c4cbe3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col11 {\n",
       "            background-color:  #d2d2e7;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col0 {\n",
       "            background-color:  #b3c3de;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col1 {\n",
       "            background-color:  #9ab8d8;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col2 {\n",
       "            background-color:  #a5bddb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col3 {\n",
       "            background-color:  #cacee5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col4 {\n",
       "            background-color:  #d1d2e6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col5 {\n",
       "            background-color:  #1379b5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col6 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col7 {\n",
       "            background-color:  #a4bcda;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col8 {\n",
       "            background-color:  #a9bfdc;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col9 {\n",
       "            background-color:  #d2d3e7;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col10 {\n",
       "            background-color:  #dddbec;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col11 {\n",
       "            background-color:  #e7e3f0;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col0 {\n",
       "            background-color:  #0567a1;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col1 {\n",
       "            background-color:  #a8bedc;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col2 {\n",
       "            background-color:  #4697c4;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col3 {\n",
       "            background-color:  #9ab8d8;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col4 {\n",
       "            background-color:  #a8bedc;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col5 {\n",
       "            background-color:  #eee8f3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col6 {\n",
       "            background-color:  #d5d5e8;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col7 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col8 {\n",
       "            background-color:  #dbdaeb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col9 {\n",
       "            background-color:  #b7c5df;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col10 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col11 {\n",
       "            background-color:  #e6e2ef;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col0 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col1 {\n",
       "            background-color:  #71a8ce;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col2 {\n",
       "            background-color:  #fef6fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col3 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col4 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col5 {\n",
       "            background-color:  #dddbec;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col6 {\n",
       "            background-color:  #eee8f3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col7 {\n",
       "            background-color:  #f0eaf4;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col8 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col9 {\n",
       "            background-color:  #f7f0f7;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col10 {\n",
       "            background-color:  #80aed2;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col11 {\n",
       "            background-color:  #d2d3e7;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col0 {\n",
       "            background-color:  #6da6cd;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col1 {\n",
       "            background-color:  #dedcec;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col2 {\n",
       "            background-color:  #589ec8;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col3 {\n",
       "            background-color:  #f2ecf5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col4 {\n",
       "            background-color:  #73a9cf;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col5 {\n",
       "            background-color:  #e0deed;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col6 {\n",
       "            background-color:  #dad9ea;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col7 {\n",
       "            background-color:  #8fb4d6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col8 {\n",
       "            background-color:  #c4cbe3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col9 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col10 {\n",
       "            background-color:  #9fbad9;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col11 {\n",
       "            background-color:  #83afd3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col0 {\n",
       "            background-color:  #a8bedc;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col1 {\n",
       "            background-color:  #d6d6e9;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col2 {\n",
       "            background-color:  #91b5d6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col3 {\n",
       "            background-color:  #ede8f3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col4 {\n",
       "            background-color:  #faf3f9;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col5 {\n",
       "            background-color:  #f4eef6;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col6 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col7 {\n",
       "            background-color:  #fff7fb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col8 {\n",
       "            background-color:  #65a3cb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col9 {\n",
       "            background-color:  #c6cce3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col10 {\n",
       "            background-color:  #023858;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col11 {\n",
       "            background-color:  #3790c0;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col0 {\n",
       "            background-color:  #7dacd1;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col1 {\n",
       "            background-color:  #f0eaf4;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col2 {\n",
       "            background-color:  #73a9cf;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col3 {\n",
       "            background-color:  #f1ebf5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col4 {\n",
       "            background-color:  #efe9f3;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col5 {\n",
       "            background-color:  #f2ecf5;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col6 {\n",
       "            background-color:  #fdf5fa;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col7 {\n",
       "            background-color:  #d9d8ea;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col8 {\n",
       "            background-color:  #a7bddb;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col9 {\n",
       "            background-color:  #99b8d8;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col10 {\n",
       "            background-color:  #2c89bd;\n",
       "        }    #T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col11 {\n",
       "            background-color:  #023858;\n",
       "        }</style>  \n",
       "<table id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058c\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >fixed acidity</th> \n",
       "        <th class=\"col_heading level0 col1\" >volatile acidity</th> \n",
       "        <th class=\"col_heading level0 col2\" >citric acid</th> \n",
       "        <th class=\"col_heading level0 col3\" >residual sugar</th> \n",
       "        <th class=\"col_heading level0 col4\" >chlorides</th> \n",
       "        <th class=\"col_heading level0 col5\" >free sulfur dioxide</th> \n",
       "        <th class=\"col_heading level0 col6\" >total sulfur dioxide</th> \n",
       "        <th class=\"col_heading level0 col7\" >density</th> \n",
       "        <th class=\"col_heading level0 col8\" >pH</th> \n",
       "        <th class=\"col_heading level0 col9\" >sulphates</th> \n",
       "        <th class=\"col_heading level0 col10\" >alcohol</th> \n",
       "        <th class=\"col_heading level0 col11\" >quality</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row0\" class=\"row_heading level0 row0\" >fixed acidity</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col0\" class=\"data row0 col0\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col1\" class=\"data row0 col1\" >-0.256</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col2\" class=\"data row0 col2\" >0.672</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col3\" class=\"data row0 col3\" >0.115</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col4\" class=\"data row0 col4\" >0.0937</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col5\" class=\"data row0 col5\" >-0.154</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col6\" class=\"data row0 col6\" >-0.113</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col7\" class=\"data row0 col7\" >0.668</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col8\" class=\"data row0 col8\" >-0.683</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col9\" class=\"data row0 col9\" >0.183</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col10\" class=\"data row0 col10\" >-0.0617</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow0_col11\" class=\"data row0 col11\" >0.124</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row1\" class=\"row_heading level0 row1\" >volatile acidity</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col0\" class=\"data row1 col0\" >-0.256</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col1\" class=\"data row1 col1\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col2\" class=\"data row1 col2\" >-0.552</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col3\" class=\"data row1 col3\" >0.00192</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col4\" class=\"data row1 col4\" >0.0613</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col5\" class=\"data row1 col5\" >-0.0105</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col6\" class=\"data row1 col6\" >0.0765</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col7\" class=\"data row1 col7\" >0.022</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col8\" class=\"data row1 col8\" >0.235</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col9\" class=\"data row1 col9\" >-0.261</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col10\" class=\"data row1 col10\" >-0.202</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow1_col11\" class=\"data row1 col11\" >-0.391</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row2\" class=\"row_heading level0 row2\" >citric acid</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col0\" class=\"data row2 col0\" >0.672</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col1\" class=\"data row2 col1\" >-0.552</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col2\" class=\"data row2 col2\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col3\" class=\"data row2 col3\" >0.144</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col4\" class=\"data row2 col4\" >0.204</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col5\" class=\"data row2 col5\" >-0.061</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col6\" class=\"data row2 col6\" >0.0355</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col7\" class=\"data row2 col7\" >0.365</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col8\" class=\"data row2 col8\" >-0.542</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col9\" class=\"data row2 col9\" >0.313</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col10\" class=\"data row2 col10\" >0.11</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow2_col11\" class=\"data row2 col11\" >0.226</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row3\" class=\"row_heading level0 row3\" >residual sugar</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col0\" class=\"data row3 col0\" >0.115</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col1\" class=\"data row3 col1\" >0.00192</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col2\" class=\"data row3 col2\" >0.144</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col3\" class=\"data row3 col3\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col4\" class=\"data row3 col4\" >0.0556</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col5\" class=\"data row3 col5\" >0.187</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col6\" class=\"data row3 col6\" >0.203</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col7\" class=\"data row3 col7\" >0.355</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col8\" class=\"data row3 col8\" >-0.0857</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col9\" class=\"data row3 col9\" >0.00553</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col10\" class=\"data row3 col10\" >0.0421</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow3_col11\" class=\"data row3 col11\" >0.0137</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row4\" class=\"row_heading level0 row4\" >chlorides</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col0\" class=\"data row4 col0\" >0.0937</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col1\" class=\"data row4 col1\" >0.0613</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col2\" class=\"data row4 col2\" >0.204</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col3\" class=\"data row4 col3\" >0.0556</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col4\" class=\"data row4 col4\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col5\" class=\"data row4 col5\" >0.00556</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col6\" class=\"data row4 col6\" >0.0474</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col7\" class=\"data row4 col7\" >0.201</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col8\" class=\"data row4 col8\" >-0.265</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col9\" class=\"data row4 col9\" >0.371</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col10\" class=\"data row4 col10\" >-0.221</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow4_col11\" class=\"data row4 col11\" >-0.129</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row5\" class=\"row_heading level0 row5\" >free sulfur dioxide</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col0\" class=\"data row5 col0\" >-0.154</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col1\" class=\"data row5 col1\" >-0.0105</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col2\" class=\"data row5 col2\" >-0.061</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col3\" class=\"data row5 col3\" >0.187</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col4\" class=\"data row5 col4\" >0.00556</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col5\" class=\"data row5 col5\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col6\" class=\"data row5 col6\" >0.668</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col7\" class=\"data row5 col7\" >-0.0219</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col8\" class=\"data row5 col8\" >0.0704</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col9\" class=\"data row5 col9\" >0.0517</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col10\" class=\"data row5 col10\" >-0.0694</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow5_col11\" class=\"data row5 col11\" >-0.0507</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row6\" class=\"row_heading level0 row6\" >total sulfur dioxide</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col0\" class=\"data row6 col0\" >-0.113</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col1\" class=\"data row6 col1\" >0.0765</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col2\" class=\"data row6 col2\" >0.0355</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col3\" class=\"data row6 col3\" >0.203</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col4\" class=\"data row6 col4\" >0.0474</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col5\" class=\"data row6 col5\" >0.668</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col6\" class=\"data row6 col6\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col7\" class=\"data row6 col7\" >0.0713</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col8\" class=\"data row6 col8\" >-0.0665</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col9\" class=\"data row6 col9\" >0.0429</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col10\" class=\"data row6 col10\" >-0.206</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow6_col11\" class=\"data row6 col11\" >-0.185</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row7\" class=\"row_heading level0 row7\" >density</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col0\" class=\"data row7 col0\" >0.668</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col1\" class=\"data row7 col1\" >0.022</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col2\" class=\"data row7 col2\" >0.365</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col3\" class=\"data row7 col3\" >0.355</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col4\" class=\"data row7 col4\" >0.201</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col5\" class=\"data row7 col5\" >-0.0219</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col6\" class=\"data row7 col6\" >0.0713</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col7\" class=\"data row7 col7\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col8\" class=\"data row7 col8\" >-0.342</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col9\" class=\"data row7 col9\" >0.149</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col10\" class=\"data row7 col10\" >-0.496</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow7_col11\" class=\"data row7 col11\" >-0.175</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row8\" class=\"row_heading level0 row8\" >pH</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col0\" class=\"data row8 col0\" >-0.683</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col1\" class=\"data row8 col1\" >0.235</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col2\" class=\"data row8 col2\" >-0.542</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col3\" class=\"data row8 col3\" >-0.0857</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col4\" class=\"data row8 col4\" >-0.265</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col5\" class=\"data row8 col5\" >0.0704</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col6\" class=\"data row8 col6\" >-0.0665</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col7\" class=\"data row8 col7\" >-0.342</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col8\" class=\"data row8 col8\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col9\" class=\"data row8 col9\" >-0.197</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col10\" class=\"data row8 col10\" >0.206</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow8_col11\" class=\"data row8 col11\" >-0.0577</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row9\" class=\"row_heading level0 row9\" >sulphates</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col0\" class=\"data row9 col0\" >0.183</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col1\" class=\"data row9 col1\" >-0.261</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col2\" class=\"data row9 col2\" >0.313</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col3\" class=\"data row9 col3\" >0.00553</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col4\" class=\"data row9 col4\" >0.371</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col5\" class=\"data row9 col5\" >0.0517</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col6\" class=\"data row9 col6\" >0.0429</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col7\" class=\"data row9 col7\" >0.149</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col8\" class=\"data row9 col8\" >-0.197</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col9\" class=\"data row9 col9\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col10\" class=\"data row9 col10\" >0.0936</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow9_col11\" class=\"data row9 col11\" >0.251</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row10\" class=\"row_heading level0 row10\" >alcohol</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col0\" class=\"data row10 col0\" >-0.0617</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col1\" class=\"data row10 col1\" >-0.202</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col2\" class=\"data row10 col2\" >0.11</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col3\" class=\"data row10 col3\" >0.0421</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col4\" class=\"data row10 col4\" >-0.221</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col5\" class=\"data row10 col5\" >-0.0694</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col6\" class=\"data row10 col6\" >-0.206</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col7\" class=\"data row10 col7\" >-0.496</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col8\" class=\"data row10 col8\" >0.206</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col9\" class=\"data row10 col9\" >0.0936</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col10\" class=\"data row10 col10\" >1</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow10_col11\" class=\"data row10 col11\" >0.476</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058clevel0_row11\" class=\"row_heading level0 row11\" >quality</th> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col0\" class=\"data row11 col0\" >0.124</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col1\" class=\"data row11 col1\" >-0.391</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col2\" class=\"data row11 col2\" >0.226</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col3\" class=\"data row11 col3\" >0.0137</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col4\" class=\"data row11 col4\" >-0.129</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col5\" class=\"data row11 col5\" >-0.0507</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col6\" class=\"data row11 col6\" >-0.185</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col7\" class=\"data row11 col7\" >-0.175</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col8\" class=\"data row11 col8\" >-0.0577</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col9\" class=\"data row11 col9\" >0.251</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col10\" class=\"data row11 col10\" >0.476</td> \n",
       "        <td id=\"T_934d21b4_f0ac_11e8_a5ad_5ce0c5fe058crow11_col11\" class=\"data row11 col11\" >1</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x20b71256080>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcorr = red.corr()\n",
    "rcorr.style.background_gradient().set_precision(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Assigning classes</h2>\n",
    "<p>\n",
    "    Assign classes based on quality. Less than 6; 6; better than 6. Because it makes sense considering the distribution of ratings.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    2198\n",
      "1    1640\n",
      "3    1060\n",
      "Name: classnum, dtype: int64\n",
      "1    744\n",
      "2    638\n",
      "3    217\n",
      "Name: classnum, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Assign classes for white\n",
    "conditions = [(white['quality'] < 6),\n",
    "              (white['quality'] > 6)]\n",
    "choices = ['2_low', '1_high']\n",
    "white['class'] = np.select(conditions, choices, default = '3_medium')\n",
    "choices = [1,3]\n",
    "white['classnum'] = np.select(conditions, choices, default = 2)\n",
    "white_classnum = white['classnum']\n",
    "white.drop('classnum',axis=1,inplace=True)\n",
    "#Assign classes for red\n",
    "conditions = [(red['quality'] < 6),\n",
    "              (red['quality'] > 6)]\n",
    "choices = ['3_low', '1_high']\n",
    "red['class'] = np.select(conditions, choices, default = '2_medium')\n",
    "choices = [1,3]\n",
    "red['classnum'] = np.select(conditions, choices, default = 2)\n",
    "red_classnum = red['classnum']\n",
    "red.drop('classnum',axis=1,inplace=True)\n",
    "\n",
    "#print('class distribution fot white:')\n",
    "#print(white['class'].value_counts())\n",
    "#print('\\n class distribution for red:')\n",
    "#print(red['class'].value_counts())\n",
    "\n",
    "white_norm['class']=white['class']\n",
    "red_norm['class']=red['class']\n",
    "\n",
    "white_targetclass = white_classnum\n",
    "red_targetclass = red_classnum\n",
    "print(white_targetclass.value_counts())\n",
    "print(red_targetclass.value_counts())\n",
    "#white_targetclass = white['class']\n",
    "#red_targetclass = red['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_norm_input = white_norm.drop('class', axis = 1)\n",
    "red_norm_input = red_norm.drop('class', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.898000e+03</td>\n",
       "      <td>4.898000e+03</td>\n",
       "      <td>4.898000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.998539e-14</td>\n",
       "      <td>-6.380722e-17</td>\n",
       "      <td>-4.325046e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.966784e+00</td>\n",
       "      <td>-1.958477e+00</td>\n",
       "      <td>-2.043089e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.770318e-01</td>\n",
       "      <td>-7.237012e-01</td>\n",
       "      <td>-8.241915e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.809733e-01</td>\n",
       "      <td>-7.691388e-02</td>\n",
       "      <td>-9.285319e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.142970e-01</td>\n",
       "      <td>6.286722e-01</td>\n",
       "      <td>7.197450e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.152811e+00</td>\n",
       "      <td>1.491679e+01</td>\n",
       "      <td>2.995020e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       volatile acidity  free sulfur dioxide       alcohol\n",
       "count      4.898000e+03         4.898000e+03  4.898000e+03\n",
       "mean      -1.998539e-14        -6.380722e-17 -4.325046e-14\n",
       "std        1.000000e+00         1.000000e+00  1.000000e+00\n",
       "min       -1.966784e+00        -1.958477e+00 -2.043089e+00\n",
       "25%       -6.770318e-01        -7.237012e-01 -8.241915e-01\n",
       "50%       -1.809733e-01        -7.691388e-02 -9.285319e-02\n",
       "75%        4.142970e-01         6.286722e-01  7.197450e-01\n",
       "max        8.152811e+00         1.491679e+01  2.995020e+00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#white_norm.loc[white_norm['class']=='3_high'].describe()\n",
    "#white_norm.loc[white_norm['class']=='2_medium'].describe()\n",
    "#white_norm.loc[white_norm['class']=='1_low'].describe()\n",
    "white_norm_filtered = white_norm_input.drop([fixed_acidity,sulphates,chlorides,citric_acid,ph,density,total_sulfur_dioxide,residual_sugar],axis=1)\n",
    "white_norm_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.599000e+03</td>\n",
       "      <td>1.599000e+03</td>\n",
       "      <td>1.599000e+03</td>\n",
       "      <td>1.599000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.477896e-15</td>\n",
       "      <td>2.365560e-16</td>\n",
       "      <td>6.625737e-15</td>\n",
       "      <td>2.204136e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.277567e+00</td>\n",
       "      <td>-1.230199e+00</td>\n",
       "      <td>-1.935902e+00</td>\n",
       "      <td>-1.898325e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.696903e-01</td>\n",
       "      <td>-7.438076e-01</td>\n",
       "      <td>-6.380200e-01</td>\n",
       "      <td>-8.661079e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.367545e-02</td>\n",
       "      <td>-2.574163e-01</td>\n",
       "      <td>-2.250577e-01</td>\n",
       "      <td>-2.092427e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.264921e-01</td>\n",
       "      <td>4.721707e-01</td>\n",
       "      <td>4.238832e-01</td>\n",
       "      <td>6.352984e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.876138e+00</td>\n",
       "      <td>7.372847e+00</td>\n",
       "      <td>7.916200e+00</td>\n",
       "      <td>4.201138e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       volatile acidity  total sulfur dioxide     sulphates       alcohol\n",
       "count      1.599000e+03          1.599000e+03  1.599000e+03  1.599000e+03\n",
       "mean       8.477896e-15          2.365560e-16  6.625737e-15  2.204136e-14\n",
       "std        1.000000e+00          1.000000e+00  1.000000e+00  1.000000e+00\n",
       "min       -2.277567e+00         -1.230199e+00 -1.935902e+00 -1.898325e+00\n",
       "25%       -7.696903e-01         -7.438076e-01 -6.380200e-01 -8.661079e-01\n",
       "50%       -4.367545e-02         -2.574163e-01 -2.250577e-01 -2.092427e-01\n",
       "75%        6.264921e-01          4.721707e-01  4.238832e-01  6.352984e-01\n",
       "max        5.876138e+00          7.372847e+00  7.916200e+00  4.201138e+00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#red_norm.loc[red_norm['class']=='3_high'].describe()\n",
    "#red_norm.loc[red_norm['class']=='2_medium'].describe()\n",
    "#red_norm.loc[red_norm['class']=='1_low'].describe()\n",
    "red_norm_filtered = red_norm_input.drop([free_sulfur_dioxide,ph,residual_sugar,chlorides,citric_acid,fixed_acidity,density],axis=1)\n",
    "red_norm_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>k-NN classification<h2><p>https://scikit-learn.org/stable/tutorial/statistical_inference/supervised_learning.html#the-curse-of-dimensionality</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>white: normalized and selected for attributes with low std/range</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   419   101\n",
      "    2  420  1444   334\n",
      "    3   84   326   650\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.69      1640\n",
      "          2       0.66      0.66      0.66      2198\n",
      "          3       0.60      0.61      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "1.1171662512042362\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1310   286    44\n",
      "    2  799  1243   156\n",
      "    3  197   484   379\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.80      0.66      1640\n",
      "          2       0.62      0.57      0.59      2198\n",
      "          3       0.65      0.36      0.46      1060\n",
      "\n",
      "avg / total       0.61      0.60      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.721964788885416\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   532    86\n",
      "    2  620  1236   342\n",
      "    3  160   377   523\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.62      0.59      1640\n",
      "          2       0.58      0.56      0.57      2198\n",
      "          3       0.55      0.49      0.52      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9641385206360522\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   415    63\n",
      "    2  704  1245   249\n",
      "    3  121   521   418\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.71      0.64      1640\n",
      "          2       0.57      0.57      0.57      2198\n",
      "          3       0.57      0.39      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.8432713525976573\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1031   545    64\n",
      "    2  606  1267   325\n",
      "    3  126   462   472\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.63      0.61      1640\n",
      "          2       0.56      0.58      0.57      2198\n",
      "          3       0.55      0.45      0.49      1060\n",
      "\n",
      "avg / total       0.56      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9523133811024962\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1107   467    66\n",
      "    2  678  1237   283\n",
      "    3  125   530   405\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.68      0.62      1640\n",
      "          2       0.55      0.56      0.56      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.8601708168835119\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   569    66\n",
      "    2  568  1305   325\n",
      "    3   84   522   454\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.61      0.61      1640\n",
      "          2       0.54      0.59      0.57      2198\n",
      "          3       0.54      0.43      0.48      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9695233365959609\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1066   522    52\n",
      "    2  624  1287   287\n",
      "    3   89   569   402\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.65      0.62      1640\n",
      "          2       0.54      0.59      0.56      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9039182435919786\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1011   570    59\n",
      "    2  578  1291   329\n",
      "    3   75   549   436\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.62      0.61      1640\n",
      "          2       0.54      0.59      0.56      2198\n",
      "          3       0.53      0.41      0.46      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9576580935237095\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1046   542    52\n",
      "    2  599  1300   299\n",
      "    3   68   577   415\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.64      0.62      1640\n",
      "          2       0.54      0.59      0.56      2198\n",
      "          3       0.54      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9309566465009812\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  998   595    47\n",
      "    2  553  1333   312\n",
      "    3   64   566   430\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.61      1640\n",
      "          2       0.53      0.61      0.57      2198\n",
      "          3       0.54      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9722570592707238\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1050   547    43\n",
      "    2  582  1308   308\n",
      "    3   68   585   407\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.54      0.60      0.56      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.939362006891823\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1007   585    48\n",
      "    2  534  1345   319\n",
      "    3   62   578   420\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.61      0.62      1640\n",
      "          2       0.54      0.61      0.57      2198\n",
      "          3       0.53      0.40      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9766569089726534\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1047   543    50\n",
      "    2  560  1345   293\n",
      "    3   62   587   411\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.64      0.63      1640\n",
      "          2       0.54      0.61      0.58      2198\n",
      "          3       0.55      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9504893326160504\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1010   583    47\n",
      "    2  523  1376   299\n",
      "    3   67   577   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.62      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9777015738439504\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   566    45\n",
      "    2  535  1382   281\n",
      "    3   62   601   397\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.37      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9586169770972626\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   578    40\n",
      "    2  532  1388   278\n",
      "    3   64   594   402\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.56      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9646677727594796\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1037   565    38\n",
      "    2  549  1383   266\n",
      "    3   61   600   399\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.57      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9520989685407102\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1019   582    39\n",
      "    2  526  1397   275\n",
      "    3   60   596   404\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.54      0.64      0.59      2198\n",
      "          3       0.56      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9696286222928121\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1037   569    34\n",
      "    2  530  1410   258\n",
      "    3   67   597   396\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.55      0.64      0.59      2198\n",
      "          3       0.58      0.37      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.960425589615904\n"
     ]
    }
   ],
   "source": [
    "def run_knn_report(inputs, targets):\n",
    "    print(\"_______________________________________________________________________________________________\")\n",
    "    print(\"KNN, no weights\")\n",
    "    for n_neighbour in range(1,21):\n",
    "        print(str(n_neighbour) + \" neighbours:\")\n",
    "        knn_estimator = KNeighborsClassifier(n_neighbour)\n",
    "        print(str(n_neighbour)+ \" neighbours//\")\n",
    "        predicted = cross_val_predict(knn_estimator,inputs,targets,cv=cv)\n",
    "        print(confusion_matrix_report(targets,predicted))\n",
    "        print(classification_report(targets,predicted))\n",
    "        try:\n",
    "            print(\"RMSE:\")\n",
    "            print(root_mean_squared_error(targets,predicted))\n",
    "        except(Error):\n",
    "            pass\n",
    "    \n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=1337)\n",
    "#cv = KFold(n_splits=3)\n",
    "run_knn_report(white_norm_filtered.values, white_targetclass)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i>red: </i>normalized and selected for attributes with low std/range</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   165    12\n",
      "    2  147   417    74\n",
      "    3   18    69   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.77       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.60      0.60      0.60       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1796163292264188\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  641   100     3\n",
      "    2  288   322    28\n",
      "    3   36   121    60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.86      0.75       744\n",
      "          2       0.59      0.50      0.55       638\n",
      "          3       0.66      0.28      0.39       217\n",
      "\n",
      "avg / total       0.64      0.64      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.8138113605631304\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  556   172    16\n",
      "    2  224   335    79\n",
      "    3   39    95    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.56      0.53      0.54       638\n",
      "          3       0.47      0.38      0.42       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.9965544141880932\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   121    13\n",
      "    2  247   341    50\n",
      "    3   23   118    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.82      0.75       744\n",
      "          2       0.59      0.53      0.56       638\n",
      "          3       0.55      0.35      0.43       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.9289991386566328\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   167     8\n",
      "    2  214   361    63\n",
      "    3   24   107    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.76      0.73       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.55      0.40      0.46       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "1.019816167568828\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   135     6\n",
      "    2  248   336    54\n",
      "    3   25   121    71\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.81      0.74       744\n",
      "          2       0.57      0.53      0.55       638\n",
      "          3       0.54      0.33      0.41       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.9289991386566328\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   162     9\n",
      "    2  214   366    58\n",
      "    3   26   109    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.77      0.74       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.55      0.38      0.45       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "1.0093372707270842\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   138     6\n",
      "    2  236   351    51\n",
      "    3   24   122    71\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.81      0.75       744\n",
      "          2       0.57      0.55      0.56       638\n",
      "          3       0.55      0.33      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.9493093503445846\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   162     7\n",
      "    2  218   366    54\n",
      "    3   27   110    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.77      0.74       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.57      0.37      0.45       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.9996872556608425\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   145     5\n",
      "    2  223   365    50\n",
      "    3   25   117    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.58      0.57      0.58       638\n",
      "          3       0.58      0.35      0.43       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9791446280436009\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   166     7\n",
      "    2  211   375    52\n",
      "    3   25   112    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.58      0.37      0.45       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0118126570828938\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   139     7\n",
      "    2  223   362    53\n",
      "    3   23   119    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.58      0.57      0.58       638\n",
      "          3       0.56      0.35      0.43       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9775465453267047\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  578   159     7\n",
      "    2  204   385    49\n",
      "    3   24   112    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.78      0.75       744\n",
      "          2       0.59      0.60      0.60       638\n",
      "          3       0.59      0.37      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "1.0213481140048375\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   135     9\n",
      "    2  218   370    50\n",
      "    3   22   122    73\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.81      0.76       744\n",
      "          2       0.59      0.58      0.58       638\n",
      "          3       0.55      0.34      0.42       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9791446280436009\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   161     8\n",
      "    2  212   378    48\n",
      "    3   23   115    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.58      0.59      0.59       638\n",
      "          3       0.59      0.36      0.45       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0059236683350148\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   153     6\n",
      "    2  218   375    45\n",
      "    3   23   117    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.58      0.59      0.58       638\n",
      "          3       0.60      0.35      0.45       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9912058593752295\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   176     9\n",
      "    2  209   387    42\n",
      "    3   20   117    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.75      0.73       744\n",
      "          2       0.57      0.61      0.59       638\n",
      "          3       0.61      0.37      0.46       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0152064581135072\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   160     9\n",
      "    2  221   374    43\n",
      "    3   19   116    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.58      0.59      0.58       638\n",
      "          3       0.61      0.38      0.47       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9952985165067817\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   173     8\n",
      "    2  210   386    42\n",
      "    3   19   118    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.76      0.73       744\n",
      "          2       0.57      0.61      0.59       638\n",
      "          3       0.62      0.37      0.46       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0136652298707427\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  570   166     8\n",
      "    2  213   384    41\n",
      "    3   19   117    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.58      0.60      0.59       638\n",
      "          3       0.62      0.37      0.47       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0080972981818899\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(red_norm_filtered.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>white: normalized unselected</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   416    68\n",
      "    2  381  1538   279\n",
      "    3   59   276   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.70      0.71      1640\n",
      "          2       0.69      0.70      0.69      2198\n",
      "          3       0.68      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.170970497878053\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1308   303    29\n",
      "    2  735  1331   132\n",
      "    3  132   445   483\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.80      0.69      1640\n",
      "          2       0.64      0.61      0.62      2198\n",
      "          3       0.75      0.46      0.57      1060\n",
      "\n",
      "avg / total       0.65      0.64      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.8430292071934984\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1091   478    71\n",
      "    2  556  1342   300\n",
      "    3  110   352   598\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.67      0.64      1640\n",
      "          2       0.62      0.61      0.61      2198\n",
      "          3       0.62      0.56      0.59      1060\n",
      "\n",
      "avg / total       0.62      0.62      0.62      4898\n",
      "\n",
      "RMSE:\n",
      "1.033533307836527\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1168   406    66\n",
      "    2  667  1305   226\n",
      "    3   90   458   512\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.71      0.66      1640\n",
      "          2       0.60      0.59      0.60      2198\n",
      "          3       0.64      0.48      0.55      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.9183710968998697\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1062   517    61\n",
      "    2  561  1371   266\n",
      "    3   99   396   565\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.65      0.63      1640\n",
      "          2       0.60      0.62      0.61      2198\n",
      "          3       0.63      0.53      0.58      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "1.0182090619084825\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1141   433    66\n",
      "    2  647  1311   240\n",
      "    3   94   434   532\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.70      0.65      1640\n",
      "          2       0.60      0.60      0.60      2198\n",
      "          3       0.63      0.50      0.56      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.9443476946523792\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1040   532    68\n",
      "    2  555  1360   283\n",
      "    3   65   434   561\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.58      0.62      0.60      2198\n",
      "          3       0.62      0.53      0.57      1060\n",
      "\n",
      "avg / total       0.61      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0244061311807213\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1106   474    60\n",
      "    2  615  1332   251\n",
      "    3   68   481   511\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.67      0.65      1640\n",
      "          2       0.58      0.61      0.59      2198\n",
      "          3       0.62      0.48      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.9598939985032707\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1063   510    67\n",
      "    2  558  1337   303\n",
      "    3   66   446   548\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.65      0.64      1640\n",
      "          2       0.58      0.61      0.60      2198\n",
      "          3       0.60      0.52      0.55      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0163023956539732\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1097   482    61\n",
      "    2  569  1353   276\n",
      "    3   57   490   513\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.67      0.65      1640\n",
      "          2       0.58      0.62      0.60      2198\n",
      "          3       0.60      0.48      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.9894296380111769\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1057   519    64\n",
      "    2  534  1375   289\n",
      "    3   56   472   532\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.58      0.63      0.60      2198\n",
      "          3       0.60      0.50      0.55      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0214122442196856\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1076   497    67\n",
      "    2  541  1367   290\n",
      "    3   59   484   517\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.66      0.65      1640\n",
      "          2       0.58      0.62      0.60      2198\n",
      "          3       0.59      0.49      0.53      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.007323124673022\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1042   529    69\n",
      "    2  528  1382   288\n",
      "    3   58   479   523\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.58      0.63      0.60      2198\n",
      "          3       0.59      0.49      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0196116923940406\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1067   511    62\n",
      "    2  543  1369   286\n",
      "    3   64   496   500\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.65      0.64      1640\n",
      "          2       0.58      0.62      0.60      2198\n",
      "          3       0.59      0.47      0.52      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.9991830063995606\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1053   527    60\n",
      "    2  524  1386   288\n",
      "    3   65   478   517\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.58      0.63      0.60      2198\n",
      "          3       0.60      0.49      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0195115684980467\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1054   521    65\n",
      "    2  524  1387   287\n",
      "    3   57   497   506\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.58      0.63      0.60      2198\n",
      "          3       0.59      0.48      0.53      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0130830570701803\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1027   551    62\n",
      "    2  513  1407   278\n",
      "    3   60   488   512\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.63      1640\n",
      "          2       0.58      0.64      0.61      2198\n",
      "          3       0.60      0.48      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0240074519941178\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1050   528    62\n",
      "    2  520  1399   279\n",
      "    3   59   508   493\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.57      0.64      0.60      2198\n",
      "          3       0.59      0.47      0.52      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0088420847587596\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1032   551    57\n",
      "    2  505  1412   281\n",
      "    3   56   507   497\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.63      0.64      1640\n",
      "          2       0.57      0.64      0.60      2198\n",
      "          3       0.60      0.47      0.52      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.0222114714501254\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1039   548    53\n",
      "    2  514  1406   278\n",
      "    3   60   506   494\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.64      1640\n",
      "          2       0.57      0.64      0.60      2198\n",
      "          3       0.60      0.47      0.52      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "1.016001016001524\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(white_norm_input.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i>red: </i> normalized unselected</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554   166    24\n",
      "    2  158   412    68\n",
      "    3   21    61   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.74      0.75       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.59      0.62      0.61       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1630651100782905\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  627   109     8\n",
      "    2  286   316    36\n",
      "    3   39   105    73\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.84      0.74       744\n",
      "          2       0.60      0.50      0.54       638\n",
      "          3       0.62      0.34      0.44       217\n",
      "\n",
      "avg / total       0.63      0.64      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.8436200621463342\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  534   195    15\n",
      "    2  216   358    64\n",
      "    3   38    70   109\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.72      0.70       744\n",
      "          2       0.57      0.56      0.57       638\n",
      "          3       0.58      0.50      0.54       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "1.0518157860480428\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  579   151    14\n",
      "    2  232   346    60\n",
      "    3   27   103    87\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.78      0.73       744\n",
      "          2       0.58      0.54      0.56       638\n",
      "          3       0.54      0.40      0.46       217\n",
      "\n",
      "avg / total       0.62      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.9826512617347357\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  512   218    14\n",
      "    2  211   361    66\n",
      "    3   36    92    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.69      0.68       744\n",
      "          2       0.54      0.57      0.55       638\n",
      "          3       0.53      0.41      0.46       217\n",
      "\n",
      "avg / total       0.60      0.60      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "1.0380503204529008\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  556   167    21\n",
      "    2  242   334    62\n",
      "    3   31   105    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.75      0.71       744\n",
      "          2       0.55      0.52      0.54       638\n",
      "          3       0.49      0.37      0.43       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.9568553875301133\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  519   204    21\n",
      "    2  204   364    70\n",
      "    3   27    97    93\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.70      0.69       744\n",
      "          2       0.55      0.57      0.56       638\n",
      "          3       0.51      0.43      0.46       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "1.0500305245868344\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   174    19\n",
      "    2  232   344    62\n",
      "    3   30   105    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.74      0.71       744\n",
      "          2       0.55      0.54      0.55       638\n",
      "          3       0.50      0.38      0.43       217\n",
      "\n",
      "avg / total       0.60      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9785057081530261\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  524   200    20\n",
      "    2  218   352    68\n",
      "    3   28    97    92\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.70      0.69       744\n",
      "          2       0.54      0.55      0.55       638\n",
      "          3       0.51      0.42      0.46       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "1.0259302281445057\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  562   163    19\n",
      "    2  231   340    67\n",
      "    3   27   101    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.72       744\n",
      "          2       0.56      0.53      0.55       638\n",
      "          3       0.51      0.41      0.45       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.990258997965637\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  532   196    16\n",
      "    2  217   352    69\n",
      "    3   27    96    94\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.72      0.70       744\n",
      "          2       0.55      0.55      0.55       638\n",
      "          3       0.53      0.43      0.47       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "1.0323110196427225\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   165    19\n",
      "    2  235   332    71\n",
      "    3   24   104    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.72       744\n",
      "          2       0.55      0.52      0.54       638\n",
      "          3       0.50      0.41      0.45       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9867793996074711\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  538   187    19\n",
      "    2  214   360    64\n",
      "    3   22    94   101\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.72      0.71       744\n",
      "          2       0.56      0.56      0.56       638\n",
      "          3       0.55      0.47      0.50       217\n",
      "\n",
      "avg / total       0.62      0.62      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "1.0428589174481193\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  557   170    17\n",
      "    2  229   350    59\n",
      "    3   23    98    96\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.55      0.56       638\n",
      "          3       0.56      0.44      0.49       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "1.0065451844081117\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   176    17\n",
      "    2  223   349    66\n",
      "    3   23    99    95\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.74      0.72       744\n",
      "          2       0.56      0.55      0.55       638\n",
      "          3       0.53      0.44      0.48       217\n",
      "\n",
      "avg / total       0.62      0.62      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "1.0182819164103354\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   173    16\n",
      "    2  233   345    60\n",
      "    3   22   107    88\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.71       744\n",
      "          2       0.55      0.54      0.55       638\n",
      "          3       0.54      0.41      0.46       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9899431762392294\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  540   190    14\n",
      "    2  227   354    57\n",
      "    3   23   106    88\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.73      0.70       744\n",
      "          2       0.54      0.55      0.55       638\n",
      "          3       0.55      0.41      0.47       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "1.0046794827403414\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553   177    14\n",
      "    2  231   347    60\n",
      "    3   22   105    90\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.74      0.71       744\n",
      "          2       0.55      0.54      0.55       638\n",
      "          3       0.55      0.41      0.47       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9987484350540063\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  546   184    14\n",
      "    2  224   360    54\n",
      "    3   19   116    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.73      0.71       744\n",
      "          2       0.55      0.56      0.55       638\n",
      "          3       0.55      0.38      0.45       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9984352986816589\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   180    13\n",
      "    2  221   356    61\n",
      "    3   18   119    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.54      0.56      0.55       638\n",
      "          3       0.52      0.37      0.43       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "1.001874415890415\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(red_norm_input.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> white: unfiltered, unnormalized <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1052   450   138\n",
      "    2  437  1435   326\n",
      "    3  107   325   628\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.64      0.65      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.58      0.59      0.58      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "1.0923095061227794\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1234   345    61\n",
      "    2  856  1200   142\n",
      "    3  265   467   328\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.75      0.62      1640\n",
      "          2       0.60      0.55      0.57      2198\n",
      "          3       0.62      0.31      0.41      1060\n",
      "\n",
      "avg / total       0.58      0.56      0.55      4898\n",
      "\n",
      "RMSE:\n",
      "0.6319388199114419\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  949   555   136\n",
      "    2  642  1238   318\n",
      "    3  209   376   475\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.58      0.55      1640\n",
      "          2       0.57      0.56      0.57      2198\n",
      "          3       0.51      0.45      0.48      1060\n",
      "\n",
      "avg / total       0.54      0.54      0.54      4898\n",
      "\n",
      "RMSE:\n",
      "0.9096596090452171\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1034   486   120\n",
      "    2  716  1212   270\n",
      "    3  175   493   392\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.63      0.58      1640\n",
      "          2       0.55      0.55      0.55      2198\n",
      "          3       0.50      0.37      0.43      1060\n",
      "\n",
      "avg / total       0.54      0.54      0.53      4898\n",
      "\n",
      "RMSE:\n",
      "0.8104311774260798\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  927   607   106\n",
      "    2  642  1290   266\n",
      "    3  192   457   411\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.57      0.55      1640\n",
      "          2       0.55      0.59      0.57      2198\n",
      "          3       0.52      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.54      0.54      0.53      4898\n",
      "\n",
      "RMSE:\n",
      "0.8819685469235011\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  994   530   116\n",
      "    2  716  1216   266\n",
      "    3  202   470   388\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.61      0.56      1640\n",
      "          2       0.55      0.55      0.55      2198\n",
      "          3       0.50      0.37      0.42      1060\n",
      "\n",
      "avg / total       0.53      0.53      0.53      4898\n",
      "\n",
      "RMSE:\n",
      "0.8105571283441495\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  886   638   116\n",
      "    2  621  1296   281\n",
      "    3  178   494   388\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.54      0.53      1640\n",
      "          2       0.53      0.59      0.56      2198\n",
      "          3       0.49      0.37      0.42      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.52      4898\n",
      "\n",
      "RMSE:\n",
      "0.8854340555462675\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  947   585   108\n",
      "    2  668  1275   255\n",
      "    3  199   522   339\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.58      0.55      1640\n",
      "          2       0.54      0.58      0.56      2198\n",
      "          3       0.48      0.32      0.38      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.52      4898\n",
      "\n",
      "RMSE:\n",
      "0.8178290935742306\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  881   635   124\n",
      "    2  621  1307   270\n",
      "    3  198   509   353\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.54      0.53      1640\n",
      "          2       0.53      0.59      0.56      2198\n",
      "          3       0.47      0.33      0.39      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8591020600198911\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  920   607   113\n",
      "    2  643  1294   261\n",
      "    3  189   535   336\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.56      0.54      1640\n",
      "          2       0.53      0.59      0.56      2198\n",
      "          3       0.47      0.32      0.38      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.834876752285472\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  862   668   110\n",
      "    2  618  1313   267\n",
      "    3  190   551   319\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.53      0.52      1640\n",
      "          2       0.52      0.60      0.56      2198\n",
      "          3       0.46      0.30      0.36      1060\n",
      "\n",
      "avg / total       0.50      0.51      0.50      4898\n",
      "\n",
      "RMSE:\n",
      "0.8484607637477626\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  912   620   108\n",
      "    2  628  1307   263\n",
      "    3  183   555   322\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.56      0.54      1640\n",
      "          2       0.53      0.59      0.56      2198\n",
      "          3       0.46      0.30      0.37      1060\n",
      "\n",
      "avg / total       0.51      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8392670196410961\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  849   676   115\n",
      "    2  598  1334   266\n",
      "    3  176   584   300\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.52      0.52      1640\n",
      "          2       0.51      0.61      0.56      2198\n",
      "          3       0.44      0.28      0.34      1060\n",
      "\n",
      "avg / total       0.50      0.51      0.50      4898\n",
      "\n",
      "RMSE:\n",
      "0.8503836234689071\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  885   653   102\n",
      "    2  638  1287   273\n",
      "    3  184   590   286\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.54      0.53      1640\n",
      "          2       0.51      0.59      0.54      2198\n",
      "          3       0.43      0.27      0.33      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8175794128804025\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  844   692   104\n",
      "    2  620  1308   270\n",
      "    3  189   591   280\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.51      0.51      1640\n",
      "          2       0.50      0.60      0.55      2198\n",
      "          3       0.43      0.26      0.33      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8283709605884695\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  866   674   100\n",
      "    2  623  1312   263\n",
      "    3  189   585   286\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.53      0.52      1640\n",
      "          2       0.51      0.60      0.55      2198\n",
      "          3       0.44      0.27      0.33      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8281244582885352\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  833   703   104\n",
      "    2  610  1346   242\n",
      "    3  193   593   274\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.51      0.51      1640\n",
      "          2       0.51      0.61      0.56      2198\n",
      "          3       0.44      0.26      0.33      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.828247718608975\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  834   708    98\n",
      "    2  620  1338   240\n",
      "    3  197   594   269\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.51      0.51      1640\n",
      "          2       0.51      0.61      0.55      2198\n",
      "          3       0.44      0.25      0.32      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.820321720791475\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  831   717    92\n",
      "    2  615  1348   235\n",
      "    3  196   611   253\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.51      0.51      1640\n",
      "          2       0.50      0.61      0.55      2198\n",
      "          3       0.44      0.24      0.31      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.48      4898\n",
      "\n",
      "RMSE:\n",
      "0.815579215601521\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  852   701    87\n",
      "    2  632  1339   227\n",
      "    3  195   600   265\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.52      0.51      1640\n",
      "          2       0.51      0.61      0.55      2198\n",
      "          3       0.46      0.25      0.32      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.810808971484713\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(white_input.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>red, unnormalized, unselected</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  518   188    38\n",
      "    2  181   398    59\n",
      "    3   28    75   114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.70      0.70       744\n",
      "          2       0.60      0.62      0.61       638\n",
      "          3       0.54      0.53      0.53       217\n",
      "\n",
      "avg / total       0.65      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0960729263659628\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   128    11\n",
      "    2  353   257    28\n",
      "    3   62    95    60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.81      0.69       744\n",
      "          2       0.54      0.40      0.46       638\n",
      "          3       0.61      0.28      0.38       217\n",
      "\n",
      "avg / total       0.57      0.58      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.6710301229387411\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  528   194    22\n",
      "    2  289   295    54\n",
      "    3   55    79    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.71      0.65       744\n",
      "          2       0.52      0.46      0.49       638\n",
      "          3       0.52      0.38      0.44       217\n",
      "\n",
      "avg / total       0.56      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.8777707849828199\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   154    17\n",
      "    2  319   263    56\n",
      "    3   48   103    66\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.77      0.68       744\n",
      "          2       0.51      0.41      0.45       638\n",
      "          3       0.47      0.30      0.37       217\n",
      "\n",
      "avg / total       0.55      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7812691523606119\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  518   206    20\n",
      "    2  296   292    50\n",
      "    3   55    98    64\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.70      0.64       744\n",
      "          2       0.49      0.46      0.47       638\n",
      "          3       0.48      0.29      0.36       217\n",
      "\n",
      "avg / total       0.54      0.55      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.8346768406950953\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   152    23\n",
      "    2  333   255    50\n",
      "    3   63    88    66\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.76      0.67       744\n",
      "          2       0.52      0.40      0.45       638\n",
      "          3       0.47      0.30      0.37       217\n",
      "\n",
      "avg / total       0.54      0.56      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.7380484043438286\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  518   203    23\n",
      "    2  308   284    46\n",
      "    3   58   100    59\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.70      0.64       744\n",
      "          2       0.48      0.45      0.46       638\n",
      "          3       0.46      0.27      0.34       217\n",
      "\n",
      "avg / total       0.53      0.54      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.7959402933600744\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   170    14\n",
      "    2  318   283    37\n",
      "    3   66   104    47\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.75      0.66       744\n",
      "          2       0.51      0.44      0.47       638\n",
      "          3       0.48      0.22      0.30       217\n",
      "\n",
      "avg / total       0.54      0.56      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.7380484043438286\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  513   216    15\n",
      "    2  306   292    40\n",
      "    3   64   108    45\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.69      0.63       744\n",
      "          2       0.47      0.46      0.47       638\n",
      "          3       0.45      0.21      0.28       217\n",
      "\n",
      "avg / total       0.52      0.53      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.7788640081647817\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  543   190    11\n",
      "    2  322   278    38\n",
      "    3   61   116    40\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.73      0.65       744\n",
      "          2       0.48      0.44      0.45       638\n",
      "          3       0.45      0.18      0.26       217\n",
      "\n",
      "avg / total       0.52      0.54      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.7282385990598998\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  512   221    11\n",
      "    2  309   293    36\n",
      "    3   65   119    33\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.69      0.63       744\n",
      "          2       0.46      0.46      0.46       638\n",
      "          3       0.41      0.15      0.22       217\n",
      "\n",
      "avg / total       0.51      0.52      0.51      1599\n",
      "\n",
      "RMSE:\n",
      "0.7514838354694381\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  529   204    11\n",
      "    2  318   285    35\n",
      "    3   67   116    34\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.71      0.64       744\n",
      "          2       0.47      0.45      0.46       638\n",
      "          3       0.42      0.16      0.23       217\n",
      "\n",
      "avg / total       0.51      0.53      0.51      1599\n",
      "\n",
      "RMSE:\n",
      "0.7260884951672619\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  518   215    11\n",
      "    2  302   300    36\n",
      "    3   61   121    35\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.70      0.64       744\n",
      "          2       0.47      0.47      0.47       638\n",
      "          3       0.43      0.16      0.23       217\n",
      "\n",
      "avg / total       0.52      0.53      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.7691682276013938\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  537   196    11\n",
      "    2  329   282    27\n",
      "    3   65   119    33\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.72      0.64       744\n",
      "          2       0.47      0.44      0.46       638\n",
      "          3       0.46      0.15      0.23       217\n",
      "\n",
      "avg / total       0.52      0.53      0.51      1599\n",
      "\n",
      "RMSE:\n",
      "0.6934879800591746\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  540   192    12\n",
      "    2  325   283    30\n",
      "    3   66   120    31\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.73      0.64       744\n",
      "          2       0.48      0.44      0.46       638\n",
      "          3       0.42      0.14      0.21       217\n",
      "\n",
      "avg / total       0.52      0.53      0.51      1599\n",
      "\n",
      "RMSE:\n",
      "0.6961881381511136\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  544   187    13\n",
      "    2  328   280    30\n",
      "    3   65   117    35\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.73      0.65       744\n",
      "          2       0.48      0.44      0.46       638\n",
      "          3       0.45      0.16      0.24       217\n",
      "\n",
      "avg / total       0.52      0.54      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.6957388395317747\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  531   202    11\n",
      "    2  336   280    22\n",
      "    3   67   120    30\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.71      0.63       744\n",
      "          2       0.47      0.44      0.45       638\n",
      "          3       0.48      0.14      0.21       217\n",
      "\n",
      "avg / total       0.51      0.53      0.50      1599\n",
      "\n",
      "RMSE:\n",
      "0.6700974885437159\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   179    10\n",
      "    2  335   281    22\n",
      "    3   68   117    32\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.75      0.65       744\n",
      "          2       0.49      0.44      0.46       638\n",
      "          3       0.50      0.15      0.23       217\n",
      "\n",
      "avg / total       0.53      0.54      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.6668229960548318\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   195     8\n",
      "    2  330   283    25\n",
      "    3   64   117    36\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.73      0.64       744\n",
      "          2       0.48      0.44      0.46       638\n",
      "          3       0.52      0.17      0.25       217\n",
      "\n",
      "avg / total       0.53      0.54      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.6997721419552656\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554   181     9\n",
      "    2  324   290    24\n",
      "    3   70   113    34\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.74      0.65       744\n",
      "          2       0.50      0.45      0.47       638\n",
      "          3       0.51      0.16      0.24       217\n",
      "\n",
      "avg / total       0.54      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.6984302957695782\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(red_input.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knc_report(inputs, targets):\n",
    "    knc_estimator = NearestCentroid()\n",
    "    predicted = cross_val_predict(knc_estimator,inputs,targets,cv=cv)\n",
    "    print(confusion_matrix_report(targets,predicted))\n",
    "    print(classification_report(targets,predicted))\n",
    "    try:\n",
    "        print(\"RMSE:\")\n",
    "        print(root_mean_squared_error(targets,predicted))\n",
    "    except(Error):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   266   293\n",
      "    2  785   537   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9783278373268796\n"
     ]
    }
   ],
   "source": [
    "run_knc_report(white_norm_input.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   145    58\n",
      "    2  217   220   201\n",
      "    3   11    43   163\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.72       744\n",
      "          2       0.54      0.34      0.42       638\n",
      "          3       0.39      0.75      0.51       217\n",
      "\n",
      "avg / total       0.59      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "1.1355861801214393\n"
     ]
    }
   ],
   "source": [
    "run_knc_report(red_norm_input.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kncs_report(inputs, targets,thresh=0):\n",
    "    knc_estimator = NearestCentroid(shrink_threshold=thresh)\n",
    "    predicted = cross_val_predict(knc_estimator,inputs,targets,cv=cv)\n",
    "    print(confusion_matrix_report(targets,predicted))\n",
    "    print(classification_report(targets,predicted))\n",
    "    try:\n",
    "        print(\"RMSE:\")\n",
    "        print(root_mean_squared_error(targets,predicted))\n",
    "    except(Error):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   266   293\n",
      "    2  785   537   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9783278373268796\n"
     ]
    }
   ],
   "source": [
    "run_kncs_report(white_norm_input.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   266   293\n",
      "    2  785   537   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9783278373268796\n",
      "0.001\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   266   293\n",
      "    2  785   537   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9783278373268796\n",
      "0.002\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   266   293\n",
      "    2  785   537   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9783278373268796\n",
      "0.003\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   266   293\n",
      "    2  785   537   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9783278373268796\n",
      "0.004\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   266   293\n",
      "    2  786   536   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9778059789458384\n",
      "0.005\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   266   293\n",
      "    2  786   536   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9778059789458384\n",
      "0.006\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   267   292\n",
      "    2  786   536   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9781191273858749\n",
      "0.007\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   267   292\n",
      "    2  786   536   876\n",
      "    3  139   181   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9781191273858749\n",
      "0.008\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1082   266   292\n",
      "    2  786   536   876\n",
      "    3  139   180   741\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9785365027525919\n",
      "0.009\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1082   266   292\n",
      "    2  786   536   876\n",
      "    3  139   180   741\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.9785365027525919\n"
     ]
    }
   ],
   "source": [
    "for t in range (0,1000,100):\n",
    "    t = t/100000\n",
    "    print(t)\n",
    "    run_kncs_report(white_norm_input.values,white_targetclass,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knnw_report(inputs, targets):\n",
    "    print(\"_______________________________________________________________________________________________\")\n",
    "    print(\"KNN with inverse distance as weight:\")\n",
    "    for n_neighbour in range(1,21):\n",
    "        print(str(n_neighbour) + \" neighbours:\")\n",
    "        knn_estimator = KNeighborsClassifier(n_neighbour,weights='distance')\n",
    "        print(str(n_neighbour)+ \" neighbours//\")\n",
    "        predicted = cross_val_predict(knn_estimator,inputs,targets,cv=cv)\n",
    "        print(confusion_matrix_report(targets,predicted))\n",
    "        print(classification_report(targets,predicted))\n",
    "        try:\n",
    "            print(\"RMSE:\")\n",
    "            print(root_mean_squared_error(targets,predicted))\n",
    "        except(Error):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   416    68\n",
      "    2  381  1538   279\n",
      "    3   59   276   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.70      0.71      1640\n",
      "          2       0.69      0.70      0.69      2198\n",
      "          3       0.68      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.170970497878053\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   416    68\n",
      "    2  381  1538   279\n",
      "    3   59   276   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.70      0.71      1640\n",
      "          2       0.69      0.70      0.69      2198\n",
      "          3       0.68      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.170970497878053\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1169   403    68\n",
      "    2  359  1566   273\n",
      "    3   51   291   718\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.73      1640\n",
      "          2       0.69      0.71      0.70      2198\n",
      "          3       0.68      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.70      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1765366397522268\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1169   408    63\n",
      "    2  352  1591   255\n",
      "    3   48   298   714\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.69      0.72      0.71      2198\n",
      "          3       0.69      0.67      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1778373992868627\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1174   400    66\n",
      "    2  353  1595   250\n",
      "    3   49   294   717\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.72      0.73      1640\n",
      "          2       0.70      0.73      0.71      2198\n",
      "          3       0.69      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1769703859935987\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1172   405    63\n",
      "    2  359  1590   249\n",
      "    3   40   299   721\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.69      0.72      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.17775072667927\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1171   411    58\n",
      "    2  363  1582   253\n",
      "    3   42   309   709\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.73      1640\n",
      "          2       0.69      0.72      0.70      2198\n",
      "          3       0.70      0.67      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.172364510869144\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1173   409    58\n",
      "    2  352  1604   242\n",
      "    3   34   315   711\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.72      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.70      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1775773623261296\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1183   399    58\n",
      "    2  353  1600   245\n",
      "    3   32   314   714\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.72      0.74      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.70      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1780107253711336\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   407    49\n",
      "    2  341  1623   234\n",
      "    3   32   312   716\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.72      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1853536565680474\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1178   408    54\n",
      "    2  329  1635   234\n",
      "    3   32   306   722\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.70      0.74      0.72      2198\n",
      "          3       0.71      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1923089588390623\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1179   409    52\n",
      "    2  320  1641   237\n",
      "    3   35   308   717\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.70      0.75      0.72      2198\n",
      "          3       0.71      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1944474778993792\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1180   407    53\n",
      "    2  329  1644   225\n",
      "    3   37   303   720\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.70      0.75      0.72      2198\n",
      "          3       0.72      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.190338128065372\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1174   415    51\n",
      "    2  334  1627   237\n",
      "    3   40   302   718\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.69      0.74      0.72      2198\n",
      "          3       0.71      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1891368927134027\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1177   418    45\n",
      "    2  328  1639   231\n",
      "    3   38   307   715\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.72      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1913667943625412\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1172   420    48\n",
      "    2  321  1643   234\n",
      "    3   36   313   711\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.72      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1927369693919732\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1171   422    47\n",
      "    2  324  1652   222\n",
      "    3   36   305   719\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.73      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1941910578145827\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1178   416    46\n",
      "    2  315  1658   225\n",
      "    3   36   313   711\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.72      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1945329390290917\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1181   419    40\n",
      "    2  331  1650   217\n",
      "    3   33   323   704\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.73      0.66      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1855258837620646\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1178   423    39\n",
      "    2  326  1662   210\n",
      "    3   34   320   706\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.74      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1883640287910346\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(white_norm_input.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554   166    24\n",
      "    2  158   412    68\n",
      "    3   21    61   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.74      0.75       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.59      0.62      0.61       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1630651100782905\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554   166    24\n",
      "    2  158   412    68\n",
      "    3   21    61   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.74      0.75       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.59      0.62      0.61       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1630651100782905\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   165    19\n",
      "    2  152   423    63\n",
      "    3   19    60   138\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.75      0.76       744\n",
      "          2       0.65      0.66      0.66       638\n",
      "          3       0.63      0.64      0.63       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1766968108291043\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  562   167    15\n",
      "    2  144   430    64\n",
      "    3   16    70   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.76      0.77       744\n",
      "          2       0.64      0.67      0.66       638\n",
      "          3       0.62      0.60      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1817350850050774\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   172    17\n",
      "    2  142   424    72\n",
      "    3   12    72   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.75      0.76       744\n",
      "          2       0.63      0.66      0.65       638\n",
      "          3       0.60      0.61      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1904350926525296\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  557   172    15\n",
      "    2  135   439    64\n",
      "    3   14    74   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.75      0.77       744\n",
      "          2       0.64      0.69      0.66       638\n",
      "          3       0.62      0.59      0.61       217\n",
      "\n",
      "avg / total       0.71      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1927968090342447\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   163    14\n",
      "    2  132   435    71\n",
      "    3   12    68   137\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.76      0.78       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.62      0.63      0.62       217\n",
      "\n",
      "avg / total       0.72      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.207647095467875\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  570   160    14\n",
      "    2  134   442    62\n",
      "    3   11    75   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.77      0.78       744\n",
      "          2       0.65      0.69      0.67       638\n",
      "          3       0.63      0.60      0.62       217\n",
      "\n",
      "avg / total       0.72      0.71      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1943686921792769\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   157    14\n",
      "    2  138   435    65\n",
      "    3   14    73   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.77      0.78       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.62      0.60      0.61       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.1870154289299797\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   154    14\n",
      "    2  138   440    60\n",
      "    3   10    74   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.77      0.78       744\n",
      "          2       0.66      0.69      0.67       638\n",
      "          3       0.64      0.61      0.63       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1899096302156942\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   156    14\n",
      "    2  138   436    64\n",
      "    3   10    73   134\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.77      0.78       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.63      0.62      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1927968090342447\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  583   146    15\n",
      "    2  136   438    64\n",
      "    3    9    73   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.78      0.79       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.63      0.62      0.63       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1938449610897763\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581   148    15\n",
      "    2  132   445    61\n",
      "    3    8    70   139\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.78      0.79       744\n",
      "          2       0.67      0.70      0.68       638\n",
      "          3       0.65      0.64      0.64       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.2042763079506222\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  586   143    15\n",
      "    2  133   444    61\n",
      "    3   10    71   136\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.80       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.64      0.63      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.197245117935447\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   138    15\n",
      "    2  141   440    57\n",
      "    3   11    71   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.79       744\n",
      "          2       0.68      0.69      0.68       638\n",
      "          3       0.65      0.62      0.64       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.182793039635054\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  587   143    14\n",
      "    2  139   442    57\n",
      "    3   11    72   134\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.79       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.65      0.62      0.64       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1859612409521023\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   146    13\n",
      "    2  146   437    55\n",
      "    3   13    74   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.67      0.68      0.67       638\n",
      "          3       0.66      0.60      0.63       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1716368712612333\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   143    13\n",
      "    2  143   436    59\n",
      "    3    8    78   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.79       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.65      0.60      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1785555229603897\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   146    10\n",
      "    2  135   450    53\n",
      "    3    8    80   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.80       744\n",
      "          2       0.67      0.71      0.68       638\n",
      "          3       0.67      0.59      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.187278829671917\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   148    11\n",
      "    2  129   455    54\n",
      "    3    7    85   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.79      0.80       744\n",
      "          2       0.66      0.71      0.69       638\n",
      "          3       0.66      0.58      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1904350926525296\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(red_norm_input.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   412    89\n",
      "    2  416  1464   318\n",
      "    3   67   304   689\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.69      0.70      1640\n",
      "          2       0.67      0.67      0.67      2198\n",
      "          3       0.63      0.65      0.64      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "1.1382578221750783\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   412    89\n",
      "    2  416  1464   318\n",
      "    3   67   304   689\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.69      0.70      1640\n",
      "          2       0.67      0.67      0.67      2198\n",
      "          3       0.63      0.65      0.64      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "1.1382578221750783\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   420   100\n",
      "    2  410  1505   283\n",
      "    3   65   286   709\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.68      0.69      1640\n",
      "          2       0.68      0.68      0.68      2198\n",
      "          3       0.65      0.67      0.66      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "1.1456773375876754\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1119   437    84\n",
      "    2  386  1527   285\n",
      "    3   67   295   698\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.68      0.70      1640\n",
      "          2       0.68      0.69      0.69      2198\n",
      "          3       0.65      0.66      0.66      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "1.155790365033931\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1124   436    80\n",
      "    2  377  1538   283\n",
      "    3   56   309   695\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.69      0.70      1640\n",
      "          2       0.67      0.70      0.69      2198\n",
      "          3       0.66      0.66      0.66      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1598460916469466\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1137   434    69\n",
      "    2  361  1554   283\n",
      "    3   53   312   695\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.68      0.71      0.69      2198\n",
      "          3       0.66      0.66      0.66      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1688763611835808\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1136   431    73\n",
      "    2  367  1561   270\n",
      "    3   52   314   694\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.68      0.71      0.69      2198\n",
      "          3       0.67      0.65      0.66      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1637999741136082\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   425    71\n",
      "    2  361  1573   264\n",
      "    3   48   325   687\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.68      0.72      0.70      2198\n",
      "          3       0.67      0.65      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.163010272980943\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1138   439    63\n",
      "    2  357  1585   256\n",
      "    3   46   334   680\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.72      1640\n",
      "          2       0.67      0.72      0.70      2198\n",
      "          3       0.68      0.64      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1637999741136082\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1138   437    65\n",
      "    2  353  1601   244\n",
      "    3   41   344   675\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.72      1640\n",
      "          2       0.67      0.73      0.70      2198\n",
      "          3       0.69      0.64      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.162220035265087\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1129   452    59\n",
      "    2  352  1602   244\n",
      "    3   44   343   673\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.67      0.73      0.70      2198\n",
      "          3       0.69      0.63      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1638876856089369\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1134   454    52\n",
      "    2  347  1611   240\n",
      "    3   44   342   674\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.72      1640\n",
      "          2       0.67      0.73      0.70      2198\n",
      "          3       0.70      0.64      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1675656183934116\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1130   454    56\n",
      "    2  346  1619   233\n",
      "    3   42   346   672\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.72      1640\n",
      "          2       0.67      0.74      0.70      2198\n",
      "          3       0.70      0.63      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1659907820729691\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   459    55\n",
      "    2  343  1626   229\n",
      "    3   44   347   669\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.67      0.74      0.70      2198\n",
      "          3       0.70      0.63      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1660783287774568\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1130   455    55\n",
      "    2  346  1629   223\n",
      "    3   44   357   659\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.72      1640\n",
      "          2       0.67      0.74      0.70      2198\n",
      "          3       0.70      0.62      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1594939829285573\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1117   473    50\n",
      "    2  343  1629   226\n",
      "    3   41   354   665\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.68      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.71      0.63      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1664284498869162\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1122   470    48\n",
      "    2  345  1631   222\n",
      "    3   44   354   662\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.68      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.71      0.62      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.163712256007276\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1132   460    48\n",
      "    2  344  1626   228\n",
      "    3   41   360   659\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.69      0.72      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.62      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1627469200833567\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1119   470    51\n",
      "    2  346  1638   214\n",
      "    3   41   361   658\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.68      0.71      1640\n",
      "          2       0.66      0.75      0.70      2198\n",
      "          3       0.71      0.62      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1605499885963695\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   472    48\n",
      "    2  341  1639   218\n",
      "    3   40   365   655\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.68      0.71      1640\n",
      "          2       0.66      0.75      0.70      2198\n",
      "          3       0.71      0.62      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1625713183425557\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(log_white_norm.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  558   163    23\n",
      "    2  168   395    75\n",
      "    3   15    70   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.75      0.75       744\n",
      "          2       0.63      0.62      0.62       638\n",
      "          3       0.57      0.61      0.59       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "1.148727441218708\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  558   163    23\n",
      "    2  168   395    75\n",
      "    3   15    70   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.75      0.75       744\n",
      "          2       0.63      0.62      0.62       638\n",
      "          3       0.57      0.61      0.59       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "1.148727441218708\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   163    26\n",
      "    2  182   388    68\n",
      "    3   18    77   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.75      0.74       744\n",
      "          2       0.62      0.61      0.61       638\n",
      "          3       0.56      0.56      0.56       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "1.1110902645532408\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   161    22\n",
      "    2  185   383    70\n",
      "    3   16    76   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.75      0.75       744\n",
      "          2       0.62      0.60      0.61       638\n",
      "          3       0.58      0.58      0.58       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "1.1139010210417817\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   166    19\n",
      "    2  177   380    81\n",
      "    3   14    77   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.75      0.75       744\n",
      "          2       0.61      0.60      0.60       638\n",
      "          3       0.56      0.58      0.57       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "1.1331052266489472\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   165    16\n",
      "    2  172   397    69\n",
      "    3   14    78   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.76      0.75       744\n",
      "          2       0.62      0.62      0.62       638\n",
      "          3       0.60      0.58      0.59       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "1.1366870879709925\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   156    15\n",
      "    2  168   403    67\n",
      "    3   14    77   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.77      0.76       744\n",
      "          2       0.63      0.63      0.63       638\n",
      "          3       0.61      0.58      0.59       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1410800979198032\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565   164    15\n",
      "    2  170   403    65\n",
      "    3   17    81   119\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.76      0.76       744\n",
      "          2       0.62      0.63      0.63       638\n",
      "          3       0.60      0.55      0.57       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "1.1295120067349214\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   156    14\n",
      "    2  168   407    63\n",
      "    3   17    80   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.77      0.76       744\n",
      "          2       0.63      0.64      0.64       638\n",
      "          3       0.61      0.55      0.58       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.131448235423699\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   146    13\n",
      "    2  171   406    61\n",
      "    3   15    87   115\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.79      0.77       744\n",
      "          2       0.64      0.64      0.64       638\n",
      "          3       0.61      0.53      0.57       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1181039073884518\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  584   146    14\n",
      "    2  169   408    61\n",
      "    3   17    85   115\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.78      0.77       744\n",
      "          2       0.64      0.64      0.64       638\n",
      "          3       0.61      0.53      0.57       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1197806450073529\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  582   148    14\n",
      "    2  174   412    52\n",
      "    3   17    84   116\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.78      0.77       744\n",
      "          2       0.64      0.65      0.64       638\n",
      "          3       0.64      0.53      0.58       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1122154195398317\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  583   146    15\n",
      "    2  166   420    52\n",
      "    3   18    82   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.78      0.77       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.64      0.54      0.58       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1234049911914652\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   145    14\n",
      "    2  166   425    47\n",
      "    3   19    79   119\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.79      0.77       744\n",
      "          2       0.65      0.67      0.66       638\n",
      "          3       0.66      0.55      0.60       217\n",
      "\n",
      "avg / total       0.70      0.71      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1247958608478086\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  584   146    14\n",
      "    2  169   420    49\n",
      "    3   19    83   115\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.78      0.77       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.65      0.53      0.58       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1158643379743691\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  587   144    13\n",
      "    2  171   418    49\n",
      "    3   14    84   119\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.79      0.77       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.66      0.55      0.60       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1200598572408424\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   142    14\n",
      "    2  170   419    49\n",
      "    3   16    83   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.79      0.77       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.65      0.54      0.59       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1183835382312353\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  595   137    12\n",
      "    2  171   417    50\n",
      "    3   17    83   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.80      0.78       744\n",
      "          2       0.65      0.65      0.65       638\n",
      "          3       0.65      0.54      0.59       217\n",
      "\n",
      "avg / total       0.70      0.71      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1153037429437733\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  592   139    13\n",
      "    2  172   418    48\n",
      "    3   18    85   114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.80      0.78       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.65      0.53      0.58       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1088365294445544\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   140    10\n",
      "    2  173   418    47\n",
      "    3   21    83   113\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.80      0.78       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.66      0.52      0.58       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1068607468627618\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(log_red_norm.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   408    69\n",
      "    2  375  1528   295\n",
      "    3   60   277   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.71      0.72      1640\n",
      "          2       0.69      0.70      0.69      2198\n",
      "          3       0.67      0.68      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1731479152404758\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   408    69\n",
      "    2  375  1528   295\n",
      "    3   60   277   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.71      0.72      1640\n",
      "          2       0.69      0.70      0.69      2198\n",
      "          3       0.67      0.68      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1731479152404758\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1166   405    69\n",
      "    2  352  1557   289\n",
      "    3   47   290   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.69      0.71      0.70      2198\n",
      "          3       0.67      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "1.1834575032094805\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1170   402    68\n",
      "    2  344  1577   277\n",
      "    3   46   294   720\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.69      0.72      0.71      2198\n",
      "          3       0.68      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1845783243211963\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1168   411    61\n",
      "    2  348  1578   272\n",
      "    3   45   288   727\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.69      0.72      0.71      2198\n",
      "          3       0.69      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1875047011576583\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1174   404    62\n",
      "    2  352  1585   261\n",
      "    3   38   290   732\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.72      0.73      1640\n",
      "          2       0.70      0.72      0.71      2198\n",
      "          3       0.69      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1868167910630536\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1159   420    61\n",
      "    2  337  1588   273\n",
      "    3   34   291   735\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.73      1640\n",
      "          2       0.69      0.72      0.71      2198\n",
      "          3       0.69      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1974349883168631\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   413    64\n",
      "    2  334  1606   258\n",
      "    3   35   302   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.69      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.191109711073586\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   426    67\n",
      "    2  328  1597   273\n",
      "    3   36   291   733\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.68      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1997345561866128\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1157   414    69\n",
      "    2  329  1597   272\n",
      "    3   31   301   728\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.68      0.69      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1961555403734194\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   422    66\n",
      "    2  319  1615   264\n",
      "    3   35   300   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.69      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1993090429417388\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1161   413    66\n",
      "    2  335  1602   261\n",
      "    3   29   310   721\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.69      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1902523657447113\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   421    63\n",
      "    2  326  1607   265\n",
      "    3   29   303   728\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.69      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1986279075507518\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   427    60\n",
      "    2  325  1606   267\n",
      "    3   27   308   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.69      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1991387953657597\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   430    64\n",
      "    2  322  1616   260\n",
      "    3   29   306   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.69      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1992239221748944\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   429    61\n",
      "    2  321  1625   252\n",
      "    3   29   308   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1985427384095244\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   433    65\n",
      "    2  316  1633   249\n",
      "    3   30   307   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.1999897917083149\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1148   429    63\n",
      "    2  324  1630   244\n",
      "    3   28   310   722\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "1.195899486524746\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1154   424    62\n",
      "    2  327  1624   247\n",
      "    3   25   312   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.195301814234843\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1157   427    56\n",
      "    2  323  1635   240\n",
      "    3   24   318   718\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.71      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "1.1956433778406816\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(mm_white_norm.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553   167    24\n",
      "    2  155   416    67\n",
      "    3   21    66   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.74      0.75       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.59      0.60      0.59       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.160373449191463\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553   167    24\n",
      "    2  155   416    67\n",
      "    3   21    66   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.74      0.75       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.59      0.60      0.59       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.160373449191463\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  544   180    20\n",
      "    2  142   431    65\n",
      "    3   20    63   134\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.73      0.75       744\n",
      "          2       0.64      0.68      0.66       638\n",
      "          3       0.61      0.62      0.61       217\n",
      "\n",
      "avg / total       0.70      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1883318487965768\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   183    10\n",
      "    2  143   430    65\n",
      "    3   14    61   142\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.74      0.76       744\n",
      "          2       0.64      0.67      0.66       638\n",
      "          3       0.65      0.65      0.65       217\n",
      "\n",
      "avg / total       0.71      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.205055018868044\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   161    14\n",
      "    2  137   435    66\n",
      "    3   14    67   136\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.76      0.78       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.63      0.63      0.63       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.1975062685804847\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   171    13\n",
      "    2  140   427    71\n",
      "    3   14    69   134\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.75      0.77       744\n",
      "          2       0.64      0.67      0.65       638\n",
      "          3       0.61      0.62      0.62       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1954154659929783\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   160    10\n",
      "    2  134   433    71\n",
      "    3   14    71   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.77      0.78       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.62      0.61      0.61       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.1993327308860577\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  579   153    12\n",
      "    2  136   438    64\n",
      "    3   14    71   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.79       744\n",
      "          2       0.66      0.69      0.67       638\n",
      "          3       0.63      0.61      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1920100901562858\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   141    12\n",
      "    2  137   443    58\n",
      "    3   13    69   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.80       744\n",
      "          2       0.68      0.69      0.69       638\n",
      "          3       0.66      0.62      0.64       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1901723904331436\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  586   145    13\n",
      "    2  129   451    58\n",
      "    3   15    70   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.80       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.65      0.61      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1967226456793052\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  584   150    10\n",
      "    2  133   451    54\n",
      "    3   14    74   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.78      0.79       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.67      0.59      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1896468119617507\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   146     9\n",
      "    2  131   452    55\n",
      "    3   13    75   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.67      0.59      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1922723874617285\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  592   143     9\n",
      "    2  141   440    57\n",
      "    3   11    79   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.66      0.59      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1766968108291043\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   146     9\n",
      "    2  128   453    57\n",
      "    3   13    76   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.79      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.66      0.59      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1954154659929783\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   142    11\n",
      "    2  130   454    54\n",
      "    3   10    78   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.79      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.66      0.59      0.63       217\n",
      "\n",
      "avg / total       0.74      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1920100901562858\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   141     9\n",
      "    2  129   457    52\n",
      "    3   12    75   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.80      0.80       744\n",
      "          2       0.68      0.72      0.70       638\n",
      "          3       0.68      0.60      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1943686921792769\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  593   140    11\n",
      "    2  136   451    51\n",
      "    3    9    76   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.68      0.61      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1870154289299797\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   150     9\n",
      "    2  132   457    49\n",
      "    3    9    78   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.79      0.80       744\n",
      "          2       0.67      0.72      0.69       638\n",
      "          3       0.69      0.60      0.64       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1927968090342447\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   143    12\n",
      "    2  138   447    53\n",
      "    3    8    78   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.80       744\n",
      "          2       0.67      0.70      0.68       638\n",
      "          3       0.67      0.60      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.184114153684347\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   141    12\n",
      "    2  132   454    52\n",
      "    3    7    82   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.79      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.67      0.59      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1875421719907089\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(mm_red_norm.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   419   101\n",
      "    2  420  1444   334\n",
      "    3   84   326   650\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.69      1640\n",
      "          2       0.66      0.66      0.66      2198\n",
      "          3       0.60      0.61      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "1.1171662512042362\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1310   286    44\n",
      "    2  799  1243   156\n",
      "    3  197   484   379\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.80      0.66      1640\n",
      "          2       0.62      0.57      0.59      2198\n",
      "          3       0.65      0.36      0.46      1060\n",
      "\n",
      "avg / total       0.61      0.60      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.721964788885416\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   532    86\n",
      "    2  620  1236   342\n",
      "    3  160   377   523\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.62      0.59      1640\n",
      "          2       0.58      0.56      0.57      2198\n",
      "          3       0.55      0.49      0.52      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9641385206360522\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   415    63\n",
      "    2  704  1245   249\n",
      "    3  121   521   418\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.71      0.64      1640\n",
      "          2       0.57      0.57      0.57      2198\n",
      "          3       0.57      0.39      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.8432713525976573\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1031   545    64\n",
      "    2  606  1267   325\n",
      "    3  126   462   472\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.63      0.61      1640\n",
      "          2       0.56      0.58      0.57      2198\n",
      "          3       0.55      0.45      0.49      1060\n",
      "\n",
      "avg / total       0.56      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9523133811024962\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1107   467    66\n",
      "    2  678  1237   283\n",
      "    3  125   530   405\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.68      0.62      1640\n",
      "          2       0.55      0.56      0.56      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.8601708168835119\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   569    66\n",
      "    2  568  1305   325\n",
      "    3   84   522   454\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.61      0.61      1640\n",
      "          2       0.54      0.59      0.57      2198\n",
      "          3       0.54      0.43      0.48      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9695233365959609\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1066   522    52\n",
      "    2  624  1287   287\n",
      "    3   89   569   402\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.65      0.62      1640\n",
      "          2       0.54      0.59      0.56      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9039182435919786\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1011   570    59\n",
      "    2  578  1291   329\n",
      "    3   75   549   436\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.62      0.61      1640\n",
      "          2       0.54      0.59      0.56      2198\n",
      "          3       0.53      0.41      0.46      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9576580935237095\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1046   542    52\n",
      "    2  599  1300   299\n",
      "    3   68   577   415\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.64      0.62      1640\n",
      "          2       0.54      0.59      0.56      2198\n",
      "          3       0.54      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9309566465009812\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  998   595    47\n",
      "    2  553  1333   312\n",
      "    3   64   566   430\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.61      1640\n",
      "          2       0.53      0.61      0.57      2198\n",
      "          3       0.54      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9722570592707238\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1050   547    43\n",
      "    2  582  1308   308\n",
      "    3   68   585   407\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.54      0.60      0.56      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.939362006891823\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1007   585    48\n",
      "    2  534  1345   319\n",
      "    3   62   578   420\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.61      0.62      1640\n",
      "          2       0.54      0.61      0.57      2198\n",
      "          3       0.53      0.40      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.9766569089726534\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1047   543    50\n",
      "    2  560  1345   293\n",
      "    3   62   587   411\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.64      0.63      1640\n",
      "          2       0.54      0.61      0.58      2198\n",
      "          3       0.55      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9504893326160504\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1010   583    47\n",
      "    2  523  1376   299\n",
      "    3   67   577   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.62      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9777015738439504\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   566    45\n",
      "    2  535  1382   281\n",
      "    3   62   601   397\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.37      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9586169770972626\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   578    40\n",
      "    2  532  1388   278\n",
      "    3   64   594   402\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.56      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9646677727594796\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1037   565    38\n",
      "    2  549  1383   266\n",
      "    3   61   600   399\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.57      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9520989685407102\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1019   582    39\n",
      "    2  526  1397   275\n",
      "    3   60   596   404\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.54      0.64      0.59      2198\n",
      "          3       0.56      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.9696286222928121\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1037   569    34\n",
      "    2  530  1410   258\n",
      "    3   67   597   396\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.55      0.64      0.59      2198\n",
      "          3       0.58      0.37      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.960425589615904\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(white_norm_filtered.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   419   101\n",
      "    2  420  1444   334\n",
      "    3   84   326   650\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.69      1640\n",
      "          2       0.66      0.66      0.66      2198\n",
      "          3       0.60      0.61      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "1.1171662512042362\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1137   404    99\n",
      "    2  440  1435   323\n",
      "    3   89   331   640\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.69      0.69      1640\n",
      "          2       0.66      0.65      0.66      2198\n",
      "          3       0.60      0.60      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "1.1008738501631556\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1114   427    99\n",
      "    2  432  1452   314\n",
      "    3   73   330   657\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.68      1640\n",
      "          2       0.66      0.66      0.66      2198\n",
      "          3       0.61      0.62      0.62      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "1.1151541613576588\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1133   432    75\n",
      "    2  421  1471   306\n",
      "    3   71   351   638\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.69      0.69      1640\n",
      "          2       0.65      0.67      0.66      2198\n",
      "          3       0.63      0.60      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "1.115794765335609\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   417    74\n",
      "    2  403  1489   306\n",
      "    3   62   355   643\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.70      0.71      1640\n",
      "          2       0.66      0.68      0.67      2198\n",
      "          3       0.63      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "1.1259042008526987\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   427    64\n",
      "    2  397  1493   308\n",
      "    3   49   370   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.70      0.71      1640\n",
      "          2       0.65      0.68      0.67      2198\n",
      "          3       0.63      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "1.1317822194405298\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   429    67\n",
      "    2  397  1509   292\n",
      "    3   47   382   631\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.70      0.71      1640\n",
      "          2       0.65      0.69      0.67      2198\n",
      "          3       0.64      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "1.1256321666520899\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   426    62\n",
      "    2  388  1522   288\n",
      "    3   45   382   633\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.65      0.69      0.67      2198\n",
      "          3       0.64      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "1.1310604194822642\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   433    58\n",
      "    2  376  1525   297\n",
      "    3   48   375   637\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.65      0.69      0.67      2198\n",
      "          3       0.64      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "1.1401396116326645\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1151   429    60\n",
      "    2  372  1538   288\n",
      "    3   44   378   638\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.65      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "1.1412135267325685\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   427    60\n",
      "    2  377  1541   280\n",
      "    3   40   383   637\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.65      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "1.1379887410896807\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1155   429    56\n",
      "    2  361  1557   280\n",
      "    3   37   388   635\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.65      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "1.1454099995050282\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1155   431    54\n",
      "    2  363  1558   277\n",
      "    3   38   392   630\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.65      0.71      0.68      2198\n",
      "          3       0.66      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "1.1424651518149138\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   438    53\n",
      "    2  352  1572   274\n",
      "    3   41   380   639\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.66      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1516317182747902\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   440    51\n",
      "    2  355  1576   267\n",
      "    3   42   384   634\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1479027336818584\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   446    51\n",
      "    2  342  1598   258\n",
      "    3   41   388   631\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.67      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1521634451449574\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   449    48\n",
      "    2  347  1590   261\n",
      "    3   38   400   622\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.65      0.72      0.69      2198\n",
      "          3       0.67      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.69      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "1.147280057892248\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1155   439    46\n",
      "    2  345  1584   269\n",
      "    3   38   396   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.73      1640\n",
      "          2       0.65      0.72      0.69      2198\n",
      "          3       0.67      0.59      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1501238238235838\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   442    46\n",
      "    2  351  1594   253\n",
      "    3   42   389   629\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.68      0.59      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.147280057892248\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   440    47\n",
      "    2  339  1605   254\n",
      "    3   37   397   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.73      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.68      0.59      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "1.1514544214192595\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(white_norm_filtered.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   165    12\n",
      "    2  147   417    74\n",
      "    3   18    69   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.77       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.60      0.60      0.60       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1796163292264188\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  641   100     3\n",
      "    2  288   322    28\n",
      "    3   36   121    60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.86      0.75       744\n",
      "          2       0.59      0.50      0.55       638\n",
      "          3       0.66      0.28      0.39       217\n",
      "\n",
      "avg / total       0.64      0.64      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.8138113605631304\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  556   172    16\n",
      "    2  224   335    79\n",
      "    3   39    95    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.56      0.53      0.54       638\n",
      "          3       0.47      0.38      0.42       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.9965544141880932\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   121    13\n",
      "    2  247   341    50\n",
      "    3   23   118    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.82      0.75       744\n",
      "          2       0.59      0.53      0.56       638\n",
      "          3       0.55      0.35      0.43       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.9289991386566328\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   167     8\n",
      "    2  214   361    63\n",
      "    3   24   107    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.76      0.73       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.55      0.40      0.46       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "1.019816167568828\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   135     6\n",
      "    2  248   336    54\n",
      "    3   25   121    71\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.81      0.74       744\n",
      "          2       0.57      0.53      0.55       638\n",
      "          3       0.54      0.33      0.41       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.9289991386566328\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   162     9\n",
      "    2  214   366    58\n",
      "    3   26   109    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.77      0.74       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.55      0.38      0.45       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "1.0093372707270842\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   138     6\n",
      "    2  236   351    51\n",
      "    3   24   122    71\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.81      0.75       744\n",
      "          2       0.57      0.55      0.56       638\n",
      "          3       0.55      0.33      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.9493093503445846\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   162     7\n",
      "    2  218   366    54\n",
      "    3   27   110    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.77      0.74       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.57      0.37      0.45       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.9996872556608425\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   145     5\n",
      "    2  223   365    50\n",
      "    3   25   117    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.58      0.57      0.58       638\n",
      "          3       0.58      0.35      0.43       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9791446280436009\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   166     7\n",
      "    2  211   375    52\n",
      "    3   25   112    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.58      0.37      0.45       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0118126570828938\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   139     7\n",
      "    2  223   362    53\n",
      "    3   23   119    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.58      0.57      0.58       638\n",
      "          3       0.56      0.35      0.43       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9775465453267047\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  578   159     7\n",
      "    2  204   385    49\n",
      "    3   24   112    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.78      0.75       744\n",
      "          2       0.59      0.60      0.60       638\n",
      "          3       0.59      0.37      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "1.0213481140048375\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   135     9\n",
      "    2  218   370    50\n",
      "    3   22   122    73\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.81      0.76       744\n",
      "          2       0.59      0.58      0.58       638\n",
      "          3       0.55      0.34      0.42       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9791446280436009\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   161     8\n",
      "    2  212   378    48\n",
      "    3   23   115    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.58      0.59      0.59       638\n",
      "          3       0.59      0.36      0.45       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0059236683350148\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   153     6\n",
      "    2  218   375    45\n",
      "    3   23   117    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.58      0.59      0.58       638\n",
      "          3       0.60      0.35      0.45       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9912058593752295\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   176     9\n",
      "    2  209   387    42\n",
      "    3   20   117    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.75      0.73       744\n",
      "          2       0.57      0.61      0.59       638\n",
      "          3       0.61      0.37      0.46       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0152064581135072\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   160     9\n",
      "    2  221   374    43\n",
      "    3   19   116    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.58      0.59      0.58       638\n",
      "          3       0.61      0.38      0.47       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.9952985165067817\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   173     8\n",
      "    2  210   386    42\n",
      "    3   19   118    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.76      0.73       744\n",
      "          2       0.57      0.61      0.59       638\n",
      "          3       0.62      0.37      0.46       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0136652298707427\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  570   166     8\n",
      "    2  213   384    41\n",
      "    3   19   117    81\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.58      0.60      0.59       638\n",
      "          3       0.62      0.37      0.47       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "1.0080972981818899\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   165    12\n",
      "    2  147   417    74\n",
      "    3   18    69   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.77       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.60      0.60      0.60       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1796163292264188\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   165    12\n",
      "    2  148   416    74\n",
      "    3   18    69   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.77       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.60      0.60      0.60       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1782901721694639\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   154    14\n",
      "    2  147   414    77\n",
      "    3   21    73   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.77      0.77       744\n",
      "          2       0.65      0.65      0.65       638\n",
      "          3       0.57      0.57      0.57       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.166286903258776\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   157    11\n",
      "    2  145   429    64\n",
      "    3   17    68   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.77      0.78       744\n",
      "          2       0.66      0.67      0.66       638\n",
      "          3       0.64      0.61      0.62       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.1809409970545004\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   129    10\n",
      "    2  140   434    64\n",
      "    3   16    73   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.68      0.68      0.68       638\n",
      "          3       0.63      0.59      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1756333702044237\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  595   139    10\n",
      "    2  136   440    62\n",
      "    3   14    75   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.64      0.59      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1835858850193384\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   131    10\n",
      "    2  136   446    56\n",
      "    3   17    72   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.69      0.70      0.69       638\n",
      "          3       0.66      0.59      0.62       217\n",
      "\n",
      "avg / total       0.73      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1790860453923726\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  602   134     8\n",
      "    2  138   447    53\n",
      "    3   14    73   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.68      0.60      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1809409970545004\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   138     7\n",
      "    2  140   444    54\n",
      "    3   14    75   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.68      0.59      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1774937610124585\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   130     6\n",
      "    2  139   447    52\n",
      "    3   13    74   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.70      0.69       638\n",
      "          3       0.69      0.60      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1796163292264188\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   135     6\n",
      "    2  138   448    52\n",
      "    3   15    73   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.69      0.59      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1804113083097312\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  607   132     5\n",
      "    2  138   451    49\n",
      "    3   12    72   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.71      0.61      0.66       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.185433795410804\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  607   133     4\n",
      "    2  136   455    47\n",
      "    3   14    72   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.72      0.60      0.66       217\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1599\n",
      "\n",
      "RMSE:\n",
      "1.1851699846151904\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   131     4\n",
      "    2  137   453    48\n",
      "    3   15    74   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.71      0.59      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1793512171140188\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   129     5\n",
      "    2  139   452    47\n",
      "    3   15    75   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.71      0.59      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1740364031504524\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  604   135     5\n",
      "    2  139   451    48\n",
      "    3   15    77   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.70      0.58      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1732371044740153\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   133     5\n",
      "    2  139   453    46\n",
      "    3   12    77   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.68      0.71      0.70       638\n",
      "          3       0.72      0.59      0.65       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.176962520849614\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   131     5\n",
      "    2  138   455    45\n",
      "    3   12    77   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.72      0.59      0.65       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1774937610124585\n",
      "19 neighbours:\n",
      "19 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   131     5\n",
      "    2  140   453    45\n",
      "    3   12    76   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.72      0.59      0.65       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.1761652107067264\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   134     4\n",
      "    2  137   457    44\n",
      "    3   11    78   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.68      0.72      0.70       638\n",
      "          3       0.73      0.59      0.65       217\n",
      "\n",
      "avg / total       0.75      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "1.180146374784161\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(red_norm_filtered.values,red_targetclass)\n",
    "run_knnw_report(red_norm_filtered.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568   160    16\n",
      "    2  154   402    82\n",
      "    3   16    66   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.77       744\n",
      "          2       0.64      0.63      0.64       638\n",
      "          3       0.58      0.62      0.60       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1761652107067264\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  646    92     6\n",
      "    2  292   314    32\n",
      "    3   37   119    61\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.87      0.75       744\n",
      "          2       0.60      0.49      0.54       638\n",
      "          3       0.62      0.28      0.39       217\n",
      "\n",
      "avg / total       0.63      0.64      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.8037591479914785\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   175    10\n",
      "    2  229   337    72\n",
      "    3   35    87    95\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.56      0.53      0.54       638\n",
      "          3       0.54      0.44      0.48       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "1.0111943785912574\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  618   119     7\n",
      "    2  258   326    54\n",
      "    3   28   121    68\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.83      0.75       744\n",
      "          2       0.58      0.51      0.54       638\n",
      "          3       0.53      0.31      0.39       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.8995864521353915\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566   169     9\n",
      "    2  239   338    61\n",
      "    3   28   100    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.76      0.72       744\n",
      "          2       0.56      0.53      0.54       638\n",
      "          3       0.56      0.41      0.47       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9836054467095777\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   142     8\n",
      "    2  270   313    55\n",
      "    3   26   115    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.80      0.73       744\n",
      "          2       0.55      0.49      0.52       638\n",
      "          3       0.55      0.35      0.43       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.9009757756691986\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   176     8\n",
      "    2  230   350    58\n",
      "    3   19   116    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.55      0.55      0.55       638\n",
      "          3       0.55      0.38      0.45       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9915212789088698\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581   158     5\n",
      "    2  254   338    46\n",
      "    3   22   125    70\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.78      0.73       744\n",
      "          2       0.54      0.53      0.54       638\n",
      "          3       0.58      0.32      0.41       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9239364353597956\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  570   169     5\n",
      "    2  235   340    63\n",
      "    3   23   117    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.54      0.53      0.54       638\n",
      "          3       0.53      0.35      0.43       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9756253907440167\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   163     7\n",
      "    2  233   356    49\n",
      "    3   25   125    67\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.55      0.56      0.56       638\n",
      "          3       0.54      0.31      0.39       217\n",
      "\n",
      "avg / total       0.62      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9542374472273958\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   174     6\n",
      "    2  218   367    53\n",
      "    3   28   122    67\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.76      0.73       744\n",
      "          2       0.55      0.58      0.56       638\n",
      "          3       0.53      0.31      0.39       217\n",
      "\n",
      "avg / total       0.62      0.62      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.9829694263089577\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   168     5\n",
      "    2  231   355    52\n",
      "    3   28   126    63\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.55      0.56      0.55       638\n",
      "          3       0.53      0.29      0.37       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9539096995113131\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   179     4\n",
      "    2  230   352    56\n",
      "    3   27   123    67\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.54      0.55      0.54       638\n",
      "          3       0.53      0.31      0.39       217\n",
      "\n",
      "avg / total       0.61      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.9679026408690989\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   169     6\n",
      "    2  239   354    45\n",
      "    3   23   136    58\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.76      0.72       744\n",
      "          2       0.54      0.55      0.55       638\n",
      "          3       0.53      0.27      0.36       217\n",
      "\n",
      "avg / total       0.61      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.9313523155658221\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   178     7\n",
      "    2  237   354    47\n",
      "    3   25   133    59\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.53      0.55      0.54       638\n",
      "          3       0.52      0.27      0.36       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.9387096115595448\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   161     9\n",
      "    2  239   355    44\n",
      "    3   24   131    62\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.55      0.56      0.55       638\n",
      "          3       0.54      0.29      0.37       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9326943224803032\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   168     5\n",
      "    2  236   355    47\n",
      "    3   23   130    64\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.54      0.56      0.55       638\n",
      "          3       0.55      0.29      0.38       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9473309334313419\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   167     6\n",
      "    2  241   359    38\n",
      "    3   28   128    61\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.55      0.56      0.56       638\n",
      "          3       0.58      0.28      0.38       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.9283257067894753\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565   173     6\n",
      "    2  237   357    44\n",
      "    3   28   124    65\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.76      0.72       744\n",
      "          2       0.55      0.56      0.55       638\n",
      "          3       0.57      0.30      0.39       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.945679090965551\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   160     7\n",
      "    2  236   361    41\n",
      "    3   28   126    63\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.78      0.73       744\n",
      "          2       0.56      0.57      0.56       638\n",
      "          3       0.57      0.29      0.38       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.9380431509774403\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568   160    16\n",
      "    2  154   402    82\n",
      "    3   16    66   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.77       744\n",
      "          2       0.64      0.63      0.64       638\n",
      "          3       0.58      0.62      0.60       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1761652107067264\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568   160    16\n",
      "    2  154   402    82\n",
      "    3   16    66   135\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.77       744\n",
      "          2       0.64      0.63      0.64       638\n",
      "          3       0.58      0.62      0.60       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "1.1761652107067264\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  580   154    10\n",
      "    2  158   407    73\n",
      "    3   17    71   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.78      0.77       744\n",
      "          2       0.64      0.64      0.64       638\n",
      "          3       0.61      0.59      0.60       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1617200591945374\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  590   143    11\n",
      "    2  163   397    78\n",
      "    3   18    70   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.79      0.78       744\n",
      "          2       0.65      0.62      0.64       638\n",
      "          3       0.59      0.59      0.59       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1525320847503495\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  593   142     9\n",
      "    2  163   406    69\n",
      "    3   16    70   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.80      0.78       744\n",
      "          2       0.66      0.64      0.65       638\n",
      "          3       0.63      0.60      0.62       217\n",
      "\n",
      "avg / total       0.70      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.154158806921624\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   136     9\n",
      "    2  172   401    65\n",
      "    3   15    75   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.81      0.78       744\n",
      "          2       0.66      0.63      0.64       638\n",
      "          3       0.63      0.59      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "1.1339328142650436\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   138     8\n",
      "    2  166   414    58\n",
      "    3   12    78   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.80      0.79       744\n",
      "          2       0.66      0.65      0.65       638\n",
      "          3       0.66      0.59      0.62       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.142175710364146\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   139     6\n",
      "    2  162   420    56\n",
      "    3   12    80   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.81      0.79       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.67      0.58      0.62       217\n",
      "\n",
      "avg / total       0.71      0.72      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.1457292152365908\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   142     5\n",
      "    2  154   427    57\n",
      "    3   13    80   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.80      0.79       744\n",
      "          2       0.66      0.67      0.66       638\n",
      "          3       0.67      0.57      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.156594600289309\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   141     6\n",
      "    2  154   428    56\n",
      "    3   12    83   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.80      0.79       744\n",
      "          2       0.66      0.67      0.66       638\n",
      "          3       0.66      0.56      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1530745804663172\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  602   136     6\n",
      "    2  151   432    55\n",
      "    3   13    80   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.68      0.67       638\n",
      "          3       0.67      0.57      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.157945604838523\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   139     7\n",
      "    2  156   425    57\n",
      "    3   14    81   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.80      0.79       744\n",
      "          2       0.66      0.67      0.66       638\n",
      "          3       0.66      0.56      0.61       217\n",
      "\n",
      "avg / total       0.71      0.72      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "1.1489996192680718\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   134     5\n",
      "    2  153   430    55\n",
      "    3   16    76   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.81      0.80       744\n",
      "          2       0.67      0.67      0.67       638\n",
      "          3       0.68      0.58      0.62       217\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.155783239543863\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   134     7\n",
      "    2  157   432    49\n",
      "    3   12    84   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.81      0.80       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.68      0.56      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1432702728677129\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   135     6\n",
      "    2  166   424    48\n",
      "    3   12    84   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.81      0.79       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.69      0.56      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.131448235423699\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   132     7\n",
      "    2  161   433    44\n",
      "    3   11    86   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.81      0.80       744\n",
      "          2       0.67      0.68      0.67       638\n",
      "          3       0.70      0.55      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "1.1347597983163318\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   125     6\n",
      "    2  160   432    46\n",
      "    3   10    85   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.67      0.68      0.67       638\n",
      "          3       0.70      0.56      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1383364534160079\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   128     4\n",
      "    2  162   435    41\n",
      "    3   11    88   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.67      0.68      0.67       638\n",
      "          3       0.72      0.54      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1303422251540587\n",
      "19 neighbours:\n",
      "19 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   125     7\n",
      "    2  159   439    40\n",
      "    3   12    82   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.68      0.69      0.68       638\n",
      "          3       0.72      0.57      0.64       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.1383364534160079\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  615   124     5\n",
      "    2  164   432    42\n",
      "    3   11    88   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.83      0.80       744\n",
      "          2       0.67      0.68      0.67       638\n",
      "          3       0.72      0.54      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "1.126185012742946\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(f_log_red.values,red_targetclass)\n",
    "run_knnw_report(f_log_red.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   461    98\n",
      "    2  439  1413   346\n",
      "    3   98   327   635\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.66      0.66      1640\n",
      "          2       0.64      0.64      0.64      2198\n",
      "          3       0.59      0.60      0.59      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "0.6936979336808926\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1278   319    43\n",
      "    2  810  1228   160\n",
      "    3  199   520   341\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.56      0.78      0.65      1640\n",
      "          2       0.59      0.56      0.58      2198\n",
      "          3       0.63      0.32      0.43      1060\n",
      "\n",
      "avg / total       0.59      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7529715191265614\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1012   532    96\n",
      "    2  607  1243   348\n",
      "    3  149   426   485\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.62      0.59      1640\n",
      "          2       0.56      0.57      0.57      2198\n",
      "          3       0.52      0.46      0.49      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7685370808162925\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   431    91\n",
      "    2  647  1295   256\n",
      "    3  124   535   401\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.68      0.63      1640\n",
      "          2       0.57      0.59      0.58      2198\n",
      "          3       0.54      0.38      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7464356571612504\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  997   560    83\n",
      "    2  564  1341   293\n",
      "    3  110   487   463\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.61      0.60      1640\n",
      "          2       0.56      0.61      0.58      2198\n",
      "          3       0.55      0.44      0.49      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7391518430750708\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1089   459    92\n",
      "    2  634  1294   270\n",
      "    3  123   511   426\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.66      0.62      1640\n",
      "          2       0.57      0.59      0.58      2198\n",
      "          3       0.54      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.747119143850703\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  986   560    94\n",
      "    2  548  1340   310\n",
      "    3   91   514   455\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.60      0.60      1640\n",
      "          2       0.56      0.61      0.58      2198\n",
      "          3       0.53      0.43      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7385992061057919\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1056   511    73\n",
      "    2  621  1309   268\n",
      "    3  101   554   405\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.64      0.62      1640\n",
      "          2       0.55      0.60      0.57      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.735552280958793\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  977   589    74\n",
      "    2  559  1336   303\n",
      "    3   95   506   459\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.60      0.60      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.43      0.48      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7331891663232074\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1038   534    68\n",
      "    2  564  1355   279\n",
      "    3   91   553   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.63      0.62      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7238005947352895\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  996   576    68\n",
      "    2  528  1379   291\n",
      "    3   88   560   412\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.61      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.53      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7256317561187315\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   547    64\n",
      "    2  574  1349   275\n",
      "    3   90   559   411\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.63      0.62      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7245054352905979\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1000   580    60\n",
      "    2  535  1384   279\n",
      "    3   74   572   414\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.55      0.63      0.58      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7147172470008497\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1024   560    56\n",
      "    2  567  1363   268\n",
      "    3   73   601   386\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.62      0.58      2198\n",
      "          3       0.54      0.36      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7161441145561368\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  992   591    57\n",
      "    2  536  1400   262\n",
      "    3   71   585   404\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.60      0.61      1640\n",
      "          2       0.54      0.64      0.59      2198\n",
      "          3       0.56      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7124283147909004\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1008   579    53\n",
      "    2  569  1357   272\n",
      "    3   65   600   395\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.61      0.61      1640\n",
      "          2       0.54      0.62      0.57      2198\n",
      "          3       0.55      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7132875251310331\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  983   604    53\n",
      "    2  553  1371   274\n",
      "    3   71   587   402\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.60      0.61      1640\n",
      "          2       0.54      0.62      0.58      2198\n",
      "          3       0.55      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7164291470508282\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1015   577    48\n",
      "    2  573  1354   271\n",
      "    3   69   601   390\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.62      0.62      1640\n",
      "          2       0.53      0.62      0.57      2198\n",
      "          3       0.55      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7130012367289206\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  998   593    49\n",
      "    2  545  1383   270\n",
      "    3   64   596   400\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.61      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.56      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7081166251099064\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1010   579    51\n",
      "    2  555  1382   261\n",
      "    3   65   612   383\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.36      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7102757416922127\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1081   461    98\n",
      "    2  439  1413   346\n",
      "    3   98   327   635\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.66      0.66      1640\n",
      "          2       0.64      0.64      0.64      2198\n",
      "          3       0.59      0.60      0.59      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "0.6936979336808926\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1095   451    94\n",
      "    2  459  1399   340\n",
      "    3  101   336   623\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.67      0.66      1640\n",
      "          2       0.64      0.64      0.64      2198\n",
      "          3       0.59      0.59      0.59      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "0.6950210844864835\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1106   437    97\n",
      "    2  437  1434   327\n",
      "    3   78   359   623\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.67      0.68      1640\n",
      "          2       0.64      0.65      0.65      2198\n",
      "          3       0.60      0.59      0.59      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6792737456724058\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1111   441    88\n",
      "    2  422  1454   322\n",
      "    3   73   360   627\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.68      1640\n",
      "          2       0.64      0.66      0.65      2198\n",
      "          3       0.60      0.59      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6685185928783817\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1106   445    89\n",
      "    2  408  1480   310\n",
      "    3   68   353   639\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.67      0.69      1640\n",
      "          2       0.65      0.67      0.66      2198\n",
      "          3       0.62      0.60      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6616114309668126\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1112   441    87\n",
      "    2  391  1513   294\n",
      "    3   62   357   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.68      0.69      1640\n",
      "          2       0.65      0.69      0.67      2198\n",
      "          3       0.63      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6515051518153762\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1110   444    86\n",
      "    2  390  1514   294\n",
      "    3   59   361   640\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.68      0.69      1640\n",
      "          2       0.65      0.69      0.67      2198\n",
      "          3       0.63      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6499363916484879\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1114   449    77\n",
      "    2  384  1528   286\n",
      "    3   50   364   646\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.68      0.70      1640\n",
      "          2       0.65      0.70      0.67      2198\n",
      "          3       0.64      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6375676010403009\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1116   448    76\n",
      "    2  381  1531   286\n",
      "    3   52   372   636\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.68      0.70      1640\n",
      "          2       0.65      0.70      0.67      2198\n",
      "          3       0.64      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6388472161781875\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   446    68\n",
      "    2  374  1550   274\n",
      "    3   50   380   630\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.65      0.71      0.68      2198\n",
      "          3       0.65      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6303213644309911\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1138   434    68\n",
      "    2  374  1554   270\n",
      "    3   46   386   628\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.65      0.71      0.68      2198\n",
      "          3       0.65      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.626096424970272\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1133   444    63\n",
      "    2  376  1561   261\n",
      "    3   46   376   638\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.66      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.621678598069511\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1137   437    66\n",
      "    2  382  1545   271\n",
      "    3   45   385   630\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.65      0.70      0.68      2198\n",
      "          3       0.65      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6259333577907982\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   433    65\n",
      "    2  371  1565   262\n",
      "    3   44   387   629\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.66      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6210214323487594\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1137   440    63\n",
      "    2  369  1574   255\n",
      "    3   45   389   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.72      0.68      2198\n",
      "          3       0.66      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6203635704772943\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1148   430    62\n",
      "    2  377  1568   253\n",
      "    3   43   391   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.67      0.59      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6180555396250805\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   439    55\n",
      "    2  381  1567   250\n",
      "    3   44   390   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.65      0.71      0.68      2198\n",
      "          3       0.67      0.59      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6155730465037192\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   439    55\n",
      "    2  370  1584   244\n",
      "    3   41   391   628\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.68      0.59      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6109120694123626\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   441    56\n",
      "    2  366  1595   237\n",
      "    3   41   387   632\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.68      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6094063273925434\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   439    54\n",
      "    2  361  1605   232\n",
      "    3   38   396   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.69      0.59      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6055413096266453\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(f_log_white.values,white_targetclass)\n",
    "run_knnw_report(f_log_white.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   163    14\n",
      "    2  142   420    76\n",
      "    3   15    66   136\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.76      0.77       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.60      0.63      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5933759848629978\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  639   103     2\n",
      "    2  281   325    32\n",
      "    3   34   125    58\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.86      0.75       744\n",
      "          2       0.59      0.51      0.55       638\n",
      "          3       0.63      0.27      0.38       217\n",
      "\n",
      "avg / total       0.63      0.64      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6545171850042718\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   176    13\n",
      "    2  218   343    77\n",
      "    3   39    92    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.56      0.54      0.55       638\n",
      "          3       0.49      0.40      0.44       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6943891993868717\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   123    16\n",
      "    2  237   343    58\n",
      "    3   30   111    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.81      0.75       744\n",
      "          2       0.59      0.54      0.56       638\n",
      "          3       0.51      0.35      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6677602038203002\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   174     6\n",
      "    2  194   377    67\n",
      "    3   29   105    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.53      0.38      0.45       217\n",
      "\n",
      "avg / total       0.63      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6521240611413213\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   140     7\n",
      "    2  228   354    56\n",
      "    3   28   121    68\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.80      0.75       744\n",
      "          2       0.58      0.55      0.57       638\n",
      "          3       0.52      0.31      0.39       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6545171850042718\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554   181     9\n",
      "    2  201   377    60\n",
      "    3   27   114    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.56      0.59      0.58       638\n",
      "          3       0.52      0.35      0.42       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6616446240281227\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   152     4\n",
      "    2  225   356    57\n",
      "    3   22   124    71\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.79      0.74       744\n",
      "          2       0.56      0.56      0.56       638\n",
      "          3       0.54      0.33      0.41       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6434351214164253\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   177     7\n",
      "    2  205   374    59\n",
      "    3   20   117    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.75      0.73       744\n",
      "          2       0.56      0.59      0.57       638\n",
      "          3       0.55      0.37      0.44       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6453761065838611\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  580   161     3\n",
      "    2  229   355    54\n",
      "    3   18   132    67\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.78      0.74       744\n",
      "          2       0.55      0.56      0.55       638\n",
      "          3       0.54      0.31      0.39       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6424624298226189\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  570   168     6\n",
      "    2  207   377    54\n",
      "    3   20   121    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.77      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.56      0.35      0.43       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6395354787013959\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581   158     5\n",
      "    2  223   364    51\n",
      "    3   18   124    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.78      0.74       744\n",
      "          2       0.56      0.57      0.57       638\n",
      "          3       0.57      0.35      0.43       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6365950701207667\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   171     6\n",
      "    2  204   383    51\n",
      "    3   22   114    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.57      0.60      0.59       638\n",
      "          3       0.59      0.37      0.46       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6385568469441362\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  579   160     5\n",
      "    2  214   379    45\n",
      "    3   19   117    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.78      0.74       744\n",
      "          2       0.58      0.59      0.59       638\n",
      "          3       0.62      0.37      0.47       217\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.628686749815336\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   169     6\n",
      "    2  201   391    46\n",
      "    3   22   113    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.58      0.61      0.60       638\n",
      "          3       0.61      0.38      0.47       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6331473345257095\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568   170     6\n",
      "    2  208   381    49\n",
      "    3   19   114    84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.76      0.74       744\n",
      "          2       0.57      0.60      0.58       638\n",
      "          3       0.60      0.39      0.47       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6331473345257095\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565   174     5\n",
      "    2  201   389    48\n",
      "    3   21   113    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.58      0.61      0.59       638\n",
      "          3       0.61      0.38      0.47       217\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6326532670805687\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   167     6\n",
      "    2  215   375    48\n",
      "    3   19   117    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.60      0.37      0.46       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6361036805684829\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  557   181     6\n",
      "    2  207   385    46\n",
      "    3   20   113    84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.75      0.73       744\n",
      "          2       0.57      0.60      0.58       638\n",
      "          3       0.62      0.39      0.48       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6380669682015703\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566   173     5\n",
      "    2  216   375    47\n",
      "    3   16   121    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.76      0.73       744\n",
      "          2       0.56      0.59      0.57       638\n",
      "          3       0.61      0.37      0.46       217\n",
      "\n",
      "avg / total       0.64      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6331473345257095\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   163    14\n",
      "    2  142   420    76\n",
      "    3   15    66   136\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.76      0.77       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.60      0.63      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5933759848629978\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   163    14\n",
      "    2  142   420    76\n",
      "    3   15    66   136\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.76      0.77       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.60      0.63      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5933759848629978\n",
      "3 neighbours:\n",
      "3 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   158    11\n",
      "    2  139   426    73\n",
      "    3   18    69   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.77      0.78       744\n",
      "          2       0.65      0.67      0.66       638\n",
      "          3       0.61      0.60      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5891450860847319\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  580   151    13\n",
      "    2  138   429    71\n",
      "    3   16    70   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.67      0.67       638\n",
      "          3       0.61      0.60      0.61       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5843487097907776\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  593   141    10\n",
      "    2  128   445    65\n",
      "    3   18    71   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.63      0.59      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5686185711218377\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   141     9\n",
      "    2  129   446    63\n",
      "    3   15    75   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.64      0.59      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5614240804630911\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  593   144     7\n",
      "    2  140   437    61\n",
      "    3   16    71   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.79       744\n",
      "          2       0.67      0.68      0.68       638\n",
      "          3       0.66      0.60      0.63       217\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5636475508693359\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  596   138    10\n",
      "    2  132   447    59\n",
      "    3   15    70   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.66      0.61      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5586322974706716\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   141     6\n",
      "    2  140   445    53\n",
      "    3   15    69   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.69      0.61      0.65       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5518743999732558\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   134     7\n",
      "    2  131   455    52\n",
      "    3   12    74   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.69      0.60      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.540423478357459\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  601   137     6\n",
      "    2  131   456    51\n",
      "    3   12    78   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.71      0.70       638\n",
      "          3       0.69      0.59      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5415794657283098\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   136     8\n",
      "    2  130   458    50\n",
      "    3   14    77   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.72      0.70       638\n",
      "          3       0.68      0.58      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5484642268462742\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  596   143     5\n",
      "    2  133   456    49\n",
      "    3   14    74   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.68      0.71      0.70       638\n",
      "          3       0.70      0.59      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  601   140     3\n",
      "    2  132   461    45\n",
      "    3   14    74   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.68      0.72      0.70       638\n",
      "          3       0.73      0.59      0.65       217\n",
      "\n",
      "avg / total       0.75      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5357745878684697\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   142     4\n",
      "    2  130   462    46\n",
      "    3   13    72   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.80      0.81       744\n",
      "          2       0.68      0.72      0.70       638\n",
      "          3       0.73      0.61      0.66       217\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1599\n",
      "\n",
      "RMSE:\n",
      "0.5351906371904643\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  601   141     2\n",
      "    2  130   463    45\n",
      "    3   12    73   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.73      0.70       638\n",
      "          3       0.74      0.61      0.67       217\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1599\n",
      "\n",
      "RMSE:\n",
      "0.5275404599038089\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  604   140     0\n",
      "    2  133   463    42\n",
      "    3   13    76   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.73      0.70       638\n",
      "          3       0.75      0.59      0.66       217\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1599\n",
      "\n",
      "RMSE:\n",
      "0.5263536407178501\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   137     4\n",
      "    2  127   468    43\n",
      "    3   11    76   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.69      0.73      0.71       638\n",
      "          3       0.73      0.60      0.66       217\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1599\n",
      "\n",
      "RMSE:\n",
      "0.5263536407178501\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  601   141     2\n",
      "    2  130   466    42\n",
      "    3   11    78   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.73      0.70       638\n",
      "          3       0.74      0.59      0.66       217\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1599\n",
      "\n",
      "RMSE:\n",
      "0.5263536407178501\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  601   141     2\n",
      "    2  127   466    45\n",
      "    3   10    80   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.73      0.70       638\n",
      "          3       0.73      0.59      0.65       217\n",
      "\n",
      "avg / total       0.75      0.75      0.75      1599\n",
      "\n",
      "RMSE:\n",
      "0.5251641394443731\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(f_mm_red.values,red_targetclass)\n",
    "run_knnw_report(f_mm_red.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   418   104\n",
      "    2  436  1423   339\n",
      "    3   79   336   645\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.68      0.68      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.59      0.61      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6794240108541295\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1281   321    38\n",
      "    2  795  1243   160\n",
      "    3  183   490   387\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.78      0.66      1640\n",
      "          2       0.61      0.57      0.58      2198\n",
      "          3       0.66      0.37      0.47      1060\n",
      "\n",
      "avg / total       0.60      0.59      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.735552280958793\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1037   522    81\n",
      "    2  603  1272   323\n",
      "    3  147   390   523\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.63      0.61      1640\n",
      "          2       0.58      0.58      0.58      2198\n",
      "          3       0.56      0.49      0.53      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7493021116698383\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1137   429    74\n",
      "    2  683  1250   265\n",
      "    3  121   525   414\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.69      0.64      1640\n",
      "          2       0.57      0.57      0.57      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7399800246716297\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   552    59\n",
      "    2  595  1317   286\n",
      "    3  115   454   491\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.63      0.61      1640\n",
      "          2       0.57      0.60      0.58      2198\n",
      "          3       0.59      0.46      0.52      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.726194261440506\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1097   474    69\n",
      "    2  631  1279   288\n",
      "    3  108   518   434\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.67      0.63      1640\n",
      "          2       0.56      0.58      0.57      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7312373377362732\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  989   578    73\n",
      "    2  540  1334   324\n",
      "    3   89   493   478\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.60      0.61      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.45      0.49      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.726194261440506\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1077   505    58\n",
      "    2  596  1316   286\n",
      "    3   94   548   418\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.66      0.63      1640\n",
      "          2       0.56      0.60      0.58      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7205494478087149\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1008   567    65\n",
      "    2  535  1340   323\n",
      "    3   93   510   457\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.54      0.43      0.48      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7239416177458309\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1053   529    58\n",
      "    2  561  1329   308\n",
      "    3   86   564   410\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.55      0.60      0.58      2198\n",
      "          3       0.53      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7198407337119678\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1020   568    52\n",
      "    2  545  1348   305\n",
      "    3   82   546   432\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7144315315199139\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1058   530    52\n",
      "    2  583  1321   294\n",
      "    3   84   563   413\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.65      0.63      1640\n",
      "          2       0.55      0.60      0.57      2198\n",
      "          3       0.54      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7164291470508282\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1015   575    50\n",
      "    2  540  1345   313\n",
      "    3   75   558   427\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.61      0.58      2198\n",
      "          3       0.54      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7124283147909004\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1048   542    50\n",
      "    2  558  1355   285\n",
      "    3   74   575   411\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7081166251099064\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   561    50\n",
      "    2  550  1353   295\n",
      "    3   75   556   429\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.63      0.62      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.55      0.40      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7089810607828643\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1060   531    49\n",
      "    2  539  1368   291\n",
      "    3   69   574   417\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.65      0.64      1640\n",
      "          2       0.55      0.62      0.59      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7010171691604549\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1034   562    44\n",
      "    2  533  1368   297\n",
      "    3   67   563   430\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.56      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.6998512354317896\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1033   562    45\n",
      "    2  542  1372   284\n",
      "    3   70   578   412\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7037785204155388\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   570    41\n",
      "    2  515  1388   295\n",
      "    3   71   579   410\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.55      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7010171691604549\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1034   566    40\n",
      "    2  533  1382   283\n",
      "    3   67   604   389\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7020357727457922\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   418   104\n",
      "    2  436  1423   339\n",
      "    3   79   336   645\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.68      0.68      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.59      0.61      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6794240108541295\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1132   410    98\n",
      "    2  453  1419   326\n",
      "    3   81   345   634\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.69      0.68      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.60      0.60      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6777692615535915\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1119   430    91\n",
      "    2  439  1435   324\n",
      "    3   67   336   657\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.69      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.61      0.62      0.62      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6642292450622125\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   433    87\n",
      "    2  423  1460   315\n",
      "    3   62   349   649\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.68      0.69      1640\n",
      "          2       0.65      0.66      0.66      2198\n",
      "          3       0.62      0.61      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6572770089983208\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1128   433    79\n",
      "    2  408  1481   309\n",
      "    3   59   347   654\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.69      0.70      1640\n",
      "          2       0.66      0.67      0.66      2198\n",
      "          3       0.63      0.62      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6467874564980506\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   451    71\n",
      "    2  374  1521   303\n",
      "    3   56   356   648\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.68      0.70      1640\n",
      "          2       0.65      0.69      0.67      2198\n",
      "          3       0.63      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6377276933469145\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1132   434    74\n",
      "    2  374  1531   293\n",
      "    3   52   357   651\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.64      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6329073090925854\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1130   442    68\n",
      "    2  374  1525   299\n",
      "    3   49   363   648\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.65      0.69      0.67      2198\n",
      "          3       0.64      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6303213644309911\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1137   436    67\n",
      "    2  372  1534   292\n",
      "    3   44   372   644\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.65      0.70      0.68      2198\n",
      "          3       0.64      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6254439011609174\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1135   444    61\n",
      "    2  367  1536   295\n",
      "    3   46   370   644\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.65      0.70      0.68      2198\n",
      "          3       0.64      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6234822322375225\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   434    60\n",
      "    2  373  1545   280\n",
      "    3   44   368   648\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.66      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6180555396250805\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   436    61\n",
      "    2  379  1540   279\n",
      "    3   44   377   639\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.65      0.70      0.68      2198\n",
      "          3       0.65      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6213501020898674\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   438    58\n",
      "    2  372  1537   289\n",
      "    3   42   371   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.65      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6178903503826205\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   438    57\n",
      "    2  371  1547   280\n",
      "    3   42   371   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.66      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6155730465037192\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   440    58\n",
      "    2  368  1551   279\n",
      "    3   40   371   649\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.66      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6145772415165717\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1148   432    60\n",
      "    2  372  1548   278\n",
      "    3   41   367   652\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.66      0.62      0.64      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6150753455358086\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   440    58\n",
      "    2  362  1567   269\n",
      "    3   45   364   651\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.69      2198\n",
      "          3       0.67      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6140787334652149\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   443    54\n",
      "    2  365  1570   263\n",
      "    3   45   368   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.69      2198\n",
      "          3       0.67      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.612080641182793\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   442    53\n",
      "    2  361  1571   266\n",
      "    3   46   371   643\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.69      2198\n",
      "          3       0.67      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6122473979332465\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1138   447    55\n",
      "    2  361  1581   256\n",
      "    3   43   373   644\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6110791450532307\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(f_mm_white.values,white_targetclass)\n",
    "run_knnw_report(f_mm_white.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
