{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Initializing</h2>\n",
    "<p>Import Libraries, add variables for attribute strings (to save '') and load data</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats.stats import pearsonr\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import preprocessing\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors.nearest_centroid import NearestCentroid\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn import tree\n",
    "from sklearn.metrics import classification_report\n",
    "from scipy import interp\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.model_selection import cross_validate\n",
    "import math\n",
    "\n",
    "fixed_acidity = 'fixed acidity'\n",
    "volatile_acidity = 'volatile acidity'\n",
    "citric_acid = 'citric acid'\n",
    "residual_sugar = 'residual sugar'\n",
    "chlorides = 'chlorides'\n",
    "free_sulfur_dioxide = 'free sulfur dioxide'\n",
    "total_sulfur_dioxide = 'total sulfur dioxide'\n",
    "density = 'density'\n",
    "ph = 'pH'\n",
    "sulphates = 'sulphates'\n",
    "alcohol = 'alcohol'\n",
    "quality = 'quality'\n",
    "qclass = 'qclass'\n",
    "ratio_to_fixed = 'ratio_to_fixed'\n",
    "ratio_to_volatile = 'ratio_to_volatile'\n",
    "ph_acidity = 'ph_acidity'\n",
    "ratio_to_ph = 'ratio_to_ph'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_report(y_true, y_pred):\n",
    "    cm, labels = confusion_matrix(y_true, y_pred), unique_labels(y_true, y_pred)\n",
    "    column_width = max([len(str(x)) for x in labels] + [5])  # 5 is value length\n",
    "    report = \" \" * column_width + \" \" + \"{:_^{}}\".format(\"Prediction\", column_width * len(labels))+ \"\\n\"\n",
    "    report += \" \" * column_width + \" \".join([\"{:>{}}\".format(label, column_width) for label in labels]) + \"\\n\"\n",
    "    for i, label1 in enumerate(labels):\n",
    "        report += \"{:>{}}\".format(label1, column_width) + \" \".join([\"{:{}d}\".format(cm[i, j], column_width) for j in range(len(labels))]) + \"\\n\"\n",
    "    return report\n",
    "def root_mean_squared_error(y_true, y_pred):\n",
    "        return math.sqrt(np.mean((y_pred - y_true)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Import red and white dataset.<br/>\n",
    "Split into input matrix (independent vars) and output vector (target vars).<br/>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>sort for kNN (https://scikit-learn.org/stable/modules/neighbors.html#unsupervised-nearest-neighbors) </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "white = pd.read_csv(\"data/winequality-white1.csv\")\n",
    "red = pd.read_csv(\"data/winequality-red1.csv\")\n",
    "white.sort_values(by='quality',inplace=True)\n",
    "red.sort_values(by='quality',inplace=True)\n",
    "white_target = white[quality]\n",
    "red_target = red[quality]\n",
    "white_input = white.drop(quality,axis=1)\n",
    "red_input = red.drop(quality,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add ratio of acidity to sugar as attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#white[ph_acidity] = 7 - white[ph]\n",
    "#red[ph_acidity] = 7 - red[ph]\n",
    "#white_input[ratio_to_fixed]=white[residual_sugar]/white[fixed_acidity]\n",
    "#white_input[ratio_to_volatile]=white[residual_sugar]/white[volatile_acidity]\n",
    "#white_input[ratio_to_ph]=white[residual_sugar]/white[ph_acidity]\n",
    "#red_input[ratio_to_fixed]=red[residual_sugar]/red[fixed_acidity]\n",
    "#red_input[ratio_to_volatile]=red[residual_sugar]/red[volatile_acidity]\n",
    "#red_input[ratio_to_ph]=red[residual_sugar]/red[ph_acidity]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>using log. (and filtering based on results of naive bayes)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_white_norm=np.log(white_input+1)\n",
    "log_red_norm=np.log(red_input+1)\n",
    "f_log_white=log_white_norm.drop([fixed_acidity,sulphates,chlorides,citric_acid,ph,density,total_sulfur_dioxide,residual_sugar],axis=1)\n",
    "f_log_red=log_red_norm.drop([free_sulfur_dioxide,ph,residual_sugar,chlorides,citric_acid,fixed_acidity,density],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Normalize using MinMax Normalizer. (and filtering based on results of naive bayes)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_white_norm=(white_input-white_input.min())/(white_input.max()-white_input.min())\n",
    "mm_red_norm=(red_input-red_input.min())/(red_input.max()-red_input.min())\n",
    "f_mm_white = mm_white_norm.drop([fixed_acidity,sulphates,chlorides,citric_acid,ph,density,total_sulfur_dioxide,residual_sugar],axis=1)\n",
    "f_mm_red = mm_red_norm.drop([free_sulfur_dioxide,ph,residual_sugar,chlorides,citric_acid,fixed_acidity,density],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Normalize using Std. Normalizer. (and filtering based on results of naive bayes)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_norm=(white_input-white_input.mean())/(white_input.std())\n",
    "red_norm=(red_input-red_input.mean())/(red_input.std())\n",
    "f_white_norm=white_norm.drop([fixed_acidity,sulphates,chlorides,citric_acid,ph,density,total_sulfur_dioxide,residual_sugar],axis=1)\n",
    "f_red_norm=red_norm.drop([free_sulfur_dioxide,ph,residual_sugar,chlorides,citric_acid,fixed_acidity,density],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Correlation Matrices</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wcorr = white.corr()\n",
    "#wcorr.style.background_gradient().set_precision(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rcorr = red.corr()\n",
    "#rcorr.style.background_gradient().set_precision(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Assigning classes</h2>\n",
    "<p>\n",
    "    Assign classes based on quality. Less than 6; 6; better than 6. Because it makes sense considering the distribution of ratings.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2    2198\n",
      "1    1640\n",
      "3    1060\n",
      "Name: classnum, dtype: int64\n",
      "1    744\n",
      "2    638\n",
      "3    217\n",
      "Name: classnum, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#Assign classes for white\n",
    "conditions = [(white['quality'] < 6),\n",
    "             (white['quality'] > 6)]\n",
    "choices = [1,3]\n",
    "white['classnum'] = np.select(conditions, choices, default = 2)\n",
    "white_classnum = white['classnum']\n",
    "white.drop('classnum',axis=1,inplace=True)\n",
    "#choices = ['2_low', '1_high']\n",
    "#white['class'] = np.select(conditions, choices, default = '3_medium')\n",
    "#choices = [1,3]\n",
    "#white['classnum'] = np.select(conditions, choices, default = 2)\n",
    "#white_classnum = white['classnum']\n",
    "#white.drop('classnum',axis=1,inplace=True)\n",
    "#Assign classes for red\n",
    "conditions = [(red['quality'] < 6),\n",
    "              (red['quality'] > 6)]\n",
    "#choices = ['3_low', '1_high']\n",
    "#red['class'] = np.select(conditions, choices, default = '2_medium')\n",
    "#choices = [1,3]\n",
    "red['classnum'] = np.select(conditions, choices, default = 2)\n",
    "red_classnum = red['classnum']\n",
    "red.drop('classnum',axis=1,inplace=True)\n",
    "\n",
    "#print('class distribution fot white:')\n",
    "#print(white['class'].value_counts())\n",
    "#print('\\n class distribution for red:')\n",
    "#print(red['class'].value_counts())\n",
    "\n",
    "#white_norm['class']=white['class']\n",
    "#red_norm['class']=red['class']\n",
    "\n",
    "white_targetclass = white_classnum\n",
    "red_targetclass = red_classnum\n",
    "print(white_targetclass.value_counts())\n",
    "print(red_targetclass.value_counts())\n",
    "#white_targetclass = white['class']\n",
    "#red_targetclass = red['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "3307       3.016125         -0.379397    -0.365159        0.415726  -0.401518   \n",
      "445        0.290581          0.414297    -0.117266        0.908622  -0.355747   \n",
      "2050       5.860171         -0.478608     0.378521        0.928338  -0.538831   \n",
      "3810      -0.064924         -0.180973     0.047996        1.716973   0.651211   \n",
      "3409      -0.775936         -0.478608     0.130627       -1.122112   0.239274   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
      "3307             5.214982              1.638647 -0.025871 -1.909043   \n",
      "445             -1.135293             -1.702681 -0.109457  0.342604   \n",
      "2050            -1.194092             -0.361444  1.896623 -1.710368   \n",
      "3810             0.393477              0.556245  1.010604  0.342604   \n",
      "3409            -0.664902             -0.643809 -0.811585  1.203527   \n",
      "\n",
      "      sulphates   alcohol  \n",
      "3307  -0.962507  0.394706  \n",
      "445   -0.787262  0.801005  \n",
      "2050   0.527077 -0.661672  \n",
      "3810   0.264209 -0.011593  \n",
      "3409  -0.524394  0.394706  \n",
      "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "1478      -0.700500          1.938904    -1.134365        2.242096  -0.116148   \n",
      "832        1.194858         -0.490454     0.765008       -0.736779   1.222418   \n",
      "899       -0.011279          2.748689    -1.288368        0.610807  -0.073654   \n",
      "1374      -0.872805          1.603820    -1.391037       -0.949556   3.814561   \n",
      "459        1.884079          0.291408     1.997033       -0.240300  -0.286125   \n",
      "\n",
      "      free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
      "1478            -1.230854             -0.987003  0.706457  0.575742   \n",
      "832              1.732773              0.046578  0.833621  0.446197   \n",
      "899             -0.944051             -1.078202  1.151530  1.093922   \n",
      "1374             0.011958             -0.531011 -1.079130  0.057562   \n",
      "459             -0.561648              0.016179  2.147644 -0.395846   \n",
      "\n",
      "      sulphates   alcohol  \n",
      "1478  -0.815004 -0.209243  \n",
      "832    1.190813 -0.490756  \n",
      "899   -0.991988  0.541460  \n",
      "1374  -0.873998 -0.584594  \n",
      "459   -0.520031 -1.335297  \n"
     ]
    }
   ],
   "source": [
    "white_norm_input = white_norm\n",
    "red_norm_input = red_norm\n",
    "print(white_norm_input.head())\n",
    "print(red_norm_input.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.898000e+03</td>\n",
       "      <td>4.898000e+03</td>\n",
       "      <td>4.898000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.998539e-14</td>\n",
       "      <td>-6.380722e-17</td>\n",
       "      <td>-4.325046e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.966784e+00</td>\n",
       "      <td>-1.958477e+00</td>\n",
       "      <td>-2.043089e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.770318e-01</td>\n",
       "      <td>-7.237012e-01</td>\n",
       "      <td>-8.241915e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.809733e-01</td>\n",
       "      <td>-7.691388e-02</td>\n",
       "      <td>-9.285319e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.142970e-01</td>\n",
       "      <td>6.286722e-01</td>\n",
       "      <td>7.197450e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.152811e+00</td>\n",
       "      <td>1.491679e+01</td>\n",
       "      <td>2.995020e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       volatile acidity  free sulfur dioxide       alcohol\n",
       "count      4.898000e+03         4.898000e+03  4.898000e+03\n",
       "mean      -1.998539e-14        -6.380722e-17 -4.325046e-14\n",
       "std        1.000000e+00         1.000000e+00  1.000000e+00\n",
       "min       -1.966784e+00        -1.958477e+00 -2.043089e+00\n",
       "25%       -6.770318e-01        -7.237012e-01 -8.241915e-01\n",
       "50%       -1.809733e-01        -7.691388e-02 -9.285319e-02\n",
       "75%        4.142970e-01         6.286722e-01  7.197450e-01\n",
       "max        8.152811e+00         1.491679e+01  2.995020e+00"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#white_norm.loc[white_norm['class']=='3_high'].describe()\n",
    "#white_norm.loc[white_norm['class']=='2_medium'].describe()\n",
    "#white_norm.loc[white_norm['class']=='1_low'].describe()\n",
    "white_norm_filtered = white_norm_input.drop([fixed_acidity,sulphates,chlorides,citric_acid,ph,density,total_sulfur_dioxide,residual_sugar],axis=1)\n",
    "white_norm_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.599000e+03</td>\n",
       "      <td>1.599000e+03</td>\n",
       "      <td>1.599000e+03</td>\n",
       "      <td>1.599000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.477896e-15</td>\n",
       "      <td>2.365560e-16</td>\n",
       "      <td>6.625737e-15</td>\n",
       "      <td>2.204136e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-2.277567e+00</td>\n",
       "      <td>-1.230199e+00</td>\n",
       "      <td>-1.935902e+00</td>\n",
       "      <td>-1.898325e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-7.696903e-01</td>\n",
       "      <td>-7.438076e-01</td>\n",
       "      <td>-6.380200e-01</td>\n",
       "      <td>-8.661079e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-4.367545e-02</td>\n",
       "      <td>-2.574163e-01</td>\n",
       "      <td>-2.250577e-01</td>\n",
       "      <td>-2.092427e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.264921e-01</td>\n",
       "      <td>4.721707e-01</td>\n",
       "      <td>4.238832e-01</td>\n",
       "      <td>6.352984e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.876138e+00</td>\n",
       "      <td>7.372847e+00</td>\n",
       "      <td>7.916200e+00</td>\n",
       "      <td>4.201138e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       volatile acidity  total sulfur dioxide     sulphates       alcohol\n",
       "count      1.599000e+03          1.599000e+03  1.599000e+03  1.599000e+03\n",
       "mean       8.477896e-15          2.365560e-16  6.625737e-15  2.204136e-14\n",
       "std        1.000000e+00          1.000000e+00  1.000000e+00  1.000000e+00\n",
       "min       -2.277567e+00         -1.230199e+00 -1.935902e+00 -1.898325e+00\n",
       "25%       -7.696903e-01         -7.438076e-01 -6.380200e-01 -8.661079e-01\n",
       "50%       -4.367545e-02         -2.574163e-01 -2.250577e-01 -2.092427e-01\n",
       "75%        6.264921e-01          4.721707e-01  4.238832e-01  6.352984e-01\n",
       "max        5.876138e+00          7.372847e+00  7.916200e+00  4.201138e+00"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#red_norm.loc[red_norm['class']=='3_high'].describe()\n",
    "#red_norm.loc[red_norm['class']=='2_medium'].describe()\n",
    "#red_norm.loc[red_norm['class']=='1_low'].describe()\n",
    "red_norm_filtered = red_norm_input.drop([free_sulfur_dioxide,ph,residual_sugar,chlorides,citric_acid,fixed_acidity,density],axis=1)\n",
    "red_norm_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>k-NN classification<h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.898000e+03</td>\n",
       "      <td>4.898000e+03</td>\n",
       "      <td>4.898000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-1.998539e-14</td>\n",
       "      <td>-6.380722e-17</td>\n",
       "      <td>-4.325046e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.966784e+00</td>\n",
       "      <td>-1.958477e+00</td>\n",
       "      <td>-2.043089e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-6.770318e-01</td>\n",
       "      <td>-7.237012e-01</td>\n",
       "      <td>-8.241915e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.809733e-01</td>\n",
       "      <td>-7.691388e-02</td>\n",
       "      <td>-9.285319e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.142970e-01</td>\n",
       "      <td>6.286722e-01</td>\n",
       "      <td>7.197450e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8.152811e+00</td>\n",
       "      <td>1.491679e+01</td>\n",
       "      <td>2.995020e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       volatile acidity  free sulfur dioxide       alcohol\n",
       "count      4.898000e+03         4.898000e+03  4.898000e+03\n",
       "mean      -1.998539e-14        -6.380722e-17 -4.325046e-14\n",
       "std        1.000000e+00         1.000000e+00  1.000000e+00\n",
       "min       -1.966784e+00        -1.958477e+00 -2.043089e+00\n",
       "25%       -6.770318e-01        -7.237012e-01 -8.241915e-01\n",
       "50%       -1.809733e-01        -7.691388e-02 -9.285319e-02\n",
       "75%        4.142970e-01         6.286722e-01  7.197450e-01\n",
       "max        8.152811e+00         1.491679e+01  2.995020e+00"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "white_norm_filtered.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>white: knn normalized and filtered based on Naive Bayes results</h3>\n",
    "RMSE/P/R/F1\n",
    "<p>White,STD Normed, filteredNB:0.68/0.66/0.66/0.66 at k=1, decreasing after<br>\n",
    "White log normed, filteredNB: 0.69/0.64/0.64/0.64 at k=1, decreasing after<br/>\n",
    "White MM normed, filteredNB: 0.68/0.65/0.65/0.65 at k=1, decreasing after</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white STD normed filtered____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1129   416    95\n",
      "    2  428  1432   338\n",
      "    3   86   332   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.69      0.69      1640\n",
      "          2       0.66      0.65      0.65      2198\n",
      "          3       0.60      0.61      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6759594605620941\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1306   296    38\n",
      "    2  796  1243   159\n",
      "    3  193   492   375\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.80      0.66      1640\n",
      "          2       0.61      0.57      0.59      2198\n",
      "          3       0.66      0.35      0.46      1060\n",
      "\n",
      "avg / total       0.61      0.60      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.7379078278712365\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1024   538    78\n",
      "    2  618  1240   340\n",
      "    3  167   379   514\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.62      0.59      1640\n",
      "          2       0.57      0.56      0.57      2198\n",
      "          3       0.55      0.48      0.52      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7634729699920844\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   410    67\n",
      "    2  702  1238   258\n",
      "    3  126   512   422\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.71      0.64      1640\n",
      "          2       0.57      0.56      0.57      2198\n",
      "          3       0.56      0.40      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7361072054292438\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1035   541    64\n",
      "    2  594  1283   321\n",
      "    3  121   473   466\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.63      0.61      1640\n",
      "          2       0.56      0.58      0.57      2198\n",
      "          3       0.55      0.44      0.49      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7381844568698466\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1104   467    69\n",
      "    2  660  1258   280\n",
      "    3  116   523   421\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.67      0.63      1640\n",
      "          2       0.56      0.57      0.57      2198\n",
      "          3       0.55      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7383227325022048\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  999   571    70\n",
      "    2  556  1317   325\n",
      "    3   78   535   447\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.61      0.61      1640\n",
      "          2       0.54      0.60      0.57      2198\n",
      "          3       0.53      0.42      0.47      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7256317561187315\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1067   517    56\n",
      "    2  627  1284   287\n",
      "    3   84   571   405\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.65      0.62      1640\n",
      "          2       0.54      0.58      0.56      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7232362277140099\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   564    60\n",
      "    2  559  1327   312\n",
      "    3   74   541   445\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.55      0.60      0.57      2198\n",
      "          3       0.54      0.42      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7161441145561368\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1044   552    44\n",
      "    2  597  1306   295\n",
      "    3   67   574   419\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.64      0.62      1640\n",
      "          2       0.54      0.59      0.56      2198\n",
      "          3       0.55      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7089810607828643\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   583    41\n",
      "    2  551  1340   307\n",
      "    3   66   555   439\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.61      0.57      2198\n",
      "          3       0.56      0.41      0.48      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7034883622830594\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1047   548    45\n",
      "    2  577  1325   296\n",
      "    3   72   581   407\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.54      0.60      0.57      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7101320048210269\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1001   585    54\n",
      "    2  561  1335   302\n",
      "    3   66   560   434\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.61      0.61      1640\n",
      "          2       0.54      0.61      0.57      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7127148333284402\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1031   559    50\n",
      "    2  574  1328   296\n",
      "    3   67   576   417\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.63      0.62      1640\n",
      "          2       0.54      0.60      0.57      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7105631282067815\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1008   579    53\n",
      "    2  533  1363   302\n",
      "    3   68   573   419\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.61      0.62      1640\n",
      "          2       0.54      0.62      0.58      2198\n",
      "          3       0.54      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7102757416922127\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   556    55\n",
      "    2  549  1372   277\n",
      "    3   59   601   400\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.54      0.62      0.58      2198\n",
      "          3       0.55      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.70566164012725\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1018   575    47\n",
      "    2  532  1383   283\n",
      "    3   66   605   389\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7068179893504523\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1027   569    44\n",
      "    2  554  1373   271\n",
      "    3   67   619   374\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.63      0.62      1640\n",
      "          2       0.54      0.62      0.58      2198\n",
      "          3       0.54      0.35      0.43      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7082607709892844\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1015   575    50\n",
      "    2  542  1378   278\n",
      "    3   64   607   389\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.62      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7084048875379302\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1035   563    42\n",
      "    2  540  1392   266\n",
      "    3   65   612   383\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.63      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.36      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7013083497209496\n"
     ]
    }
   ],
   "source": [
    "def run_knn_report(inputs, targets):\n",
    "    print(\"_______________________________________________________________________________________________\")\n",
    "    print(\"KNN, no weights\")\n",
    "    for n_neighbour in range(1,21):\n",
    "        print(str(n_neighbour) + \" neighbours:\")\n",
    "        knn_estimator = KNeighborsClassifier(n_neighbour)\n",
    "        predicted = cross_val_predict(knn_estimator,inputs,targets,cv=cv)\n",
    "        print(confusion_matrix_report(targets,predicted))\n",
    "        print(classification_report(targets,predicted))\n",
    "        try:\n",
    "            print(\"RMSE:\")\n",
    "            print(root_mean_squared_error(targets,predicted))\n",
    "        except(Error):\n",
    "            pass\n",
    "    \n",
    "cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "#cv = KFold(n_splits=3)\n",
    "print(\"#____________________white STD normed filtered____________________#\")\n",
    "run_knn_report(f_white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white log normed filtered____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1090   455    95\n",
      "    2  459  1372   367\n",
      "    3  102   330   628\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.66      0.66      1640\n",
      "          2       0.64      0.62      0.63      2198\n",
      "          3       0.58      0.59      0.58      1060\n",
      "\n",
      "avg / total       0.63      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.6998512354317896\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1278   325    37\n",
      "    2  807  1229   162\n",
      "    3  203   507   350\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.56      0.78      0.65      1640\n",
      "          2       0.60      0.56      0.58      2198\n",
      "          3       0.64      0.33      0.44      1060\n",
      "\n",
      "avg / total       0.59      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.750799220278691\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1013   532    95\n",
      "    2  599  1254   345\n",
      "    3  155   412   493\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.62      0.59      1640\n",
      "          2       0.57      0.57      0.57      2198\n",
      "          3       0.53      0.47      0.49      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7678726585594571\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   423    91\n",
      "    2  656  1273   269\n",
      "    3  111   533   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.69      0.64      1640\n",
      "          2       0.57      0.58      0.58      2198\n",
      "          3       0.54      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7409450665670629\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  994   560    86\n",
      "    2  564  1353   281\n",
      "    3  105   485   470\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.61      0.60      1640\n",
      "          2       0.56      0.62      0.59      2198\n",
      "          3       0.56      0.44      0.50      1060\n",
      "\n",
      "avg / total       0.57      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7361072054292438\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1062   490    88\n",
      "    2  642  1285   271\n",
      "    3  108   519   433\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.65      0.62      1640\n",
      "          2       0.56      0.58      0.57      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7432835233476071\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  974   585    81\n",
      "    2  560  1325   313\n",
      "    3   86   511   463\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.59      0.60      1640\n",
      "          2       0.55      0.60      0.57      2198\n",
      "          3       0.54      0.44      0.48      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7337458779951597\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1035   537    68\n",
      "    2  620  1309   269\n",
      "    3   82   553   425\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.63      0.61      1640\n",
      "          2       0.55      0.60      0.57      2198\n",
      "          3       0.56      0.40      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7256317561187315\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  983   586    71\n",
      "    2  549  1355   294\n",
      "    3   87   525   448\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.60      0.60      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.55      0.42      0.48      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7266158546611806\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1026   545    69\n",
      "    2  577  1341   280\n",
      "    3   76   563   421\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.63      0.62      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7208327383436658\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  982   594    64\n",
      "    2  530  1378   290\n",
      "    3   77   548   435\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.60      0.61      1640\n",
      "          2       0.55      0.63      0.58      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.718136966272786\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1023   556    61\n",
      "    2  574  1344   280\n",
      "    3   77   572   411\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.62      0.62      1640\n",
      "          2       0.54      0.61      0.58      2198\n",
      "          3       0.55      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.719273259651585\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  991   594    55\n",
      "    2  532  1380   286\n",
      "    3   71   582   407\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.60      0.61      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7141457017299102\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   561    50\n",
      "    2  572  1354   272\n",
      "    3   70   607   383\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.63      0.62      1640\n",
      "          2       0.54      0.62      0.57      2198\n",
      "          3       0.54      0.36      0.43      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7132875251310331\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   581    54\n",
      "    2  535  1385   278\n",
      "    3   71   589   400\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.71199832079853\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1017   570    53\n",
      "    2  565  1359   274\n",
      "    3   61   604   395\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.62      0.57      2198\n",
      "          3       0.55      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7099882388503623\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1001   592    47\n",
      "    2  550  1376   272\n",
      "    3   66   601   393\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.61      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7097006195398559\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   574    44\n",
      "    2  575  1360   263\n",
      "    3   63   615   382\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.53      0.62      0.57      2198\n",
      "          3       0.55      0.36      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7079724498818805\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  988   609    43\n",
      "    2  537  1397   264\n",
      "    3   65   604   391\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.60      0.61      1640\n",
      "          2       0.54      0.64      0.58      2198\n",
      "          3       0.56      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7066735491753771\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   582    42\n",
      "    2  570  1366   262\n",
      "    3   68   619   373\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.62      0.62      1640\n",
      "          2       0.53      0.62      0.57      2198\n",
      "          3       0.55      0.35      0.43      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7105631282067815\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white log normed filtered____________________#\")\n",
    "run_knn_report(f_log_white.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white MinMax normed filtered____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   414    95\n",
      "    2  441  1419   338\n",
      "    3   82   325   653\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.69      0.69      1640\n",
      "          2       0.66      0.65      0.65      2198\n",
      "          3       0.60      0.62      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6741448010182188\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1285   319    36\n",
      "    2  796  1242   160\n",
      "    3  183   503   374\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.78      0.66      1640\n",
      "          2       0.60      0.57      0.58      2198\n",
      "          3       0.66      0.35      0.46      1060\n",
      "\n",
      "avg / total       0.60      0.59      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7361072054292438\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1032   525    83\n",
      "    2  596  1266   336\n",
      "    3  150   396   514\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.63      0.60      1640\n",
      "          2       0.58      0.58      0.58      2198\n",
      "          3       0.55      0.48      0.52      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.754055321802119\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   429    72\n",
      "    2  664  1267   267\n",
      "    3  122   522   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.69      0.64      1640\n",
      "          2       0.57      0.58      0.57      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7366617118773167\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1032   543    65\n",
      "    2  572  1320   306\n",
      "    3  111   467   482\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.63      0.62      1640\n",
      "          2       0.57      0.60      0.58      2198\n",
      "          3       0.57      0.45      0.50      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7274583081089594\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1103   454    83\n",
      "    2  629  1294   275\n",
      "    3   99   528   433\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.67      0.64      1640\n",
      "          2       0.57      0.59      0.58      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7305389923016928\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   557    78\n",
      "    2  525  1349   324\n",
      "    3   82   504   474\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.56      0.61      0.59      2198\n",
      "          3       0.54      0.45      0.49      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7215404780706953\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1053   528    59\n",
      "    2  582  1330   286\n",
      "    3   91   545   424\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7202660458517116\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1006   566    68\n",
      "    2  539  1331   328\n",
      "    3   95   520   445\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.61      0.61      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.42      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7292802853399679\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1045   532    63\n",
      "    2  560  1351   287\n",
      "    3   84   576   400\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.38      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7205494478087149\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   577    58\n",
      "    2  536  1363   299\n",
      "    3   80   555   425\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.54      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7171412326525626\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1051   530    59\n",
      "    2  573  1339   286\n",
      "    3   81   583   396\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7189893546633582\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1019   565    56\n",
      "    2  536  1345   317\n",
      "    3   76   559   425\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.61      0.58      2198\n",
      "          3       0.53      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7151456061924379\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1051   538    51\n",
      "    2  547  1372   279\n",
      "    3   71   573   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.64      0.64      1640\n",
      "          2       0.55      0.62      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7036334563059045\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   571    53\n",
      "    2  525  1390   283\n",
      "    3   69   563   428\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.56      0.40      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7043584780915559\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1039   553    48\n",
      "    2  526  1396   276\n",
      "    3   70   580   410\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.63      1640\n",
      "          2       0.55      0.64      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7010171691604549\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   569    49\n",
      "    2  522  1386   290\n",
      "    3   67   580   413\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7036334563059045\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1039   554    47\n",
      "    2  522  1396   280\n",
      "    3   66   585   409\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.64      1640\n",
      "          2       0.55      0.64      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.6989755088296373\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   575    49\n",
      "    2  514  1389   295\n",
      "    3   61   584   415\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7011627745559728\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1018   577    45\n",
      "    2  521  1386   291\n",
      "    3   64   595   401\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7029076866890369\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white MinMax normed filtered____________________#\")\n",
    "run_knn_report(f_mm_white.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i>red: </i>knn normalized and filtered based on Naive Bayes results</h3>\n",
    "<p>\n",
    "    STD,NBF: 0.6/0.7/0.7/0.7 at k=1, decreasing after<br>\n",
    "    MM,NBF: 0.6/0.7/0.7/0.7 at k=1, decreasing after<br>\n",
    "    log NBF: 0.59/0.69/0.69/0.69 at k=1, decreasing after<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red STD normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   155    13\n",
      "    2  150   407    81\n",
      "    3   17    70   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.77      0.77       744\n",
      "          2       0.64      0.64      0.64       638\n",
      "          3       0.58      0.60      0.59       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.6001875879364265\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  649    88     7\n",
      "    2  268   333    37\n",
      "    3   39   118    60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.87      0.76       744\n",
      "          2       0.62      0.52      0.57       638\n",
      "          3       0.58      0.28      0.37       217\n",
      "\n",
      "avg / total       0.64      0.65      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6592773727035149\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   157    16\n",
      "    2  198   355    85\n",
      "    3   37    94    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.59      0.56      0.57       638\n",
      "          3       0.46      0.40      0.43       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.683038497079636\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  619   114    11\n",
      "    2  239   344    55\n",
      "    3   23   118    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.83      0.76       744\n",
      "          2       0.60      0.54      0.57       638\n",
      "          3       0.54      0.35      0.42       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6434351214164253\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   162     7\n",
      "    2  199   377    62\n",
      "    3   25   107    85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.77      0.75       744\n",
      "          2       0.58      0.59      0.59       638\n",
      "          3       0.55      0.39      0.46       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6414882633337861\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   131     7\n",
      "    2  237   346    55\n",
      "    3   26   115    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.81      0.75       744\n",
      "          2       0.58      0.54      0.56       638\n",
      "          3       0.55      0.35      0.43       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6473112716665117\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  586   152     6\n",
      "    2  207   368    63\n",
      "    3   28   105    84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.59      0.58      0.58       638\n",
      "          3       0.55      0.39      0.45       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6439209162167846\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  616   122     6\n",
      "    2  230   353    55\n",
      "    3   24   120    73\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.83      0.76       744\n",
      "          2       0.59      0.55      0.57       638\n",
      "          3       0.54      0.34      0.42       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6361036805684829\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  586   151     7\n",
      "    2  206   373    59\n",
      "    3   28   107    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.59      0.58      0.59       638\n",
      "          3       0.55      0.38      0.45       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6439209162167846\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  602   137     5\n",
      "    2  220   365    53\n",
      "    3   24   120    73\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.81      0.76       744\n",
      "          2       0.59      0.57      0.58       638\n",
      "          3       0.56      0.34      0.42       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6356119111246085\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   151     5\n",
      "    2  217   369    52\n",
      "    3   25   114    78\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.58      0.36      0.44       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6395354787013959\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  602   136     6\n",
      "    2  219   368    51\n",
      "    3   29   115    73\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.81      0.76       744\n",
      "          2       0.59      0.58      0.59       638\n",
      "          3       0.56      0.34      0.42       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6429489595627921\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  582   155     7\n",
      "    2  204   383    51\n",
      "    3   28   111    78\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.78      0.75       744\n",
      "          2       0.59      0.60      0.60       638\n",
      "          3       0.57      0.36      0.44       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6429489595627921\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   132     9\n",
      "    2  215   370    53\n",
      "    3   24   121    72\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.81      0.76       744\n",
      "          2       0.59      0.58      0.59       638\n",
      "          3       0.54      0.33      0.41       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6390463501566458\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581   154     9\n",
      "    2  203   382    53\n",
      "    3   24   109    84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.78      0.75       744\n",
      "          2       0.59      0.60      0.60       638\n",
      "          3       0.58      0.39      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6380669682015703\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  593   140    11\n",
      "    2  211   378    49\n",
      "    3   26   110    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.60      0.59      0.60       638\n",
      "          3       0.57      0.37      0.45       217\n",
      "\n",
      "avg / total       0.65      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6414882633337861\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   160     9\n",
      "    2  205   387    46\n",
      "    3   25   111    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.59      0.61      0.60       638\n",
      "          3       0.60      0.37      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6414882633337861\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  587   148     9\n",
      "    2  219   370    49\n",
      "    3   23   115    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.58      0.36      0.45       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6419755313594827\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   163     7\n",
      "    2  203   390    45\n",
      "    3   21   116    80\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.77      0.74       744\n",
      "          2       0.58      0.61      0.60       638\n",
      "          3       0.61      0.37      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6321588134942232\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581   157     6\n",
      "    2  213   381    44\n",
      "    3   21   118    78\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.78      0.75       744\n",
      "          2       0.58      0.60      0.59       638\n",
      "          3       0.61      0.36      0.45       217\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6326532670805687\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red STD normed____________________#\")\n",
    "run_knn_report(f_red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red MinMax normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   152    15\n",
      "    2  139   420    79\n",
      "    3   16    68   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.59      0.61      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5928487737550271\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  641    99     4\n",
      "    2  268   334    36\n",
      "    3   37   122    58\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.86      0.76       744\n",
      "          2       0.60      0.52      0.56       638\n",
      "          3       0.59      0.27      0.37       217\n",
      "\n",
      "avg / total       0.64      0.65      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6564254024206326\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   170    14\n",
      "    2  192   362    84\n",
      "    3   39    89    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.75      0.73       744\n",
      "          2       0.58      0.57      0.58       638\n",
      "          3       0.48      0.41      0.44       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6834961443652051\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  607   118    19\n",
      "    2  220   365    53\n",
      "    3   29   113    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.82      0.76       744\n",
      "          2       0.61      0.57      0.59       638\n",
      "          3       0.51      0.35      0.41       217\n",
      "\n",
      "avg / total       0.64      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6597515024826716\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565   169    10\n",
      "    2  184   390    64\n",
      "    3   27   107    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.76      0.74       744\n",
      "          2       0.59      0.61      0.60       638\n",
      "          3       0.53      0.38      0.44       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6482766879698075\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   136    10\n",
      "    2  227   357    54\n",
      "    3   30   114    73\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.80      0.75       744\n",
      "          2       0.59      0.56      0.57       638\n",
      "          3       0.53      0.34      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6573774339614009\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566   168    10\n",
      "    2  194   379    65\n",
      "    3   24   109    84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.58      0.59      0.59       638\n",
      "          3       0.53      0.39      0.45       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6482766879698075\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  596   142     6\n",
      "    2  223   361    54\n",
      "    3   21   124    72\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.58      0.57      0.57       638\n",
      "          3       0.55      0.33      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6380669682015703\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   170    10\n",
      "    2  204   378    56\n",
      "    3   25   113    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.76      0.73       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.54      0.36      0.44       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6535609869991703\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  590   149     5\n",
      "    2  219   363    56\n",
      "    3   20   129    68\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.53      0.31      0.39       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6390463501566458\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   162     5\n",
      "    2  209   371    58\n",
      "    3   24   112    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.78      0.74       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.56      0.37      0.45       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6410006249027402\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  592   145     7\n",
      "    2  220   361    57\n",
      "    3   21   124    72\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.53      0.33      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6414882633337861\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   163     7\n",
      "    2  208   374    56\n",
      "    3   20   115    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.77      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.57      0.38      0.45       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6375767130633383\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   150     6\n",
      "    2  217   370    51\n",
      "    3   20   120    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.57      0.35      0.44       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6336410167329005\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   168     5\n",
      "    2  200   387    51\n",
      "    3   21   114    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.77      0.74       744\n",
      "          2       0.58      0.61      0.59       638\n",
      "          3       0.59      0.38      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6311687442672026\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   149     4\n",
      "    2  214   371    53\n",
      "    3   19   115    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.79      0.75       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.59      0.38      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6241942899207995\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   174     3\n",
      "    2  202   385    51\n",
      "    3   19   115    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.57      0.60      0.59       638\n",
      "          3       0.61      0.38      0.47       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6276912040603917\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   165     4\n",
      "    2  210   377    51\n",
      "    3   20   115    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.60      0.38      0.46       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6311687442672026\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566   174     4\n",
      "    2  202   385    51\n",
      "    3   20   114    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.57      0.60      0.59       638\n",
      "          3       0.60      0.38      0.47       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6311687442672026\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   167     4\n",
      "    2  219   369    50\n",
      "    3   20   112    85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.57      0.58      0.57       638\n",
      "          3       0.61      0.39      0.48       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6346272290288927\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red MinMax normed____________________#\")\n",
    "run_knn_report(f_mm_red.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red log normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   162    19\n",
      "    2  159   395    84\n",
      "    3   18    77   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.76      0.76       744\n",
      "          2       0.62      0.62      0.62       638\n",
      "          3       0.54      0.56      0.55       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6276912040603917\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  643    94     7\n",
      "    2  294   311    33\n",
      "    3   37   116    64\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.86      0.75       744\n",
      "          2       0.60      0.49      0.54       638\n",
      "          3       0.62      0.29      0.40       217\n",
      "\n",
      "avg / total       0.63      0.64      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6677602038203002\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   172    13\n",
      "    2  224   339    75\n",
      "    3   29    93    95\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.56      0.53      0.55       638\n",
      "          3       0.52      0.44      0.47       217\n",
      "\n",
      "avg / total       0.61      0.62      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6765989331374249\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   124     7\n",
      "    2  262   323    53\n",
      "    3   23   125    69\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.82      0.75       744\n",
      "          2       0.56      0.51      0.53       638\n",
      "          3       0.53      0.32      0.40       217\n",
      "\n",
      "avg / total       0.62      0.63      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6540392607455786\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   178    11\n",
      "    2  242   334    62\n",
      "    3   21   112    84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.54      0.52      0.53       638\n",
      "          3       0.54      0.39      0.45       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6719614629052536\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   137    10\n",
      "    2  260   323    55\n",
      "    3   24   122    71\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.80      0.73       744\n",
      "          2       0.55      0.51      0.53       638\n",
      "          3       0.52      0.33      0.40       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.666353897863777\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   175     8\n",
      "    2  235   345    58\n",
      "    3   22   116    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.54      0.54      0.54       638\n",
      "          3       0.54      0.36      0.44       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6635323443378545\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   149     6\n",
      "    2  252   337    49\n",
      "    3   24   131    62\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.79      0.73       744\n",
      "          2       0.55      0.53      0.54       638\n",
      "          3       0.53      0.29      0.37       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6621170586645606\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   173     7\n",
      "    2  235   344    59\n",
      "    3   22   124    71\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.72       744\n",
      "          2       0.54      0.54      0.54       638\n",
      "          3       0.52      0.33      0.40       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6649446176865927\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   166     9\n",
      "    2  251   332    55\n",
      "    3   27   128    62\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.76      0.72       744\n",
      "          2       0.53      0.52      0.53       638\n",
      "          3       0.49      0.29      0.36       217\n",
      "\n",
      "avg / total       0.59      0.60      0.59      1599\n",
      "\n",
      "RMSE:\n",
      "0.6821222813793884\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   178     6\n",
      "    2  233   347    58\n",
      "    3   25   127    65\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.72       744\n",
      "          2       0.53      0.54      0.54       638\n",
      "          3       0.50      0.30      0.38       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6710301229387411\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   166     7\n",
      "    2  241   343    54\n",
      "    3   25   137    55\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.53      0.54      0.53       638\n",
      "          3       0.47      0.25      0.33       217\n",
      "\n",
      "avg / total       0.59      0.61      0.59      1599\n",
      "\n",
      "RMSE:\n",
      "0.6738202810148577\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   183     6\n",
      "    2  234   347    57\n",
      "    3   24   133    60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.52      0.54      0.53       638\n",
      "          3       0.49      0.28      0.35       217\n",
      "\n",
      "avg / total       0.59      0.60      0.59      1599\n",
      "\n",
      "RMSE:\n",
      "0.6742841848777377\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   164     7\n",
      "    2  237   347    54\n",
      "    3   26   130    61\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.54      0.54      0.54       638\n",
      "          3       0.50      0.28      0.36       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6696306842456534\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565   174     5\n",
      "    2  230   360    48\n",
      "    3   26   127    64\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.72       744\n",
      "          2       0.54      0.56      0.55       638\n",
      "          3       0.55      0.29      0.38       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.663060918101192\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   161     6\n",
      "    2  244   350    44\n",
      "    3   23   134    60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.78      0.73       744\n",
      "          2       0.54      0.55      0.55       638\n",
      "          3       0.55      0.28      0.37       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6611718518176818\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   169     6\n",
      "    2  233   359    46\n",
      "    3   26   129    62\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.72       744\n",
      "          2       0.55      0.56      0.55       638\n",
      "          3       0.54      0.29      0.37       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6640034358734768\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   162     5\n",
      "    2  240   358    40\n",
      "    3   24   132    61\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.78      0.73       744\n",
      "          2       0.55      0.56      0.56       638\n",
      "          3       0.58      0.28      0.38       217\n",
      "\n",
      "avg / total       0.62      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6569015906605667\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   170     5\n",
      "    2  229   364    45\n",
      "    3   24   130    63\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.73       744\n",
      "          2       0.55      0.57      0.56       638\n",
      "          3       0.56      0.29      0.38       217\n",
      "\n",
      "avg / total       0.62      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6569015906605667\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   165     6\n",
      "    2  239   356    43\n",
      "    3   25   138    54\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.54      0.56      0.55       638\n",
      "          3       0.52      0.25      0.34       217\n",
      "\n",
      "avg / total       0.61      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6658844692053987\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red log normed____________________#\")\n",
    "run_knn_report(f_log_red.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>*white: normalized unfiltered</h3>\n",
    "<p>\n",
    "    STD: 0.62/0.7/0.7/0.7 at k=1, decreasing after<br>\n",
    "    MM: 0.62/0.7/0.7/0.7 at k=1, decreasing after<br>\n",
    "    log: 0.65/0.67/0.67/0.67 at k=1, decreasing after<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white STD normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   420    67\n",
      "    2  372  1543   283\n",
      "    3   57   277   726\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.69      0.70      0.70      2198\n",
      "          3       0.67      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6142449477688314\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1324   292    24\n",
      "    2  753  1318   127\n",
      "    3  137   450   473\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.81      0.69      1640\n",
      "          2       0.64      0.60      0.62      2198\n",
      "          3       0.76      0.45      0.56      1060\n",
      "\n",
      "avg / total       0.65      0.64      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.6801748388110016\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1075   498    67\n",
      "    2  568  1327   303\n",
      "    3  106   351   603\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.66      0.63      1640\n",
      "          2       0.61      0.60      0.61      2198\n",
      "          3       0.62      0.57      0.59      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.7017448940207528\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1170   403    67\n",
      "    2  666  1306   226\n",
      "    3   88   456   516\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.71      0.66      1640\n",
      "          2       0.60      0.59      0.60      2198\n",
      "          3       0.64      0.49      0.55      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.6957550809783767\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1055   524    61\n",
      "    2  562  1381   255\n",
      "    3   94   401   565\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.60      0.63      0.61      2198\n",
      "          3       0.64      0.53      0.58      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.6944333287073712\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1165   419    56\n",
      "    2  646  1304   248\n",
      "    3   89   451   520\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.71      0.66      1640\n",
      "          2       0.60      0.59      0.60      2198\n",
      "          3       0.63      0.49      0.55      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.6917822479974061\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1047   527    66\n",
      "    2  550  1355   293\n",
      "    3   62   427   571\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.64      0.63      1640\n",
      "          2       0.59      0.62      0.60      2198\n",
      "          3       0.61      0.54      0.57      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.6865980664545497\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   461    61\n",
      "    2  618  1329   251\n",
      "    3   69   476   515\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.68      0.65      1640\n",
      "          2       0.59      0.60      0.60      2198\n",
      "          3       0.62      0.49      0.55      1060\n",
      "\n",
      "avg / total       0.61      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6891209685309898\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1060   504    76\n",
      "    2  565  1332   301\n",
      "    3   64   444   552\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.65      0.64      1640\n",
      "          2       0.58      0.61      0.59      2198\n",
      "          3       0.59      0.52      0.56      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.696195107425428\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1092   475    73\n",
      "    2  586  1334   278\n",
      "    3   60   489   511\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.67      0.65      1640\n",
      "          2       0.58      0.61      0.59      2198\n",
      "          3       0.59      0.48      0.53      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6941392641891222\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1055   515    70\n",
      "    2  558  1351   289\n",
      "    3   60   448   552\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.64      0.64      1640\n",
      "          2       0.58      0.61      0.60      2198\n",
      "          3       0.61      0.52      0.56      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6897132513807874\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1071   500    69\n",
      "    2  568  1357   273\n",
      "    3   66   459   535\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.65      0.64      1640\n",
      "          2       0.59      0.62      0.60      2198\n",
      "          3       0.61      0.50      0.55      1060\n",
      "\n",
      "avg / total       0.61      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6911917380750271\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1045   527    68\n",
      "    2  536  1367   295\n",
      "    3   62   465   533\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.58      0.62      0.60      2198\n",
      "          3       0.59      0.50      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6916346677828207\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1065   513    62\n",
      "    2  543  1369   286\n",
      "    3   65   493   502\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.65      0.64      1640\n",
      "          2       0.58      0.62      0.60      2198\n",
      "          3       0.59      0.47      0.53      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6916346677828207\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1060   517    63\n",
      "    2  522  1378   298\n",
      "    3   70   472   518\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.65      0.64      1640\n",
      "          2       0.58      0.63      0.60      2198\n",
      "          3       0.59      0.49      0.53      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6913394128418173\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1063   516    61\n",
      "    2  528  1374   296\n",
      "    3   61   506   493\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.65      0.65      1640\n",
      "          2       0.57      0.63      0.60      2198\n",
      "          3       0.58      0.47      0.52      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.690305026051111\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1043   537    60\n",
      "    2  520  1393   285\n",
      "    3   63   488   509\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.58      0.63      0.60      2198\n",
      "          3       0.60      0.48      0.53      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6885281761902861\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1047   530    63\n",
      "    2  522  1397   279\n",
      "    3   67   487   506\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.58      0.64      0.61      2198\n",
      "          3       0.60      0.48      0.53      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6908962938477763\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1035   548    57\n",
      "    2  509  1404   285\n",
      "    3   67   486   507\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.64      1640\n",
      "          2       0.58      0.64      0.61      2198\n",
      "          3       0.60      0.48      0.53      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.688824636129186\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1054   529    57\n",
      "    2  510  1401   287\n",
      "    3   63   499   498\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.64      0.65      1640\n",
      "          2       0.58      0.64      0.61      2198\n",
      "          3       0.59      0.47      0.52      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6860030940148582\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white STD normed____________________#\")\n",
    "run_knn_report(white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white MinMax normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   412    75\n",
      "    2  380  1537   281\n",
      "    3   57   288   715\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.69      0.70      0.69      2198\n",
      "          3       0.67      0.67      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6210214323487594\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1321   283    36\n",
      "    2  762  1308   128\n",
      "    3  126   456   478\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.81      0.69      1640\n",
      "          2       0.64      0.60      0.62      2198\n",
      "          3       0.74      0.45      0.56      1060\n",
      "\n",
      "avg / total       0.65      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.6818237499308627\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1085   485    70\n",
      "    2  547  1346   305\n",
      "    3   96   347   617\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.66      0.64      1640\n",
      "          2       0.62      0.61      0.62      2198\n",
      "          3       0.62      0.58      0.60      1060\n",
      "\n",
      "avg / total       0.62      0.62      0.62      4898\n",
      "\n",
      "RMSE:\n",
      "0.6923722542863141\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1176   409    55\n",
      "    2  632  1327   239\n",
      "    3   79   475   506\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.72      0.67      1640\n",
      "          2       0.60      0.60      0.60      2198\n",
      "          3       0.63      0.48      0.54      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.6839166144230384\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1075   518    47\n",
      "    2  562  1359   277\n",
      "    3   89   401   570\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.66      0.64      1640\n",
      "          2       0.60      0.62      0.61      2198\n",
      "          3       0.64      0.54      0.58      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.6855565258256117\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1136   446    58\n",
      "    2  624  1308   266\n",
      "    3   85   454   521\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.69      0.65      1640\n",
      "          2       0.59      0.60      0.59      2198\n",
      "          3       0.62      0.49      0.55      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6944333287073712\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1056   513    71\n",
      "    2  525  1356   317\n",
      "    3   70   429   561\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.59      0.62      0.60      2198\n",
      "          3       0.59      0.53      0.56      1060\n",
      "\n",
      "avg / total       0.61      0.61      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.6923722542863141\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1099   474    67\n",
      "    2  585  1334   279\n",
      "    3   71   492   497\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.67      0.65      1640\n",
      "          2       0.58      0.61      0.59      2198\n",
      "          3       0.59      0.47      0.52      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6973671538905736\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1049   517    74\n",
      "    2  524  1350   324\n",
      "    3   75   428   557\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.64      0.64      1640\n",
      "          2       0.59      0.61      0.60      2198\n",
      "          3       0.58      0.53      0.55      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6983910810444838\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1068   497    75\n",
      "    2  549  1341   308\n",
      "    3   60   473   527\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.65      0.64      1640\n",
      "          2       0.58      0.61      0.59      2198\n",
      "          3       0.58      0.50      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.6951679457843691\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1025   542    73\n",
      "    2  513  1355   330\n",
      "    3   69   452   539\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.58      0.62      0.60      2198\n",
      "          3       0.57      0.51      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.7007258676024126\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1058   499    83\n",
      "    2  542  1334   322\n",
      "    3   63   481   516\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.65      0.64      1640\n",
      "          2       0.58      0.61      0.59      2198\n",
      "          3       0.56      0.49      0.52      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.7040685589691311\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1017   538    85\n",
      "    2  506  1342   350\n",
      "    3   60   468   532\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.57      0.61      0.59      2198\n",
      "          3       0.55      0.50      0.52      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.7060954930056956\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1038   530    72\n",
      "    2  537  1341   320\n",
      "    3   58   484   518\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.63      1640\n",
      "          2       0.57      0.61      0.59      2198\n",
      "          3       0.57      0.49      0.53      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.6986833560441142\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1008   552    80\n",
      "    2  519  1347   332\n",
      "    3   56   477   527\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.61      0.63      1640\n",
      "          2       0.57      0.61      0.59      2198\n",
      "          3       0.56      0.50      0.53      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.7034883622830594\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1026   542    72\n",
      "    2  517  1353   328\n",
      "    3   53   484   523\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.63      1640\n",
      "          2       0.57      0.62      0.59      2198\n",
      "          3       0.57      0.49      0.53      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.6957550809783767\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1018   547    75\n",
      "    2  521  1350   327\n",
      "    3   51   484   525\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.57      0.61      0.59      2198\n",
      "          3       0.57      0.50      0.53      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.6975135212243064\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1031   531    78\n",
      "    2  533  1337   328\n",
      "    3   48   497   515\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.63      1640\n",
      "          2       0.57      0.61      0.59      2198\n",
      "          3       0.56      0.49      0.52      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.6989755088296373\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1006   562    72\n",
      "    2  511  1361   326\n",
      "    3   49   504   507\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.61      0.63      1640\n",
      "          2       0.56      0.62      0.59      2198\n",
      "          3       0.56      0.48      0.52      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.6980986836772425\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1012   557    71\n",
      "    2  540  1347   311\n",
      "    3   47   519   494\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.62      1640\n",
      "          2       0.56      0.61      0.58      2198\n",
      "          3       0.56      0.47      0.51      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.6998512354317896\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white MinMax normed____________________#\")\n",
    "run_knn_report(mm_white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white log normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1151   402    87\n",
      "    2  420  1485   293\n",
      "    3   69   299   692\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.70      0.70      1640\n",
      "          2       0.68      0.68      0.68      2198\n",
      "          3       0.65      0.65      0.65      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6450489898178324\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1285   318    37\n",
      "    2  762  1295   141\n",
      "    3  155   467   438\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.78      0.67      1640\n",
      "          2       0.62      0.59      0.61      2198\n",
      "          3       0.71      0.41      0.52      1060\n",
      "\n",
      "avg / total       0.63      0.62      0.61      4898\n",
      "\n",
      "RMSE:\n",
      "0.7081166251099064\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1048   502    90\n",
      "    2  583  1321   294\n",
      "    3  139   350   571\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.64      0.61      1640\n",
      "          2       0.61      0.60      0.60      2198\n",
      "          3       0.60      0.54      0.57      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.7348580360839931\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   397    87\n",
      "    2  629  1333   236\n",
      "    3  121   477   462\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.70      0.65      1640\n",
      "          2       0.60      0.61      0.61      2198\n",
      "          3       0.59      0.44      0.50      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.7245054352905979\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1042   540    58\n",
      "    2  548  1371   279\n",
      "    3  136   401   523\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.64      0.62      1640\n",
      "          2       0.59      0.62      0.61      2198\n",
      "          3       0.61      0.49      0.54      1060\n",
      "\n",
      "avg / total       0.60      0.60      0.60      4898\n",
      "\n",
      "RMSE:\n",
      "0.7206911069957335\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1105   458    77\n",
      "    2  604  1319   275\n",
      "    3  130   459   471\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.67      0.64      1640\n",
      "          2       0.59      0.60      0.59      2198\n",
      "          3       0.57      0.44      0.50      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.731935016873829\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1006   556    78\n",
      "    2  519  1367   312\n",
      "    3  101   433   526\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.58      0.62      0.60      2198\n",
      "          3       0.57      0.50      0.53      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.59      4898\n",
      "\n",
      "RMSE:\n",
      "0.7195570526236263\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1057   511    72\n",
      "    2  581  1354   263\n",
      "    3  108   491   461\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.64      0.62      1640\n",
      "          2       0.57      0.62      0.59      2198\n",
      "          3       0.58      0.43      0.50      1060\n",
      "\n",
      "avg / total       0.59      0.59      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7238005947352895\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  989   579    72\n",
      "    2  551  1371   276\n",
      "    3  100   464   496\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.60      0.60      1640\n",
      "          2       0.57      0.62      0.59      2198\n",
      "          3       0.59      0.47      0.52      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.722671419952957\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1031   543    66\n",
      "    2  563  1369   266\n",
      "    3   88   509   463\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.63      0.62      1640\n",
      "          2       0.57      0.62      0.59      2198\n",
      "          3       0.58      0.44      0.50      1060\n",
      "\n",
      "avg / total       0.59      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7140027439261097\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  965   604    71\n",
      "    2  533  1411   254\n",
      "    3   87   499   474\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.59      0.60      1640\n",
      "          2       0.56      0.64      0.60      2198\n",
      "          3       0.59      0.45      0.51      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7175681448241086\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1001   567    72\n",
      "    2  572  1377   249\n",
      "    3   82   548   430\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.61      0.61      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.57      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7218233796608914\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  951   617    72\n",
      "    2  542  1393   263\n",
      "    3   80   532   448\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.58      0.59      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.57      0.42      0.49      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7232362277140099\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  985   590    65\n",
      "    2  547  1390   261\n",
      "    3   84   555   421\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.60      0.61      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.56      0.40      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7213989856724194\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  952   619    69\n",
      "    2  544  1376   278\n",
      "    3   83   542   435\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.58      0.59      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.56      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7273179669659328\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  971   596    73\n",
      "    2  540  1377   281\n",
      "    3   75   567   418\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.59      0.60      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7252095908026027\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  952   618    70\n",
      "    2  529  1382   287\n",
      "    3   87   556   417\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.58      0.59      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7310977220141918\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  979   593    68\n",
      "    2  537  1380   281\n",
      "    3   79   580   401\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.60      0.61      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.53      0.38      0.44      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7256317561187315\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  960   609    71\n",
      "    2  523  1401   274\n",
      "    3   77   571   412\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.59      0.60      1640\n",
      "          2       0.54      0.64      0.59      2198\n",
      "          3       0.54      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7242235813856345\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  958   614    68\n",
      "    2  524  1405   269\n",
      "    3   79   569   412\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.58      0.60      1640\n",
      "          2       0.54      0.64      0.59      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7235184662526416\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white log normed____________________#\")\n",
    "run_knn_report(log_white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><i>*red: </i> normalized unfiltered</h3>\n",
    "<p>\n",
    "    STD: 0.63/0.69/0.69/0.69. k=1 more=bad<br>\n",
    "    MM: 0.63/0.69/0.69/0.69. k=1 more=bad<br>\n",
    "    log: 0.63/0.68/0.68/0.68. k=1 more=bad<br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red STD normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   157    24\n",
      "    2  162   404    72\n",
      "    3   24    64   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.76      0.75       744\n",
      "          2       0.65      0.63      0.64       638\n",
      "          3       0.57      0.59      0.58       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6361036805684829\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  625   109    10\n",
      "    2  289   316    33\n",
      "    3   39   101    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.84      0.74       744\n",
      "          2       0.60      0.50      0.54       638\n",
      "          3       0.64      0.35      0.46       217\n",
      "\n",
      "avg / total       0.63      0.64      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6747477697966318\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  542   187    15\n",
      "    2  217   363    58\n",
      "    3   36    74   107\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.73      0.70       744\n",
      "          2       0.58      0.57      0.58       638\n",
      "          3       0.59      0.49      0.54       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6802861480855303\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  582   147    15\n",
      "    2  240   348    50\n",
      "    3   30   104    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.78      0.73       744\n",
      "          2       0.58      0.55      0.56       638\n",
      "          3       0.56      0.38      0.45       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6714959543887628\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  523   206    15\n",
      "    2  210   370    58\n",
      "    3   33    92    92\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.70      0.69       744\n",
      "          2       0.55      0.58      0.57       638\n",
      "          3       0.56      0.42      0.48       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6885101879597191\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   160    20\n",
      "    2  232   338    68\n",
      "    3   26   102    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.72       744\n",
      "          2       0.56      0.53      0.55       638\n",
      "          3       0.50      0.41      0.45       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.683038497079636\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  517   204    23\n",
      "    2  207   359    72\n",
      "    3   26    96    95\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.69      0.69       744\n",
      "          2       0.54      0.56      0.55       638\n",
      "          3       0.50      0.44      0.47       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6961881381511136\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   172    17\n",
      "    2  232   341    65\n",
      "    3   27   109    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.55      0.53      0.54       638\n",
      "          3       0.50      0.37      0.43       217\n",
      "\n",
      "avg / total       0.60      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6866911354074366\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  534   191    19\n",
      "    2  223   347    68\n",
      "    3   29   105    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.72      0.70       744\n",
      "          2       0.54      0.54      0.54       638\n",
      "          3       0.49      0.38      0.43       217\n",
      "\n",
      "avg / total       0.60      0.60      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6979824404521128\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   167    18\n",
      "    2  238   330    70\n",
      "    3   26   112    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.54      0.52      0.53       638\n",
      "          3       0.47      0.36      0.41       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6907772674826483\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  542   185    17\n",
      "    2  213   355    70\n",
      "    3   24   107    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.56      0.55       638\n",
      "          3       0.50      0.40      0.44       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6798263398896478\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553   173    18\n",
      "    2  228   344    66\n",
      "    3   25   109    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.74      0.71       744\n",
      "          2       0.55      0.54      0.54       638\n",
      "          3       0.50      0.38      0.43       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6839534854296706\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  549   177    18\n",
      "    2  215   356    67\n",
      "    3   20   101    96\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.56      0.56      0.56       638\n",
      "          3       0.53      0.44      0.48       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.667291764475507\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   165    15\n",
      "    2  221   354    63\n",
      "    3   22   104    91\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.76      0.73       744\n",
      "          2       0.57      0.55      0.56       638\n",
      "          3       0.54      0.42      0.47       217\n",
      "\n",
      "avg / total       0.62      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6621170586645606\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  548   182    14\n",
      "    2  214   359    65\n",
      "    3   23   101    93\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.56      0.56      0.56       638\n",
      "          3       0.54      0.43      0.48       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.666353897863777\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  562   166    16\n",
      "    2  227   348    63\n",
      "    3   25   102    90\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.72       744\n",
      "          2       0.56      0.55      0.56       638\n",
      "          3       0.53      0.41      0.47       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6719614629052536\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  558   171    15\n",
      "    2  215   364    59\n",
      "    3   23   107    87\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.75      0.72       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.54      0.40      0.46       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6635323443378545\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565   164    15\n",
      "    2  215   363    60\n",
      "    3   25   105    87\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.76      0.73       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.54      0.40      0.46       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6635323443378545\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  547   182    15\n",
      "    2  224   355    59\n",
      "    3   20   112    85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.74      0.71       744\n",
      "          2       0.55      0.56      0.55       638\n",
      "          3       0.53      0.39      0.45       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6696306842456534\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   168    16\n",
      "    2  214   358    66\n",
      "    3   23   109    85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.75      0.73       744\n",
      "          2       0.56      0.56      0.56       638\n",
      "          3       0.51      0.39      0.44       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6677602038203002\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red STD normed____________________#\")\n",
    "run_knn_report(red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red MinMax normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   166    23\n",
      "    2  161   414    63\n",
      "    3   24    64   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.75      0.75       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.60      0.59      0.60       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6336410167329005\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  618   122     4\n",
      "    2  288   324    26\n",
      "    3   46    93    78\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.83      0.73       744\n",
      "          2       0.60      0.51      0.55       638\n",
      "          3       0.72      0.36      0.48       217\n",
      "\n",
      "avg / total       0.64      0.64      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6752110364284797\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  538   192    14\n",
      "    2  209   372    57\n",
      "    3   36    74   107\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.72      0.70       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.60      0.49      0.54       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6765989331374249\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   144    11\n",
      "    2  247   348    43\n",
      "    3   31    95    91\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.79      0.73       744\n",
      "          2       0.59      0.55      0.57       638\n",
      "          3       0.63      0.42      0.50       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6602252917735247\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  523   211    10\n",
      "    2  204   378    56\n",
      "    3   33    86    98\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.70      0.70       744\n",
      "          2       0.56      0.59      0.58       638\n",
      "          3       0.60      0.45      0.51       217\n",
      "\n",
      "avg / total       0.62      0.62      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6752110364284797\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568   162    14\n",
      "    2  248   326    64\n",
      "    3   35    97    85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.76      0.71       744\n",
      "          2       0.56      0.51      0.53       638\n",
      "          3       0.52      0.39      0.45       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6925855880307988\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  529   199    16\n",
      "    2  212   360    66\n",
      "    3   28    99    90\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.71      0.70       744\n",
      "          2       0.55      0.56      0.56       638\n",
      "          3       0.52      0.41      0.46       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.685779799723328\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   156    12\n",
      "    2  239   337    62\n",
      "    3   28   110    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.73       744\n",
      "          2       0.56      0.53      0.54       638\n",
      "          3       0.52      0.36      0.43       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6742841848777377\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  539   193    12\n",
      "    2  221   356    61\n",
      "    3   26   108    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.72      0.70       744\n",
      "          2       0.54      0.56      0.55       638\n",
      "          3       0.53      0.38      0.45       217\n",
      "\n",
      "avg / total       0.61      0.61      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6779839886978022\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   169    14\n",
      "    2  244   335    59\n",
      "    3   27   114    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.75      0.71       744\n",
      "          2       0.54      0.53      0.53       638\n",
      "          3       0.51      0.35      0.42       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6848672513487423\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  538   193    13\n",
      "    2  237   338    63\n",
      "    3   27   113    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.72      0.70       744\n",
      "          2       0.52      0.53      0.53       638\n",
      "          3       0.50      0.35      0.42       217\n",
      "\n",
      "avg / total       0.59      0.60      0.59      1599\n",
      "\n",
      "RMSE:\n",
      "0.6921339508207022\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  558   174    12\n",
      "    2  237   339    62\n",
      "    3   23   118    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.54      0.53      0.53       638\n",
      "          3       0.51      0.35      0.41       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6761366174475454\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  548   183    13\n",
      "    2  224   347    67\n",
      "    3   22   120    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.74      0.71       744\n",
      "          2       0.53      0.54      0.54       638\n",
      "          3       0.48      0.35      0.40       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6775226181178664\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   159    14\n",
      "    2  239   336    63\n",
      "    3   26   114    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.55      0.53      0.54       638\n",
      "          3       0.50      0.35      0.42       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6779839886978022\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  550   180    14\n",
      "    2  231   347    60\n",
      "    3   22   116    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.74      0.71       744\n",
      "          2       0.54      0.54      0.54       638\n",
      "          3       0.52      0.36      0.43       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6761366174475454\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   161    14\n",
      "    2  241   333    64\n",
      "    3   24   117    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.76      0.72       744\n",
      "          2       0.55      0.52      0.53       638\n",
      "          3       0.49      0.35      0.41       217\n",
      "\n",
      "avg / total       0.60      0.61      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.6779839886978022\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  562   169    13\n",
      "    2  224   350    64\n",
      "    3   22   118    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.76      0.72       744\n",
      "          2       0.55      0.55      0.55       638\n",
      "          3       0.50      0.35      0.42       217\n",
      "\n",
      "avg / total       0.61      0.62      0.61      1599\n",
      "\n",
      "RMSE:\n",
      "0.6686960980480711\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   155    13\n",
      "    2  229   352    57\n",
      "    3   23   116    78\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.77      0.73       744\n",
      "          2       0.57      0.55      0.56       638\n",
      "          3       0.53      0.36      0.43       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6621170586645606\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566   164    14\n",
      "    2  220   359    59\n",
      "    3   21   119    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.76      0.73       744\n",
      "          2       0.56      0.56      0.56       638\n",
      "          3       0.51      0.35      0.42       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6625891564490792\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   155    13\n",
      "    2  230   351    57\n",
      "    3   21   115    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.77      0.73       744\n",
      "          2       0.57      0.55      0.56       638\n",
      "          3       0.54      0.37      0.44       217\n",
      "\n",
      "avg / total       0.62      0.63      0.62      1599\n",
      "\n",
      "RMSE:\n",
      "0.6583280887371149\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red MinMax normed____________________#\")\n",
    "run_knn_report(mm_red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red log normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   162    27\n",
      "    2  171   392    75\n",
      "    3   21    67   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.75      0.74       744\n",
      "          2       0.63      0.61      0.62       638\n",
      "          3       0.56      0.59      0.58       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "0.6458604414412116\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  634    99    11\n",
      "    2  321   285    32\n",
      "    3   53    96    68\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.85      0.72       744\n",
      "          2       0.59      0.45      0.51       638\n",
      "          3       0.61      0.31      0.41       217\n",
      "\n",
      "avg / total       0.61      0.62      0.60      1599\n",
      "\n",
      "RMSE:\n",
      "0.7090939704382063\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  515   203    26\n",
      "    2  264   306    68\n",
      "    3   43    79    95\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.69      0.66       744\n",
      "          2       0.52      0.48      0.50       638\n",
      "          3       0.50      0.44      0.47       217\n",
      "\n",
      "avg / total       0.57      0.57      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7460548730965065\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566   156    22\n",
      "    2  292   291    55\n",
      "    3   45   106    66\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.76      0.69       744\n",
      "          2       0.53      0.46      0.49       638\n",
      "          3       0.46      0.30      0.37       217\n",
      "\n",
      "avg / total       0.56      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7405861140814289\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  524   202    18\n",
      "    2  255   322    61\n",
      "    3   44    97    76\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.70      0.67       744\n",
      "          2       0.52      0.50      0.51       638\n",
      "          3       0.49      0.35      0.41       217\n",
      "\n",
      "avg / total       0.57      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.734651155447349\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   164    20\n",
      "    2  301   279    58\n",
      "    3   41   106    70\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.75      0.68       744\n",
      "          2       0.51      0.44      0.47       638\n",
      "          3       0.47      0.32      0.38       217\n",
      "\n",
      "avg / total       0.56      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7388952759986074\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  507   216    21\n",
      "    2  258   315    65\n",
      "    3   30   112    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.68      0.66       744\n",
      "          2       0.49      0.49      0.49       638\n",
      "          3       0.47      0.35      0.40       217\n",
      "\n",
      "avg / total       0.56      0.56      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7312381234904117\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  549   177    18\n",
      "    2  295   289    54\n",
      "    3   37   117    63\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.74      0.68       744\n",
      "          2       0.50      0.45      0.47       638\n",
      "          3       0.47      0.29      0.36       217\n",
      "\n",
      "avg / total       0.55      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.734651155447349\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  523   199    22\n",
      "    2  271   303    64\n",
      "    3   34   117    66\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.70      0.67       744\n",
      "          2       0.49      0.47      0.48       638\n",
      "          3       0.43      0.30      0.36       217\n",
      "\n",
      "avg / total       0.55      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7397411781370865\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  550   175    19\n",
      "    2  298   283    57\n",
      "    3   37   119    61\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.74      0.68       744\n",
      "          2       0.49      0.44      0.47       638\n",
      "          3       0.45      0.28      0.34       217\n",
      "\n",
      "avg / total       0.55      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7388952759986074\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  533   186    25\n",
      "    2  285   296    57\n",
      "    3   36   116    65\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.72      0.67       744\n",
      "          2       0.49      0.46      0.48       638\n",
      "          3       0.44      0.30      0.36       217\n",
      "\n",
      "avg / total       0.55      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7452161377294897\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   164    20\n",
      "    2  297   289    52\n",
      "    3   36   118    63\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.75      0.68       744\n",
      "          2       0.51      0.45      0.48       638\n",
      "          3       0.47      0.29      0.36       217\n",
      "\n",
      "avg / total       0.56      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7312381234904117\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  538   186    20\n",
      "    2  272   316    50\n",
      "    3   35   117    65\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.72      0.68       744\n",
      "          2       0.51      0.50      0.50       638\n",
      "          3       0.48      0.30      0.37       217\n",
      "\n",
      "avg / total       0.57      0.57      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7269492998503029\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  556   169    19\n",
      "    2  289   302    47\n",
      "    3   38   121    58\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.75      0.68       744\n",
      "          2       0.51      0.47      0.49       638\n",
      "          3       0.47      0.27      0.34       217\n",
      "\n",
      "avg / total       0.56      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7308103737471748\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  540   188    16\n",
      "    2  278   314    46\n",
      "    3   39   118    60\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.73      0.67       744\n",
      "          2       0.51      0.49      0.50       638\n",
      "          3       0.49      0.28      0.35       217\n",
      "\n",
      "avg / total       0.56      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7290968652376117\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  547   181    16\n",
      "    2  282   310    46\n",
      "    3   37   123    57\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.74      0.68       744\n",
      "          2       0.50      0.49      0.50       638\n",
      "          3       0.48      0.26      0.34       217\n",
      "\n",
      "avg / total       0.56      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7265190249976612\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  530   200    14\n",
      "    2  284   304    50\n",
      "    3   38   128    51\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.71      0.66       744\n",
      "          2       0.48      0.48      0.48       638\n",
      "          3       0.44      0.24      0.31       217\n",
      "\n",
      "avg / total       0.54      0.55      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.7376246039044375\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  539   193    12\n",
      "    2  283   309    46\n",
      "    3   39   131    47\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.72      0.67       744\n",
      "          2       0.49      0.48      0.49       638\n",
      "          3       0.45      0.22      0.29       217\n",
      "\n",
      "avg / total       0.55      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7320928731959936\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  515   213    16\n",
      "    2  277   312    49\n",
      "    3   37   133    47\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.69      0.65       744\n",
      "          2       0.47      0.49      0.48       638\n",
      "          3       0.42      0.22      0.29       217\n",
      "\n",
      "avg / total       0.54      0.55      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.7435358286291822\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  540   190    14\n",
      "    2  283   306    49\n",
      "    3   39   135    43\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.73      0.67       744\n",
      "          2       0.48      0.48      0.48       638\n",
      "          3       0.41      0.20      0.27       217\n",
      "\n",
      "avg / total       0.54      0.56      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.7372005598315053\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red log normed____________________#\")\n",
    "run_knn_report(log_red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> white: unfiltered, unnormalized <h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white_____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1044   451   145\n",
      "    2  430  1436   332\n",
      "    3  113   329   618\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.64      0.65      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.56      0.58      0.57      1060\n",
      "\n",
      "avg / total       0.63      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.7249280106751942\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1220   361    59\n",
      "    2  868  1187   143\n",
      "    3  252   463   345\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.74      0.61      1640\n",
      "          2       0.59      0.54      0.56      2198\n",
      "          3       0.63      0.33      0.43      1060\n",
      "\n",
      "avg / total       0.58      0.56      0.55      4898\n",
      "\n",
      "RMSE:\n",
      "0.7928580756566286\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  941   573   126\n",
      "    2  647  1251   300\n",
      "    3  209   371   480\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.57      0.55      1640\n",
      "          2       0.57      0.57      0.57      2198\n",
      "          3       0.53      0.45      0.49      1060\n",
      "\n",
      "avg / total       0.55      0.55      0.54      4898\n",
      "\n",
      "RMSE:\n",
      "0.812192712881807\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1031   497   112\n",
      "    2  723  1213   262\n",
      "    3  186   472   402\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.63      0.58      1640\n",
      "          2       0.56      0.55      0.55      2198\n",
      "          3       0.52      0.38      0.44      1060\n",
      "\n",
      "avg / total       0.54      0.54      0.54      4898\n",
      "\n",
      "RMSE:\n",
      "0.8014380704761244\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  913   628    99\n",
      "    2  644  1279   275\n",
      "    3  185   458   417\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.56      0.54      1640\n",
      "          2       0.54      0.58      0.56      2198\n",
      "          3       0.53      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.53      0.53      0.53      4898\n",
      "\n",
      "RMSE:\n",
      "0.8008009465416693\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  959   578   103\n",
      "    2  736  1185   277\n",
      "    3  191   477   392\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.58      0.54      1640\n",
      "          2       0.53      0.54      0.53      2198\n",
      "          3       0.51      0.37      0.43      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8138250103106349\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  869   673    98\n",
      "    2  649  1255   294\n",
      "    3  170   501   389\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.53      0.52      1640\n",
      "          2       0.52      0.57      0.54      2198\n",
      "          3       0.50      0.37      0.42      1060\n",
      "\n",
      "avg / total       0.51      0.51      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8068965697758588\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  936   601   103\n",
      "    2  681  1259   258\n",
      "    3  192   514   354\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.57      0.54      1640\n",
      "          2       0.53      0.57      0.55      2198\n",
      "          3       0.50      0.33      0.40      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.52      4898\n",
      "\n",
      "RMSE:\n",
      "0.8125696879370934\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  887   636   117\n",
      "    2  627  1290   281\n",
      "    3  185   517   358\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.54      0.53      1640\n",
      "          2       0.53      0.59      0.56      2198\n",
      "          3       0.47      0.34      0.39      1060\n",
      "\n",
      "avg / total       0.51      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8169548772970291\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  904   622   114\n",
      "    2  633  1307   258\n",
      "    3  178   536   346\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.55      0.54      1640\n",
      "          2       0.53      0.59      0.56      2198\n",
      "          3       0.48      0.33      0.39      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.52      4898\n",
      "\n",
      "RMSE:\n",
      "0.8104311774260798\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  873   665   102\n",
      "    2  591  1331   276\n",
      "    3  174   547   339\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.53      0.53      1640\n",
      "          2       0.52      0.61      0.56      2198\n",
      "          3       0.47      0.32      0.38      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8061371375419294\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  915   618   107\n",
      "    2  628  1287   283\n",
      "    3  177   551   332\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.56      0.54      1640\n",
      "          2       0.52      0.59      0.55      2198\n",
      "          3       0.46      0.31      0.37      1060\n",
      "\n",
      "avg / total       0.51      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8103052069306541\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  852   687   101\n",
      "    2  597  1315   286\n",
      "    3  163   576   321\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.52      0.52      1640\n",
      "          2       0.51      0.60      0.55      2198\n",
      "          3       0.45      0.30      0.36      1060\n",
      "\n",
      "avg / total       0.50      0.51      0.50      4898\n",
      "\n",
      "RMSE:\n",
      "0.8085395592454601\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  886   656    98\n",
      "    2  622  1295   281\n",
      "    3  175   596   289\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.54      0.53      1640\n",
      "          2       0.51      0.59      0.55      2198\n",
      "          3       0.43      0.27      0.33      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.50      4898\n",
      "\n",
      "RMSE:\n",
      "0.8142012296127911\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  849   692    99\n",
      "    2  602  1320   276\n",
      "    3  189   597   274\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.52      0.52      1640\n",
      "          2       0.51      0.60      0.55      2198\n",
      "          3       0.42      0.26      0.32      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8231789111754513\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  870   671    99\n",
      "    2  619  1312   267\n",
      "    3  185   592   283\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.53      0.53      1640\n",
      "          2       0.51      0.60      0.55      2198\n",
      "          3       0.44      0.27      0.33      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8189517146841291\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  831   716    93\n",
      "    2  616  1316   266\n",
      "    3  195   579   286\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.51      0.51      1640\n",
      "          2       0.50      0.60      0.55      2198\n",
      "          3       0.44      0.27      0.34      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8244180792880037\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  856   701    83\n",
      "    2  627  1312   259\n",
      "    3  187   600   273\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.52      0.52      1640\n",
      "          2       0.50      0.60      0.55      2198\n",
      "          3       0.44      0.26      0.33      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8167049293403462\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  831   727    82\n",
      "    2  610  1347   241\n",
      "    3  183   608   269\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.51      0.51      1640\n",
      "          2       0.50      0.61      0.55      2198\n",
      "          3       0.45      0.25      0.33      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8140758424973\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  847   709    84\n",
      "    2  628  1335   235\n",
      "    3  181   612   267\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.52      0.51      1640\n",
      "          2       0.50      0.61      0.55      2198\n",
      "          3       0.46      0.25      0.32      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8138250103106349\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white_____________________#\")\n",
    "run_knn_report(white_input.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>\n",
    "    unnormed white: 0.71/0.64/0.64/0.64, k=1 more bad\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>red, unnormalized, unselected</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red_____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1044   451   145\n",
      "    2  430  1436   332\n",
      "    3  113   329   618\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.64      0.65      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.56      0.58      0.57      1060\n",
      "\n",
      "avg / total       0.63      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.7249280106751942\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1220   361    59\n",
      "    2  868  1187   143\n",
      "    3  252   463   345\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.74      0.61      1640\n",
      "          2       0.59      0.54      0.56      2198\n",
      "          3       0.63      0.33      0.43      1060\n",
      "\n",
      "avg / total       0.58      0.56      0.55      4898\n",
      "\n",
      "RMSE:\n",
      "0.7928580756566286\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  941   573   126\n",
      "    2  647  1251   300\n",
      "    3  209   371   480\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.57      0.55      1640\n",
      "          2       0.57      0.57      0.57      2198\n",
      "          3       0.53      0.45      0.49      1060\n",
      "\n",
      "avg / total       0.55      0.55      0.54      4898\n",
      "\n",
      "RMSE:\n",
      "0.812192712881807\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1031   497   112\n",
      "    2  723  1213   262\n",
      "    3  186   472   402\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.63      0.58      1640\n",
      "          2       0.56      0.55      0.55      2198\n",
      "          3       0.52      0.38      0.44      1060\n",
      "\n",
      "avg / total       0.54      0.54      0.54      4898\n",
      "\n",
      "RMSE:\n",
      "0.8014380704761244\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  913   628    99\n",
      "    2  644  1279   275\n",
      "    3  185   458   417\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.56      0.54      1640\n",
      "          2       0.54      0.58      0.56      2198\n",
      "          3       0.53      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.53      0.53      0.53      4898\n",
      "\n",
      "RMSE:\n",
      "0.8008009465416693\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  959   578   103\n",
      "    2  736  1185   277\n",
      "    3  191   477   392\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.58      0.54      1640\n",
      "          2       0.53      0.54      0.53      2198\n",
      "          3       0.51      0.37      0.43      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8138250103106349\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  869   673    98\n",
      "    2  649  1255   294\n",
      "    3  170   501   389\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.53      0.52      1640\n",
      "          2       0.52      0.57      0.54      2198\n",
      "          3       0.50      0.37      0.42      1060\n",
      "\n",
      "avg / total       0.51      0.51      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8068965697758588\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  936   601   103\n",
      "    2  681  1259   258\n",
      "    3  192   514   354\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.57      0.54      1640\n",
      "          2       0.53      0.57      0.55      2198\n",
      "          3       0.50      0.33      0.40      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.52      4898\n",
      "\n",
      "RMSE:\n",
      "0.8125696879370934\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  887   636   117\n",
      "    2  627  1290   281\n",
      "    3  185   517   358\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.54      0.53      1640\n",
      "          2       0.53      0.59      0.56      2198\n",
      "          3       0.47      0.34      0.39      1060\n",
      "\n",
      "avg / total       0.51      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8169548772970291\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  904   622   114\n",
      "    2  633  1307   258\n",
      "    3  178   536   346\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.55      0.54      1640\n",
      "          2       0.53      0.59      0.56      2198\n",
      "          3       0.48      0.33      0.39      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.52      4898\n",
      "\n",
      "RMSE:\n",
      "0.8104311774260798\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  873   665   102\n",
      "    2  591  1331   276\n",
      "    3  174   547   339\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.53      0.53      1640\n",
      "          2       0.52      0.61      0.56      2198\n",
      "          3       0.47      0.32      0.38      1060\n",
      "\n",
      "avg / total       0.52      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8061371375419294\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  915   618   107\n",
      "    2  628  1287   283\n",
      "    3  177   551   332\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.56      0.54      1640\n",
      "          2       0.52      0.59      0.55      2198\n",
      "          3       0.46      0.31      0.37      1060\n",
      "\n",
      "avg / total       0.51      0.52      0.51      4898\n",
      "\n",
      "RMSE:\n",
      "0.8103052069306541\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  852   687   101\n",
      "    2  597  1315   286\n",
      "    3  163   576   321\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.52      0.52      1640\n",
      "          2       0.51      0.60      0.55      2198\n",
      "          3       0.45      0.30      0.36      1060\n",
      "\n",
      "avg / total       0.50      0.51      0.50      4898\n",
      "\n",
      "RMSE:\n",
      "0.8085395592454601\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  886   656    98\n",
      "    2  622  1295   281\n",
      "    3  175   596   289\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.54      0.53      1640\n",
      "          2       0.51      0.59      0.55      2198\n",
      "          3       0.43      0.27      0.33      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.50      4898\n",
      "\n",
      "RMSE:\n",
      "0.8142012296127911\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  849   692    99\n",
      "    2  602  1320   276\n",
      "    3  189   597   274\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.52      0.52      1640\n",
      "          2       0.51      0.60      0.55      2198\n",
      "          3       0.42      0.26      0.32      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8231789111754513\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  870   671    99\n",
      "    2  619  1312   267\n",
      "    3  185   592   283\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.53      0.53      1640\n",
      "          2       0.51      0.60      0.55      2198\n",
      "          3       0.44      0.27      0.33      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8189517146841291\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  831   716    93\n",
      "    2  616  1316   266\n",
      "    3  195   579   286\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.51      0.51      1640\n",
      "          2       0.50      0.60      0.55      2198\n",
      "          3       0.44      0.27      0.34      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8244180792880037\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  856   701    83\n",
      "    2  627  1312   259\n",
      "    3  187   600   273\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.52      0.52      1640\n",
      "          2       0.50      0.60      0.55      2198\n",
      "          3       0.44      0.26      0.33      1060\n",
      "\n",
      "avg / total       0.49      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8167049293403462\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  831   727    82\n",
      "    2  610  1347   241\n",
      "    3  183   608   269\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.51      0.51      1640\n",
      "          2       0.50      0.61      0.55      2198\n",
      "          3       0.45      0.25      0.33      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8140758424973\n",
      "20 neighbours:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  847   709    84\n",
      "    2  628  1335   235\n",
      "    3  181   612   267\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.52      0.51      1640\n",
      "          2       0.50      0.61      0.55      2198\n",
      "          3       0.46      0.25      0.32      1060\n",
      "\n",
      "avg / total       0.50      0.50      0.49      4898\n",
      "\n",
      "RMSE:\n",
      "0.8138250103106349\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red_____________________#\")\n",
    "run_knn_report(white_input.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.72 0.64      0.64      0.64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knc_report(inputs, targets):\n",
    "    knc_estimator = NearestCentroid()\n",
    "    predicted = cross_val_predict(knc_estimator,inputs,targets,cv=cv)\n",
    "    print(confusion_matrix_report(targets,predicted))\n",
    "    print(classification_report(targets,predicted))\n",
    "    try:\n",
    "        print(\"RMSE:\")\n",
    "        print(root_mean_squared_error(targets,predicted))\n",
    "    except(Error):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1078   272   290\n",
      "    2  783   537   878\n",
      "    3  138   181   741\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8838185092014216\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white STD normed____________________#\")\n",
    "run_knc_report(white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   298   200\n",
      "    2  847   556   795\n",
      "    3  145   196   719\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.70      0.61      1640\n",
      "          2       0.53      0.25      0.34      2198\n",
      "          3       0.42      0.68      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.47      4898\n",
      "\n",
      "RMSE:\n",
      "0.8472567603545674\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white MinMax normed____________________#\")\n",
    "run_knc_report(mm_white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  921    97   622\n",
      "    2  974   246   978\n",
      "    3  301   147   612\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.56      0.48      1640\n",
      "          2       0.50      0.11      0.18      2198\n",
      "          3       0.28      0.58      0.37      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.0964138432357722\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"#____________________white log normed____________________#\")\n",
    "run_knc_report(log_white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red STD normed____________________#\")\n",
    "run_knc_report(red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red MinMax normed____________________#\")\n",
    "run_knc_report(mm_red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red log normed____________________#\")\n",
    "run_knc_report(log_red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kncs_report(inputs, targets,thresh=0):\n",
    "    knc_estimator = NearestCentroid(shrink_threshold=thresh)\n",
    "    predicted = cross_val_predict(knc_estimator,inputs,targets,cv=cv)\n",
    "    print(confusion_matrix_report(targets,predicted))\n",
    "    print(classification_report(targets,predicted))\n",
    "    try:\n",
    "        print(\"RMSE:\")\n",
    "        print(root_mean_squared_error(targets,predicted))\n",
    "    except(Error):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1078   272   290\n",
      "    2  783   537   878\n",
      "    3  138   181   741\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8838185092014216\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   298   200\n",
      "    2  847   556   795\n",
      "    3  145   196   719\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.70      0.61      1640\n",
      "          2       0.53      0.25      0.34      2198\n",
      "          3       0.42      0.68      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.47      4898\n",
      "\n",
      "RMSE:\n",
      "0.8472567603545674\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  921    97   622\n",
      "    2  974   246   978\n",
      "    3  301   147   612\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.56      0.48      1640\n",
      "          2       0.50      0.11      0.18      2198\n",
      "          3       0.28      0.58      0.37      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.0964138432357722\n",
      "0.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1080   270   290\n",
      "    2  781   542   875\n",
      "    3  138   180   742\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.25      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8828940125998633\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1141   296   203\n",
      "    2  847   557   794\n",
      "    3  146   193   721\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.53      0.25      0.34      2198\n",
      "          3       0.42      0.68      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.47      4898\n",
      "\n",
      "RMSE:\n",
      "0.8484607637477626\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  925    92   623\n",
      "    2  982   238   978\n",
      "    3  304   143   613\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.56      0.48      1640\n",
      "          2       0.50      0.11      0.18      2198\n",
      "          3       0.28      0.58      0.37      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.09780954182336\n",
      "0.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1079   271   290\n",
      "    2  784   535   879\n",
      "    3  138   179   743\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8837030000185194\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1141   296   203\n",
      "    2  846   553   799\n",
      "    3  146   192   722\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.53      0.25      0.34      2198\n",
      "          3       0.42      0.68      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.47      4898\n",
      "\n",
      "RMSE:\n",
      "0.8488216317432729\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  926    91   623\n",
      "    2  986   236   976\n",
      "    3  307   137   616\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.56      0.48      1640\n",
      "          2       0.51      0.11      0.18      2198\n",
      "          3       0.28      0.58      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.0984602609450462\n",
      "0.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1082   268   290\n",
      "    2  786   531   881\n",
      "    3  140   175   745\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.33      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8842803950490993\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   293   204\n",
      "    2  846   551   801\n",
      "    3  146   191   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.70      0.61      1640\n",
      "          2       0.53      0.25      0.34      2198\n",
      "          3       0.42      0.68      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.47      4898\n",
      "\n",
      "RMSE:\n",
      "0.8490621251980895\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  929    86   625\n",
      "    2  995   227   976\n",
      "    3  309   132   619\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.57      0.48      1640\n",
      "          2       0.51      0.10      0.17      2198\n",
      "          3       0.28      0.58      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.0998533626601497\n",
      "0.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1083   266   291\n",
      "    2  788   524   886\n",
      "    3  140   172   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.33      2198\n",
      "          3       0.39      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8849727718184005\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   293   205\n",
      "    2  849   540   809\n",
      "    3  148   189   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.53      0.25      0.34      2198\n",
      "          3       0.42      0.68      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8515832059857846\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  932    81   627\n",
      "    2  998   227   973\n",
      "    3  311   129   620\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.57      0.48      1640\n",
      "          2       0.52      0.10      0.17      2198\n",
      "          3       0.28      0.58      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.1005956292286347\n",
      "0.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1085   265   290\n",
      "    2  785   519   894\n",
      "    3  140   168   752\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.33      2198\n",
      "          3       0.39      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8845112475253071\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   292   205\n",
      "    2  848   539   811\n",
      "    3  149   189   722\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.53      0.25      0.33      2198\n",
      "          3       0.42      0.68      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8520625661171809\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  933    79   628\n",
      "    2  997   227   974\n",
      "    3  312   126   622\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.57      0.48      1640\n",
      "          2       0.53      0.10      0.17      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.1008738501631556\n",
      "0.6\n",
      "#____________________white STD normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1088   263   289\n",
      "    2  786   516   896\n",
      "    3  138   166   756\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.60      1640\n",
      "          2       0.55      0.23      0.33      2198\n",
      "          3       0.39      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8830096276088838\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   287   209\n",
      "    2  849   534   815\n",
      "    3  150   188   722\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.53      0.24      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8543358537008395\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  935    76   629\n",
      "    2  998   226   974\n",
      "    3  313   124   623\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.57      0.48      1640\n",
      "          2       0.53      0.10      0.17      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.1012447020686265\n",
      "0.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1086   259   295\n",
      "    2  786   515   897\n",
      "    3  138   164   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.60      1640\n",
      "          2       0.55      0.23      0.33      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8852034437294778\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   286   209\n",
      "    2  848   533   817\n",
      "    3  151   189   720\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.61      1640\n",
      "          2       0.53      0.24      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8549330826124358\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  937    73   630\n",
      "    2 1001   223   974\n",
      "    3  314   122   624\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.57      0.48      1640\n",
      "          2       0.53      0.10      0.17      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.1018007458819266\n",
      "0.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1085   259   296\n",
      "    2  786   512   900\n",
      "    3  138   163   759\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.23      0.33      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8858950990846932\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1148   282   210\n",
      "    2  854   527   817\n",
      "    3  151   187   722\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.61      1640\n",
      "          2       0.53      0.24      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8554105655218259\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  938    70   632\n",
      "    2 1001   222   975\n",
      "    3  316   119   625\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.57      0.48      1640\n",
      "          2       0.54      0.10      0.17      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.102819431386744\n",
      "0.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1086   260   294\n",
      "    2  789   501   908\n",
      "    3  139   160   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.23      0.32      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8864710663122278\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1148   282   210\n",
      "    2  853   523   822\n",
      "    3  151   185   724\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.61      1640\n",
      "          2       0.53      0.24      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8556492070568136\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  940    67   633\n",
      "    2 1005   214   979\n",
      "    3  315   118   627\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.57      0.48      1640\n",
      "          2       0.54      0.10      0.16      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.103189629259335\n",
      "1.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1088   259   293\n",
      "    2  792   497   909\n",
      "    3  139   160   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.23      0.32      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.886355902808486\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   275   213\n",
      "    2  852   521   825\n",
      "    3  151   184   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.61      1640\n",
      "          2       0.53      0.24      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8563647326511675\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  939    64   637\n",
      "    2 1006   210   982\n",
      "    3  315   117   628\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.57      0.48      1640\n",
      "          2       0.54      0.10      0.16      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.1046691801394752\n",
      "1.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1090   259   291\n",
      "    2  794   496   908\n",
      "    3  140   160   760\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.23      0.32      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8860103224836438\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   274   214\n",
      "    2  854   518   826\n",
      "    3  151   182   727\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.61      1640\n",
      "          2       0.53      0.24      0.33      2198\n",
      "          3       0.41      0.69      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.856841417760529\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  936    65   639\n",
      "    2 1008   206   984\n",
      "    3  316   118   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.57      0.48      1640\n",
      "          2       0.53      0.09      0.16      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.106331309746441\n",
      "1.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1092   260   288\n",
      "    2  797   493   908\n",
      "    3  140   159   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.60      1640\n",
      "          2       0.54      0.22      0.32      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8849727718184005\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1154   271   215\n",
      "    2  854   520   824\n",
      "    3  151   182   727\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.61      1640\n",
      "          2       0.53      0.24      0.33      2198\n",
      "          3       0.41      0.69      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8567222713485284\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  938    62   640\n",
      "    2 1011   198   989\n",
      "    3  315   119   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.57      0.48      1640\n",
      "          2       0.52      0.09      0.15      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.1068847983042442\n",
      "1.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1089   264   287\n",
      "    2  804   481   913\n",
      "    3  140   160   760\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8864710663122278\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1157   269   214\n",
      "    2  855   520   823\n",
      "    3  151   182   727\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.54      0.24      0.33      2198\n",
      "          3       0.41      0.69      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8560070446163569\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  939    60   641\n",
      "    2 1013   195   990\n",
      "    3  316   115   629\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.57      0.48      1640\n",
      "          2       0.53      0.09      0.15      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.107345827437611\n",
      "1.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1090   261   289\n",
      "    2  805   481   912\n",
      "    3  140   162   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8872767923065394\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1159   267   214\n",
      "    2  855   520   823\n",
      "    3  151   183   726\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.71      0.61      1640\n",
      "          2       0.54      0.24      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8558877820529615\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  940    57   643\n",
      "    2 1014   192   992\n",
      "    3  315   115   630\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.57      0.48      1640\n",
      "          2       0.53      0.09      0.15      2198\n",
      "          3       0.28      0.59      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.1077145125909722\n",
      "1.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1091   258   291\n",
      "    2  807   473   918\n",
      "    3  141   157   762\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.59      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8886563372582708\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1159   267   214\n",
      "    2  855   519   824\n",
      "    3  151   184   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.71      0.61      1640\n",
      "          2       0.54      0.24      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8561262905658964\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  940    57   643\n",
      "    2 1015   190   993\n",
      "    3  314   114   632\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.57      0.48      1640\n",
      "          2       0.53      0.09      0.15      2198\n",
      "          3       0.28      0.60      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.1074380102329788\n",
      "1.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1093   255   292\n",
      "    2  808   477   913\n",
      "    3  140   158   762\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.59      1640\n",
      "          2       0.54      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8879668326900131\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1160   266   214\n",
      "    2  855   517   826\n",
      "    3  152   184   724\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.71      0.61      1640\n",
      "          2       0.53      0.24      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8567222713485284\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  943    54   643\n",
      "    2 1016   188   994\n",
      "    3  314   113   633\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.57      0.48      1640\n",
      "          2       0.53      0.09      0.15      2198\n",
      "          3       0.28      0.60      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.1072536369676982\n",
      "1.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1096   250   294\n",
      "    2  809   479   910\n",
      "    3  141   158   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.59      1640\n",
      "          2       0.54      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8885414569866695\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   262   216\n",
      "    2  856   514   828\n",
      "    3  152   184   724\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.71      0.61      1640\n",
      "          2       0.54      0.23      0.33      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8575559486013873\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  947    50   643\n",
      "    2 1019   182   997\n",
      "    3  313   112   635\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.48      1640\n",
      "          2       0.53      0.08      0.14      2198\n",
      "          3       0.28      0.60      0.38      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.1069770194915156\n",
      "1.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1101   246   293\n",
      "    2  812   474   912\n",
      "    3  140   160   760\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.60      1640\n",
      "          2       0.54      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8879668326900131\n",
      "#____________________white MinMax normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1161   263   216\n",
      "    2  859   511   828\n",
      "    3  151   185   724\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.23      0.32      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8576749792006976\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  946    48   646\n",
      "    2 1025   176   997\n",
      "    3  313   111   636\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.58      0.48      1640\n",
      "          2       0.53      0.08      0.14      2198\n",
      "          3       0.28      0.60      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.1083594165078847\n",
      "1.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1104   242   294\n",
      "    2  818   466   914\n",
      "    3  142   160   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.67      0.60      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8898043242208957\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   263   215\n",
      "    2  860   505   833\n",
      "    3  152   185   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.23      0.32      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8583888161775344\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  947    47   646\n",
      "    2 1035   164   999\n",
      "    3  313   111   636\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.58      0.48      1640\n",
      "          2       0.51      0.07      0.13      2198\n",
      "          3       0.28      0.60      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.109372079502594\n",
      "2.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1102   243   295\n",
      "    2  820   461   917\n",
      "    3  143   159   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.67      0.59      1640\n",
      "          2       0.53      0.21      0.30      2198\n",
      "          3       0.38      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8912944967579461\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   261   216\n",
      "    2  863   500   835\n",
      "    3  153   184   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.23      0.32      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8595772271248165\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  949    45   646\n",
      "    2 1038   159  1001\n",
      "    3  310   110   640\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.58      0.48      1640\n",
      "          2       0.51      0.07      0.13      2198\n",
      "          3       0.28      0.60      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1084515150095609\n",
      "2.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1105   237   298\n",
      "    2  824   457   917\n",
      "    3  144   158   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.67      0.60      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.38      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8927821820017444\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   261   217\n",
      "    2  863   498   837\n",
      "    3  153   183   724\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.23      0.32      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8601708168835119\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  953    41   646\n",
      "    2 1036   159  1003\n",
      "    3  309   110   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.41      0.58      0.48      1640\n",
      "          2       0.51      0.07      0.13      2198\n",
      "          3       0.28      0.60      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1077145125909722\n",
      "2.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1111   229   300\n",
      "    2  827   454   917\n",
      "    3  146   157   757\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.893924870530357\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   259   219\n",
      "    2  863   496   839\n",
      "    3  154   181   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.23      0.32      2198\n",
      "          3       0.41      0.68      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.861356769214109\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  957    37   646\n",
      "    2 1034   157  1007\n",
      "    3  309   107   644\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.52      0.07      0.13      2198\n",
      "          3       0.28      0.61      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1072536369676982\n",
      "2.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1107   229   304\n",
      "    2  829   449   920\n",
      "    3  146   157   757\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.59      1640\n",
      "          2       0.54      0.20      0.30      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8963197746473334\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   258   220\n",
      "    2  865   495   838\n",
      "    3  156   177   727\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.23      0.32      2198\n",
      "          3       0.41      0.69      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.86230435670551\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  959    35   646\n",
      "    2 1034   154  1010\n",
      "    3  308   106   646\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.52      0.07      0.12      2198\n",
      "          3       0.28      0.61      0.38      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1068847983042442\n",
      "2.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1110   227   303\n",
      "    2  835   446   917\n",
      "    3  146   158   756\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8960919643057081\n",
      "#____________________white MinMax normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1164   257   219\n",
      "    2  869   492   837\n",
      "    3  157   175   728\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.22      0.32      2198\n",
      "          3       0.41      0.69      0.51      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.86230435670551\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  962    32   646\n",
      "    2 1039   148  1011\n",
      "    3  306   106   648\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.59      0.49      1640\n",
      "          2       0.52      0.07      0.12      2198\n",
      "          3       0.28      0.61      0.39      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1064235770673758\n",
      "2.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1114   223   303\n",
      "    2  836   444   918\n",
      "    3  148   157   755\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8966613816373059\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   259   218\n",
      "    2  872   488   838\n",
      "    3  157   175   728\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.41      0.69      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.49      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8625410909190862\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  959    32   649\n",
      "    2 1042   145  1011\n",
      "    3  305   105   650\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.51      0.07      0.12      2198\n",
      "          3       0.28      0.61      0.39      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.107345827437611\n",
      "2.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1113   225   302\n",
      "    2  836   439   923\n",
      "    3  148   158   754\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.53      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8971166552800646\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   258   219\n",
      "    2  876   483   839\n",
      "    3  159   173   728\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.41      0.69      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8641964146176346\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  954    37   649\n",
      "    2 1039   146  1013\n",
      "    3  302   105   653\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.48      1640\n",
      "          2       0.51      0.07      0.12      2198\n",
      "          3       0.28      0.62      0.39      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1066080886299139\n",
      "2.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1117   223   300\n",
      "    2  840   435   923\n",
      "    3  147   159   754\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.53      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8960919643057081\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1165   256   219\n",
      "    2  881   476   841\n",
      "    3  159   166   735\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.41      0.69      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.49      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8639601339803769\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  958    33   649\n",
      "    2 1038   147  1013\n",
      "    3  303   101   656\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.52      0.07      0.12      2198\n",
      "          3       0.28      0.62      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1061467520156136\n",
      "2.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   223   299\n",
      "    2  838   438   922\n",
      "    3  146   157   757\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8946097830587743\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1168   252   220\n",
      "    2  890   466   842\n",
      "    3  159   165   736\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.21      0.30      2198\n",
      "          3       0.41      0.69      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8650228885960293\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  959    32   649\n",
      "    2 1038   146  1014\n",
      "    3  303   101   656\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.52      0.07      0.12      2198\n",
      "          3       0.28      0.62      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1061467520156136\n",
      "2.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   225   297\n",
      "    2  841   437   920\n",
      "    3  144   155   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.53      0.20      0.29      2198\n",
      "          3       0.38      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8928965166608546\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1172   247   221\n",
      "    2  893   463   842\n",
      "    3  160   160   740\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.21      0.30      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8651408918553731\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  957    31   652\n",
      "    2 1039   143  1016\n",
      "    3  295   109   656\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.51      0.07      0.12      2198\n",
      "          3       0.28      0.62      0.39      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1052235010810132\n",
      "3.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   223   297\n",
      "    2  850   428   920\n",
      "    3  143   152   765\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.53      0.19      0.29      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8928965166608546\n",
      "#____________________white MinMax normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1172   246   222\n",
      "    2  895   461   842\n",
      "    3  161   158   741\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.71      0.61      1640\n",
      "          2       0.53      0.21      0.30      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8659664644299766\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  956    32   652\n",
      "    2 1032   150  1016\n",
      "    3  291   113   656\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.51      0.07      0.12      2198\n",
      "          3       0.28      0.62      0.39      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.1035597029461146\n",
      "3.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   219   295\n",
      "    2  853   424   921\n",
      "    3  144   150   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.19      0.28      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8922102889304382\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1175   243   222\n",
      "    2  898   459   841\n",
      "    3  164   154   742\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.72      0.61      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8667912506909595\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  951    35   654\n",
      "    2 1025   155  1018\n",
      "    3  286   113   661\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.51      0.07      0.12      2198\n",
      "          3       0.28      0.62      0.39      1060\n",
      "\n",
      "avg / total       0.43      0.36      0.30      4898\n",
      "\n",
      "RMSE:\n",
      "1.10226390145574\n",
      "3.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   218   296\n",
      "    2  860   419   919\n",
      "    3  145   150   765\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.19      0.28      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8935822174018682\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1180   238   222\n",
      "    2  900   457   841\n",
      "    3  165   153   742\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.72      0.61      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8667912506909595\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  953    35   652\n",
      "    2 1017   163  1018\n",
      "    3  282   116   662\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.42      0.58      0.49      1640\n",
      "          2       0.52      0.07      0.13      2198\n",
      "          3       0.28      0.62      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.0995748835158807\n",
      "3.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1128   218   294\n",
      "    2  865   412   921\n",
      "    3  145   149   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.19      0.28      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8933537089676493\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1182   236   222\n",
      "    2  904   454   840\n",
      "    3  166   152   742\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8672622049504783\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  953    35   652\n",
      "    2 1010   167  1021\n",
      "    3  276   121   663\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.58      0.49      1640\n",
      "          2       0.52      0.08      0.13      2198\n",
      "          3       0.28      0.63      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.36      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.0974375290909493\n",
      "3.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   216   293\n",
      "    2  869   407   922\n",
      "    3  146   148   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.19      0.27      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8935822174018682\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1181   237   222\n",
      "    2  905   455   838\n",
      "    3  166   151   743\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.49      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8671444903649411\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  950    36   654\n",
      "    2  993   184  1021\n",
      "    3  265   132   663\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.58      0.49      1640\n",
      "          2       0.52      0.08      0.14      2198\n",
      "          3       0.28      0.63      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.37      0.31      4898\n",
      "\n",
      "RMSE:\n",
      "1.0936171024084607\n",
      "3.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   217   292\n",
      "    2  872   406   920\n",
      "    3  146   148   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8933537089676493\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1181   234   225\n",
      "    2  910   449   839\n",
      "    3  166   150   744\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.20      0.30      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8687910431653637\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  948    37   655\n",
      "    2  982   193  1023\n",
      "    3  262   132   666\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.58      0.49      1640\n",
      "          2       0.53      0.09      0.15      2198\n",
      "          3       0.28      0.63      0.39      1060\n",
      "\n",
      "avg / total       0.45      0.37      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.0921225788507471\n",
      "3.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1136   211   293\n",
      "    2  870   405   923\n",
      "    3  146   145   769\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8928965166608546\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1183   231   226\n",
      "    2  913   444   841\n",
      "    3  166   149   745\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8693783419839839\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  947    41   652\n",
      "    2  976   198  1024\n",
      "    3  255   135   670\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.58      0.50      1640\n",
      "          2       0.53      0.09      0.15      2198\n",
      "          3       0.29      0.63      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.37      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.0885648618959332\n",
      "3.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   209   292\n",
      "    2  874   402   922\n",
      "    3  147   142   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8926678326984253\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   230   226\n",
      "    2  917   439   842\n",
      "    3  166   147   747\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8696131504533523\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  935    53   652\n",
      "    2  961   210  1027\n",
      "    3  255   135   670\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.57      0.49      1640\n",
      "          2       0.53      0.10      0.16      2198\n",
      "          3       0.29      0.63      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.37      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.0885648618959332\n",
      "3.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   206   292\n",
      "    2  876   400   922\n",
      "    3  148   139   773\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8926678326984253\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1185   226   229\n",
      "    2  921   434   843\n",
      "    3  166   148   746\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8712550378365064\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  929    60   651\n",
      "    2  958   212  1028\n",
      "    3  251   138   671\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.57      0.49      1640\n",
      "          2       0.52      0.10      0.16      2198\n",
      "          3       0.29      0.63      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.37      0.32      4898\n",
      "\n",
      "RMSE:\n",
      "1.0874389541353613\n",
      "3.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   206   292\n",
      "    2  879   397   922\n",
      "    3  148   137   775\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8927821820017444\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1186   225   229\n",
      "    2  921   434   843\n",
      "    3  166   146   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8709034654079728\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  924    68   648\n",
      "    2  948   223  1027\n",
      "    3  240   147   673\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.56      0.49      1640\n",
      "          2       0.51      0.10      0.17      2198\n",
      "          3       0.29      0.63      0.39      1060\n",
      "\n",
      "avg / total       0.44      0.37      0.33      4898\n",
      "\n",
      "RMSE:\n",
      "1.0827350694913371\n",
      "4.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   200   291\n",
      "    2  884   393   921\n",
      "    3  149   135   776\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8923246968669128\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1187   224   229\n",
      "    2  922   432   844\n",
      "    3  167   146   747\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8714893406611902\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  922    73   645\n",
      "    2  936   240  1022\n",
      "    3  230   156   674\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.56      0.49      1640\n",
      "          2       0.51      0.11      0.18      2198\n",
      "          3       0.29      0.64      0.40      1060\n",
      "\n",
      "avg / total       0.44      0.37      0.33      4898\n",
      "\n",
      "RMSE:\n",
      "1.0775370794619334\n",
      "4.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1151   196   293\n",
      "    2  888   389   921\n",
      "    3  152   132   776\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8942673923657237\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1187   223   230\n",
      "    2  923   430   845\n",
      "    3  167   145   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.61      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8719577574328035\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  922    77   641\n",
      "    2  923   253  1022\n",
      "    3  226   155   679\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.56      0.50      1640\n",
      "          2       0.52      0.12      0.19      2198\n",
      "          3       0.29      0.64      0.40      1060\n",
      "\n",
      "avg / total       0.45      0.38      0.34      4898\n",
      "\n",
      "RMSE:\n",
      "1.0735507575671916\n",
      "4.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   195   293\n",
      "    2  890   387   921\n",
      "    3  152   131   777\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8942673923657237\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1192   218   230\n",
      "    2  924   427   847\n",
      "    3  169   143   748\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.61      1640\n",
      "          2       0.54      0.19      0.29      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8724259227054246\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  915    85   640\n",
      "    2  903   274  1021\n",
      "    3  221   154   685\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.56      0.50      1640\n",
      "          2       0.53      0.12      0.20      2198\n",
      "          3       0.29      0.65      0.40      1060\n",
      "\n",
      "avg / total       0.45      0.38      0.34      4898\n",
      "\n",
      "RMSE:\n",
      "1.0699312876965497\n",
      "4.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   190   294\n",
      "    2  889   384   925\n",
      "    3  152   131   777\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.17      0.26      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8944956673898288\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1192   218   230\n",
      "    2  926   423   849\n",
      "    3  169   143   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.61      1640\n",
      "          2       0.54      0.19      0.28      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8728938368837184\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  909    92   639\n",
      "    2  890   292  1016\n",
      "    3  211   158   691\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.55      0.50      1640\n",
      "          2       0.54      0.13      0.21      2198\n",
      "          3       0.29      0.65      0.41      1060\n",
      "\n",
      "avg / total       0.46      0.39      0.35      4898\n",
      "\n",
      "RMSE:\n",
      "1.0650542461124255\n",
      "4.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1158   188   294\n",
      "    2  898   371   929\n",
      "    3  152   129   779\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.54      0.17      0.26      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8955221849104592\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1192   218   230\n",
      "    2  928   421   849\n",
      "    3  169   143   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.61      1640\n",
      "          2       0.54      0.19      0.28      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8731276999386536\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  913    97   630\n",
      "    2  874   305  1019\n",
      "    3  203   161   696\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.46      0.56      0.50      1640\n",
      "          2       0.54      0.14      0.22      2198\n",
      "          3       0.30      0.66      0.41      1060\n",
      "\n",
      "avg / total       0.46      0.39      0.36      4898\n",
      "\n",
      "RMSE:\n",
      "1.0580342644242644\n",
      "4.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   183   294\n",
      "    2  903   365   930\n",
      "    3  153   128   779\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.54      0.17      0.25      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8959780374138478\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1192   218   230\n",
      "    2  930   417   851\n",
      "    3  169   142   749\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.61      1640\n",
      "          2       0.54      0.19      0.28      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8734783771199143\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  918   100   622\n",
      "    2  864   311  1023\n",
      "    3  200   158   702\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.46      0.56      0.51      1640\n",
      "          2       0.55      0.14      0.22      2198\n",
      "          3       0.30      0.66      0.41      1060\n",
      "\n",
      "avg / total       0.47      0.39      0.36      4898\n",
      "\n",
      "RMSE:\n",
      "1.053199058312908\n",
      "4.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1165   181   294\n",
      "    2  912   356   930\n",
      "    3  154   127   779\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.54      0.16      0.25      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8971166552800646\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1192   218   230\n",
      "    2  931   415   852\n",
      "    3  169   142   749\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.61      1640\n",
      "          2       0.54      0.19      0.28      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8737120837132923\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  922    99   619\n",
      "    2  863   311  1024\n",
      "    3  192   158   710\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      0.56      0.51      1640\n",
      "          2       0.55      0.14      0.22      2198\n",
      "          3       0.30      0.67      0.42      1060\n",
      "\n",
      "avg / total       0.47      0.40      0.36      4898\n",
      "\n",
      "RMSE:\n",
      "1.0488283143551467\n",
      "4.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1166   181   293\n",
      "    2  917   351   930\n",
      "    3  155   126   779\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.53      0.16      0.25      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8975716979952398\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1194   216   230\n",
      "    2  935   411   852\n",
      "    3  169   142   749\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.61      1640\n",
      "          2       0.53      0.19      0.28      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8739457278099179\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  930   105   605\n",
      "    2  856   321  1021\n",
      "    3  191   156   713\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      0.57      0.51      1640\n",
      "          2       0.55      0.15      0.23      2198\n",
      "          3       0.30      0.67      0.42      1060\n",
      "\n",
      "avg / total       0.47      0.40      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "1.0423847395677803\n",
      "4.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1169   176   295\n",
      "    2  920   347   931\n",
      "    3  156   124   780\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.54      0.16      0.24      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8985947015922615\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1193   217   230\n",
      "    2  938   407   853\n",
      "    3  170   141   749\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.61      1640\n",
      "          2       0.53      0.19      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8748796802301118\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  943   108   589\n",
      "    2  846   330  1022\n",
      "    3  189   154   717\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.57      0.52      1640\n",
      "          2       0.56      0.15      0.24      2198\n",
      "          3       0.31      0.68      0.42      1060\n",
      "\n",
      "avg / total       0.48      0.41      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "1.034520540182955\n",
      "4.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1169   174   297\n",
      "    2  925   342   931\n",
      "    3  154   124   782\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.53      0.16      0.24      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.898935444081254\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1193   217   230\n",
      "    2  941   403   854\n",
      "    3  170   141   749\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8753462827594063\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  958   106   576\n",
      "    2  843   328  1027\n",
      "    3  188   153   719\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.58      0.53      1640\n",
      "          2       0.56      0.15      0.24      2198\n",
      "          3       0.31      0.68      0.43      1060\n",
      "\n",
      "avg / total       0.48      0.41      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "1.028880627205504\n",
      "5.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1173   172   295\n",
      "    2  930   335   933\n",
      "    3  156   122   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.53      0.15      0.24      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8992760574603537\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1193   217   230\n",
      "    2  941   404   853\n",
      "    3  171   141   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8756960714977465\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  970   104   566\n",
      "    2  852   322  1024\n",
      "    3  187   148   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.59      0.53      1640\n",
      "          2       0.56      0.15      0.23      2198\n",
      "          3       0.31      0.68      0.43      1060\n",
      "\n",
      "avg / total       0.48      0.41      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "1.0244061311807213\n",
      "5.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1177   169   294\n",
      "    2  933   332   933\n",
      "    3  160   117   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.54      0.15      0.24      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.9000703207408192\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1194   216   230\n",
      "    2  940   405   853\n",
      "    3  172   140   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.61      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8758126366991278\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  987    99   554\n",
      "    2  858   319  1021\n",
      "    3  192   138   730\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.60      0.54      1640\n",
      "          2       0.57      0.15      0.23      2198\n",
      "          3       0.32      0.69      0.43      1060\n",
      "\n",
      "avg / total       0.49      0.42      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "1.020412329888744\n",
      "5.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   164   292\n",
      "    2  940   323   935\n",
      "    3  162   116   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.54      0.15      0.23      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.9004105048111982\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1193   217   230\n",
      "    2  941   404   853\n",
      "    3  172   140   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.87604572057197\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1000    97   543\n",
      "    2  875   298  1025\n",
      "    3  191   134   735\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.61      0.54      1640\n",
      "          2       0.56      0.14      0.22      2198\n",
      "          3       0.32      0.69      0.44      1060\n",
      "\n",
      "avg / total       0.48      0.42      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "1.0171056381390975\n",
      "5.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   167   289\n",
      "    2  942   323   933\n",
      "    3  163   115   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.53      0.15      0.23      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8997300080483062\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1195   215   230\n",
      "    2  943   401   854\n",
      "    3  173   140   747\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.70      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8766281591181759\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1023    96   521\n",
      "    2  892   282  1024\n",
      "    3  190   125   745\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.62      0.55      1640\n",
      "          2       0.56      0.13      0.21      2198\n",
      "          3       0.33      0.70      0.44      1060\n",
      "\n",
      "avg / total       0.48      0.42      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "1.008437252445204\n",
      "5.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1186   167   287\n",
      "    2  947   316   935\n",
      "    3  165   114   781\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.53      0.14      0.23      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9004105048111982\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1194   218   228\n",
      "    2  946   399   853\n",
      "    3  174   138   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8765117023711834\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1050    87   503\n",
      "    2  903   277  1018\n",
      "    3  193   119   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.64      0.55      1640\n",
      "          2       0.57      0.13      0.21      2198\n",
      "          3       0.33      0.71      0.45      1060\n",
      "\n",
      "avg / total       0.49      0.42      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "1.0013261928806194\n",
      "5.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   168   288\n",
      "    2  951   311   936\n",
      "    3  166   111   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.14      0.22      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9016567483208721\n",
      "#____________________white MinMax normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1194   219   227\n",
      "    2  947   398   853\n",
      "    3  177   135   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8773265749711869\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1073    88   479\n",
      "    2  917   258  1023\n",
      "    3  197   105   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.65      0.56      1640\n",
      "          2       0.57      0.12      0.19      2198\n",
      "          3       0.34      0.72      0.46      1060\n",
      "\n",
      "avg / total       0.49      0.43      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9937534589208687\n",
      "5.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1183   170   287\n",
      "    2  953   312   933\n",
      "    3  166   110   784\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.14      0.22      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9012037682629831\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1196   216   228\n",
      "    2  950   395   853\n",
      "    3  178   134   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8781406914086817\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1100    87   453\n",
      "    2  944   232  1022\n",
      "    3  201    96   763\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.67      0.57      1640\n",
      "          2       0.56      0.11      0.18      2198\n",
      "          3       0.34      0.72      0.46      1060\n",
      "\n",
      "avg / total       0.49      0.43      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9863295897498817\n",
      "5.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1186   167   287\n",
      "    2  960   303   935\n",
      "    3  169   110   781\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.52      0.14      0.22      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9032403895456933\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1198   215   227\n",
      "    2  951   394   853\n",
      "    3  179   133   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8780244352763911\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1112   100   428\n",
      "    2  958   234  1006\n",
      "    3  198    97   765\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.68      0.57      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.35      0.72      0.47      1060\n",
      "\n",
      "avg / total       0.48      0.43      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9759249782063036\n",
      "5.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   168   288\n",
      "    2  957   305   936\n",
      "    3  169   109   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.52      0.14      0.22      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9034663974034893\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1200   213   227\n",
      "    2  952   395   851\n",
      "    3  180   131   749\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8779081637489957\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1122   114   404\n",
      "    2  971   231   996\n",
      "    3  195    98   767\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.68      0.57      1640\n",
      "          2       0.52      0.11      0.17      2198\n",
      "          3       0.35      0.72      0.48      1060\n",
      "\n",
      "avg / total       0.47      0.43      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9664650620745161\n",
      "5.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1192   159   289\n",
      "    2  968   295   935\n",
      "    3  168   108   784\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.52      0.13      0.21      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9034663974034893\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1200   214   226\n",
      "    2  958   391   849\n",
      "    3  180   131   749\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8780244352763911\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1135   131   374\n",
      "    2  978   225   995\n",
      "    3  194    96   770\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.69      0.58      1640\n",
      "          2       0.50      0.10      0.17      2198\n",
      "          3       0.36      0.73      0.48      1060\n",
      "\n",
      "avg / total       0.47      0.43      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9555237960331636\n",
      "6.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1194   157   289\n",
      "    2  973   284   941\n",
      "    3  170   108   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.52      0.13      0.21      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.905385186341815\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1198   215   227\n",
      "    2  959   389   850\n",
      "    3  182   129   749\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8795345663993092\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   134   363\n",
      "    2  979   222   997\n",
      "    3  189    91   780\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.70      0.58      1640\n",
      "          2       0.50      0.10      0.17      2198\n",
      "          3       0.36      0.74      0.49      1060\n",
      "\n",
      "avg / total       0.47      0.44      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.948769377653091\n",
      "6.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1198   153   289\n",
      "    2  979   277   942\n",
      "    3  170   107   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.52      0.13      0.20      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9056106589356083\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1200   212   228\n",
      "    2  961   388   849\n",
      "    3  183   127   750\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8799987007674436\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   145   345\n",
      "    2  986   222   990\n",
      "    3  188    91   781\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.70      0.58      1640\n",
      "          2       0.48      0.10      0.17      2198\n",
      "          3       0.37      0.74      0.49      1060\n",
      "\n",
      "avg / total       0.46      0.44      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.941749759346004\n",
      "6.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1198   154   288\n",
      "    2  984   272   942\n",
      "    3  170   107   783\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9058360754067872\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1200   211   229\n",
      "    2  961   386   851\n",
      "    3  184   125   751\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.18      0.26      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8808103474127859\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   155   332\n",
      "    2  986   237   975\n",
      "    3  188    86   786\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.70      0.58      1640\n",
      "          2       0.50      0.11      0.18      2198\n",
      "          3       0.38      0.74      0.50      1060\n",
      "\n",
      "avg / total       0.47      0.44      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9350050167673728\n",
      "6.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1202   150   288\n",
      "    2  989   267   942\n",
      "    3  170   107   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9059487626094881\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1201   208   231\n",
      "    2  965   382   851\n",
      "    3  185   123   752\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.17      0.26      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.882084283233549\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1159   157   324\n",
      "    2  984   236   978\n",
      "    3  186    87   787\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.71      0.58      1640\n",
      "          2       0.49      0.11      0.18      2198\n",
      "          3       0.38      0.74      0.50      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9310662933592025\n",
      "6.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1206   146   288\n",
      "    2  991   263   944\n",
      "    3  173   104   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.19      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9069623173877128\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1201   208   231\n",
      "    2  965   381   852\n",
      "    3  187   120   753\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.17      0.26      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8827783824490695\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1168   153   319\n",
      "    2  983   238   977\n",
      "    3  185    86   789\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.71      0.59      1640\n",
      "          2       0.50      0.11      0.18      2198\n",
      "          3       0.38      0.74      0.50      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9276612144018926\n",
      "6.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1210   142   288\n",
      "    2  994   259   945\n",
      "    3  176   101   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.52      0.12      0.19      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9079747407548945\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1201   208   231\n",
      "    2  967   376   855\n",
      "    3  187   119   754\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.17      0.26      2198\n",
      "          3       0.41      0.71      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8832408122253882\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1169   156   315\n",
      "    2  983   239   976\n",
      "    3  183    88   789\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.71      0.59      1640\n",
      "          2       0.49      0.11      0.18      2198\n",
      "          3       0.38      0.74      0.50      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9254577404721163\n",
      "6.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1212   138   290\n",
      "    2  999   250   949\n",
      "    3  177   100   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.51      0.11      0.19      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9097718226531251\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1202   206   232\n",
      "    2  967   374   857\n",
      "    3  187   115   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.17      0.26      2198\n",
      "          3       0.41      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8832408122253882\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1179   150   311\n",
      "    2  979   243   976\n",
      "    3  184    83   793\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.72      0.59      1640\n",
      "          2       0.51      0.11      0.18      2198\n",
      "          3       0.38      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9224747017327207\n",
      "6.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1215   135   290\n",
      "    2 1005   243   950\n",
      "    3  178    99   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.51      0.11      0.18      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9105569307026513\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1202   206   232\n",
      "    2  969   365   864\n",
      "    3  187   114   759\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.17      0.25      2198\n",
      "          3       0.41      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8841649462079455\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1182   150   308\n",
      "    2  981   247   970\n",
      "    3  184    81   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.72      0.59      1640\n",
      "          2       0.52      0.11      0.18      2198\n",
      "          3       0.38      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9204806385588005\n",
      "6.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   134   292\n",
      "    2 1008   239   951\n",
      "    3  181    96   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.51      0.11      0.18      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9127963756262796\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1203   204   233\n",
      "    2  972   360   866\n",
      "    3  187   113   760\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.16      0.25      2198\n",
      "          3       0.41      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8848574133128178\n",
      "#____________________white log normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1182   150   308\n",
      "    2  981   242   975\n",
      "    3  184    78   798\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.72      0.59      1640\n",
      "          2       0.51      0.11      0.18      2198\n",
      "          3       0.38      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9207024144055455\n",
      "6.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1218   131   291\n",
      "    2 1007   239   952\n",
      "    3  184    93   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.52      0.11      0.18      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9130200180100412\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1204   199   237\n",
      "    2  972   358   868\n",
      "    3  187   113   760\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.16      0.25      2198\n",
      "          3       0.41      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.886355902808486\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1186   150   304\n",
      "    2  979   246   973\n",
      "    3  185    80   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.72      0.59      1640\n",
      "          2       0.52      0.11      0.18      2198\n",
      "          3       0.38      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9191488597491233\n",
      "7.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1222   124   294\n",
      "    2 1013   233   952\n",
      "    3  186    90   784\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.52      0.11      0.18      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9148071888281853\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1204   198   238\n",
      "    2  972   355   871\n",
      "    3  188   110   762\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.16      0.25      2198\n",
      "          3       0.41      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8871617333950389\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1185   150   305\n",
      "    2  974   254   970\n",
      "    3  184    82   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.52      0.12      0.19      2198\n",
      "          3       0.38      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9184822462009605\n",
      "7.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1223   124   293\n",
      "    2 1013   231   954\n",
      "    3  188    88   784\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.52      0.11      0.17      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.91525343626391\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1204   194   242\n",
      "    2  972   350   876\n",
      "    3  188   108   764\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.16      0.25      2198\n",
      "          3       0.41      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8888860532598479\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1190   152   298\n",
      "    2  977   255   966\n",
      "    3  185    79   796\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.52      0.12      0.19      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9155879791089281\n",
      "7.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1227   120   293\n",
      "    2 1019   224   955\n",
      "    3  190    85   785\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.52      0.10      0.17      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1204   192   244\n",
      "    2  974   348   876\n",
      "    3  188   106   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.16      0.24      2198\n",
      "          3       0.41      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8895748453455847\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1188   160   292\n",
      "    2  967   268   963\n",
      "    3  185    78   797\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.12      0.20      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9122370297954432\n",
      "7.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1227   120   293\n",
      "    2 1026   214   958\n",
      "    3  195    77   788\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.52      0.10      0.16      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9185933820530462\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1204   189   247\n",
      "    2  974   340   884\n",
      "    3  188   105   767\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.15      0.24      2198\n",
      "          3       0.40      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8914090222318217\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1185   165   290\n",
      "    2  966   275   957\n",
      "    3  184    79   797\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.13      0.20      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9107811229824743\n",
      "7.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1224   123   293\n",
      "    2 1036   204   958\n",
      "    3  196    76   788\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.51      0.09      0.16      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9203697305954412\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1205   185   250\n",
      "    2  975   329   894\n",
      "    3  188   104   768\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.53      0.15      0.23      2198\n",
      "          3       0.40      0.72      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8934679704900157\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1187   163   290\n",
      "    2  967   276   955\n",
      "    3  184    77   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.13      0.20      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9102205387458344\n",
      "7.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1225   121   294\n",
      "    2 1042   196   960\n",
      "    3  196    75   789\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.09      0.15      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9213674216532473\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1206   181   253\n",
      "    2  976   320   902\n",
      "    3  188   103   769\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.53      0.15      0.23      2198\n",
      "          3       0.40      0.73      0.52      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8952941716197078\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1187   163   290\n",
      "    2  967   276   955\n",
      "    3  184    77   799\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.13      0.20      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9102205387458344\n",
      "7.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1225   122   293\n",
      "    2 1044   195   959\n",
      "    3  198    72   790\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.09      0.15      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9216997453508536\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1208   176   256\n",
      "    2  976   313   909\n",
      "    3  188   103   769\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.53      0.14      0.22      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.8968890473466081\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1187   163   290\n",
      "    2  967   276   955\n",
      "    3  184    77   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.13      0.20      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9102205387458344\n",
      "7.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1226   119   295\n",
      "    2 1047   188   963\n",
      "    3  199    70   791\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.09      0.15      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9232490076322399\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1208   174   258\n",
      "    2  979   304   915\n",
      "    3  188   103   769\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.52      0.14      0.22      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.8985947015922615\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1194   156   290\n",
      "    2  973   270   955\n",
      "    3  186    75   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.12      0.20      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9107811229824743\n",
      "7.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1228   118   294\n",
      "    2 1048   188   962\n",
      "    3  198    71   791\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.09      0.15      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9223640335418442\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1208   174   258\n",
      "    2  985   297   916\n",
      "    3  189   102   769\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.52      0.14      0.21      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.8997300080483062\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1194   156   290\n",
      "    2  973   270   955\n",
      "    3  186    75   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.12      0.20      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9107811229824743\n",
      "7.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1229   116   295\n",
      "    2 1049   186   963\n",
      "    3  201    67   792\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.14      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9236911767225471\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1211   171   258\n",
      "    2  989   292   917\n",
      "    3  189   101   770\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.52      0.13      0.21      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.8998434599128323\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1196   154   290\n",
      "    2  977   266   955\n",
      "    3  187    74   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.12      0.20      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9113413623926419\n",
      "8.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1229   118   293\n",
      "    2 1052   184   962\n",
      "    3  201    65   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.14      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9230278436555053\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1212   168   260\n",
      "    2  997   284   917\n",
      "    3  191    98   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.52      0.13      0.21      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9018831530321166\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1199   151   290\n",
      "    2  985   258   955\n",
      "    3  187    73   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.54      0.12      0.19      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9117893060728692\n",
      "8.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1234   112   294\n",
      "    2 1054   182   962\n",
      "    3  203    63   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.51      0.08      0.14      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9236911767225471\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1213   167   260\n",
      "    2 1002   279   917\n",
      "    3  195    94   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.52      0.13      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9036923487381221\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1206   144   290\n",
      "    2  996   247   955\n",
      "    3  193    67   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.19      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.914249073231834\n",
      "8.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1233   113   294\n",
      "    2 1056   178   964\n",
      "    3  203    62   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.14      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9241331342486598\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1008   273   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9049340726185721\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1206   144   290\n",
      "    2 1001   242   955\n",
      "    3  195    65   800\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9154764784108214\n",
      "8.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1234   111   295\n",
      "    2 1063   170   965\n",
      "    3  203    62   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9252371044598088\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1206   144   290\n",
      "    2 1001   242   955\n",
      "    3  195    65   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9154764784108214\n",
      "8.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1237   108   295\n",
      "    2 1063   168   967\n",
      "    3  205    60   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.925788595898454\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1211   139   290\n",
      "    2 1004   239   955\n",
      "    3  197    63   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9159223997613809\n",
      "8.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1237   110   293\n",
      "    2 1062   167   969\n",
      "    3  205    58   797\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9250164158211395\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   136   290\n",
      "    2 1009   234   955\n",
      "    3  197    63   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "8.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1237   110   293\n",
      "    2 1064   169   965\n",
      "    3  205    61   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9251267667211229\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   136   290\n",
      "    2 1009   234   955\n",
      "    3  197    63   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "8.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1238   108   294\n",
      "    2 1065   169   964\n",
      "    3  205    61   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9253474290419048\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   136   290\n",
      "    2 1009   234   955\n",
      "    3  197    63   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "8.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1238   109   293\n",
      "    2 1065   166   967\n",
      "    3  205    61   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.49      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9253474290419048\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   136   290\n",
      "    2 1009   234   955\n",
      "    3  197    63   800\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "8.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1237   112   291\n",
      "    2 1065   165   968\n",
      "    3  206    60   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.49      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9252371044598088\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   136   290\n",
      "    2 1009   234   955\n",
      "    3  197    63   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "9.0\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1238   112   290\n",
      "    2 1065   164   969\n",
      "    3  208    57   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.49      0.07      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9254577404721163\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   136   290\n",
      "    2 1009   234   955\n",
      "    3  197    63   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "9.1\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1238   114   288\n",
      "    2 1069   162   967\n",
      "    3  212    53   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.49      0.07      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9263397590096685\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   136   290\n",
      "    2 1009   234   955\n",
      "    3  197    63   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.11      0.18      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "9.2\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1241   109   290\n",
      "    2 1070   161   967\n",
      "    3  210    54   796\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.76      0.60      1640\n",
      "          2       0.50      0.07      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9260091005093928\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   132   294\n",
      "    2 1009   229   960\n",
      "    3  197    62   801\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.10      0.17      2198\n",
      "          3       0.39      0.76      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9179263651077367\n",
      "9.3\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1244   106   290\n",
      "    2 1082   154   962\n",
      "    3  216    46   798\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.76      0.59      1640\n",
      "          2       0.50      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9282112655705348\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   124   302\n",
      "    2 1009   221   968\n",
      "    3  197    61   802\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.10      0.17      2198\n",
      "          3       0.39      0.76      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9213674216532473\n",
      "9.4\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1257    92   291\n",
      "    2 1092   145   961\n",
      "    3  221    42   797\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.52      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.36      4898\n",
      "\n",
      "RMSE:\n",
      "0.9298594668074489\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   120   306\n",
      "    2 1009   219   970\n",
      "    3  197    61   802\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.55      0.10      0.17      2198\n",
      "          3       0.39      0.76      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9229172417925889\n",
      "9.5\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    88   293\n",
      "    2 1092   150   956\n",
      "    3  222    39   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9298594668074489\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   119   307\n",
      "    2 1009   210   979\n",
      "    3  197    60   803\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.10      0.16      2198\n",
      "          3       0.38      0.76      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9241331342486598\n",
      "9.6\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    88   293\n",
      "    2 1092   150   956\n",
      "    3  222    39   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9298594668074489\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   113   313\n",
      "    2 1009   204   985\n",
      "    3  197    57   806\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.55      0.09      0.16      2198\n",
      "          3       0.38      0.76      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9264499522841926\n",
      "9.7\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    86   295\n",
      "    2 1092   147   959\n",
      "    3  222    38   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.36      4898\n",
      "\n",
      "RMSE:\n",
      "0.9307373140332179\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   106   320\n",
      "    2 1009   191   998\n",
      "    3  197    55   808\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.54      0.09      0.15      2198\n",
      "          3       0.38      0.76      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9299692430272762\n",
      "9.8\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    89   292\n",
      "    2 1092   150   956\n",
      "    3  222    38   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9294202322686254\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   100   326\n",
      "    2 1009   172  1017\n",
      "    3  197    55   808\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.53      0.08      0.14      2198\n",
      "          3       0.38      0.76      0.50      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9340218930477634\n",
      "9.9\n",
      "#____________________white STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    91   290\n",
      "    2 1092   151   955\n",
      "    3  222    38   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9286510719281068\n",
      "#____________________white MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   166   260\n",
      "    2 1009   272   917\n",
      "    3  197    92   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.40      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9050468721294644\n",
      "#____________________white log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   100   326\n",
      "    2 1009   172  1017\n",
      "    3  197    55   808\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.74      0.60      1640\n",
      "          2       0.53      0.08      0.14      2198\n",
      "          3       0.38      0.76      0.50      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9340218930477634\n"
     ]
    }
   ],
   "source": [
    "for t in range (0,10000,100):\n",
    "    t = t/1000\n",
    "    print(t)\n",
    "    print(\"#____________________white STD normed____________________#\")\n",
    "    run_kncs_report(white_norm.values, white_targetclass,t)\n",
    "    print(\"#____________________white MinMax normed____________________#\")\n",
    "    run_kncs_report(mm_white_norm.values, white_targetclass,t)\n",
    "    print(\"#____________________white log normed____________________#\")\n",
    "    run_kncs_report(log_white_norm.values, white_targetclass,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1078   272   290\n",
      "    2  783   537   878\n",
      "    3  138   181   741\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8838185092014216\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "0.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1080   270   290\n",
      "    2  781   542   875\n",
      "    3  138   180   742\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.25      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8828940125998633\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  543   136    65\n",
      "    2  217   220   201\n",
      "    3   11    41   165\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.72       744\n",
      "          2       0.55      0.34      0.43       638\n",
      "          3       0.38      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7498175721431742\n",
      "0.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1079   271   290\n",
      "    2  784   535   879\n",
      "    3  138   179   743\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.34      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8837030000185194\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  542   137    65\n",
      "    2  215   220   203\n",
      "    3   11    40   166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.73      0.72       744\n",
      "          2       0.55      0.34      0.43       638\n",
      "          3       0.38      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7498175721431742\n",
      "0.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1082   268   290\n",
      "    2  786   531   881\n",
      "    3  140   175   745\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.33      2198\n",
      "          3       0.39      0.70      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8842803950490993\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  543   134    67\n",
      "    2  213   218   207\n",
      "    3   11    40   166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.73      0.72       744\n",
      "          2       0.56      0.34      0.42       638\n",
      "          3       0.38      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7527311124031857\n",
      "0.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1083   266   291\n",
      "    2  788   524   886\n",
      "    3  140   172   748\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.24      0.33      2198\n",
      "          3       0.39      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8849727718184005\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  545   130    69\n",
      "    2  214   213   211\n",
      "    3   11    38   168\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.73      0.72       744\n",
      "          2       0.56      0.33      0.42       638\n",
      "          3       0.38      0.77      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7556334188379908\n",
      "0.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1085   265   290\n",
      "    2  785   519   894\n",
      "    3  140   168   752\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.24      0.33      2198\n",
      "          3       0.39      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8845112475253071\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  544   130    70\n",
      "    2  217   202   219\n",
      "    3   11    37   169\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.72       744\n",
      "          2       0.55      0.32      0.40       638\n",
      "          3       0.37      0.78      0.50       217\n",
      "\n",
      "avg / total       0.60      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7614048435851304\n",
      "0.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1088   263   289\n",
      "    2  786   516   896\n",
      "    3  138   166   756\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.60      1640\n",
      "          2       0.55      0.23      0.33      2198\n",
      "          3       0.39      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8830096276088838\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  544   130    70\n",
      "    2  216   194   228\n",
      "    3   11    36   170\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.73      0.72       744\n",
      "          2       0.54      0.30      0.39       638\n",
      "          3       0.36      0.78      0.50       217\n",
      "\n",
      "avg / total       0.59      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7642742125179613\n",
      "0.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1086   259   295\n",
      "    2  786   515   897\n",
      "    3  138   164   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.60      1640\n",
      "          2       0.55      0.23      0.33      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.46      4898\n",
      "\n",
      "RMSE:\n",
      "0.8852034437294778\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  546   129    69\n",
      "    2  216   191   231\n",
      "    3   11    35   171\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.73      0.72       744\n",
      "          2       0.54      0.30      0.38       638\n",
      "          3       0.36      0.79      0.50       217\n",
      "\n",
      "avg / total       0.59      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "0.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1085   259   296\n",
      "    2  786   512   900\n",
      "    3  138   163   759\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.55      0.23      0.33      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8858950990846932\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  549   126    69\n",
      "    2  216   188   234\n",
      "    3   11    34   172\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.54      0.29      0.38       638\n",
      "          3       0.36      0.79      0.50       217\n",
      "\n",
      "avg / total       0.59      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7626358950657756\n",
      "0.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1086   260   294\n",
      "    2  789   501   908\n",
      "    3  139   160   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.23      0.32      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8864710663122278\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  549   126    69\n",
      "    2  215   188   235\n",
      "    3   11    34   172\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.54      0.29      0.38       638\n",
      "          3       0.36      0.79      0.50       217\n",
      "\n",
      "avg / total       0.59      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7626358950657756\n",
      "1.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1088   259   293\n",
      "    2  792   497   909\n",
      "    3  139   160   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.23      0.32      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.886355902808486\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  549   125    70\n",
      "    2  212   189   237\n",
      "    3   11    34   172\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.54      0.30      0.38       638\n",
      "          3       0.36      0.79      0.49       217\n",
      "\n",
      "avg / total       0.60      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7634554932550838\n",
      "1.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1090   259   291\n",
      "    2  794   496   908\n",
      "    3  140   160   760\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.54      0.23      0.32      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8860103224836438\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  548   126    70\n",
      "    2  213   187   238\n",
      "    3   11    34   172\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.54      0.29      0.38       638\n",
      "          3       0.36      0.79      0.49       217\n",
      "\n",
      "avg / total       0.59      0.57      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7646832434343277\n",
      "1.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1092   260   288\n",
      "    2  797   493   908\n",
      "    3  140   159   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.60      1640\n",
      "          2       0.54      0.22      0.32      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8849727718184005\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  550   122    72\n",
      "    2  214   185   239\n",
      "    3   11    33   173\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.54      0.29      0.38       638\n",
      "          3       0.36      0.80      0.49       217\n",
      "\n",
      "avg / total       0.60      0.57      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7667251248887764\n",
      "1.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1089   264   287\n",
      "    2  804   481   913\n",
      "    3  140   160   760\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8864710663122278\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   120    73\n",
      "    2  213   185   240\n",
      "    3   11    31   175\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.55      0.29      0.38       638\n",
      "          3       0.36      0.81      0.50       217\n",
      "\n",
      "avg / total       0.60      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7667251248887764\n",
      "1.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1090   261   289\n",
      "    2  805   481   912\n",
      "    3  140   162   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.66      0.59      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8872767923065394\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   119    74\n",
      "    2  211   186   241\n",
      "    3   11    31   175\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.55      0.29      0.38       638\n",
      "          3       0.36      0.81      0.50       217\n",
      "\n",
      "avg / total       0.60      0.57      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.7675403565118231\n",
      "1.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1091   258   291\n",
      "    2  807   473   918\n",
      "    3  141   157   762\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.59      1640\n",
      "          2       0.53      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8886563372582708\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   115    78\n",
      "    2  211   182   245\n",
      "    3   11    31   175\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.55      0.29      0.38       638\n",
      "          3       0.35      0.81      0.49       217\n",
      "\n",
      "avg / total       0.60      0.57      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.77403129961455\n",
      "1.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1093   255   292\n",
      "    2  808   477   913\n",
      "    3  140   158   762\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.59      1640\n",
      "          2       0.54      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8879668326900131\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  549   115    80\n",
      "    2  213   178   247\n",
      "    3   11    31   175\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.55      0.28      0.37       638\n",
      "          3       0.35      0.81      0.49       217\n",
      "\n",
      "avg / total       0.60      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7788640081647817\n",
      "1.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1096   250   294\n",
      "    2  809   479   910\n",
      "    3  141   158   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.59      1640\n",
      "          2       0.54      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.51      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8885414569866695\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  550   113    81\n",
      "    2  213   175   250\n",
      "    3   11    30   176\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.55      0.27      0.37       638\n",
      "          3       0.35      0.81      0.49       217\n",
      "\n",
      "avg / total       0.60      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7804682611686925\n",
      "1.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1101   246   293\n",
      "    2  812   474   912\n",
      "    3  140   160   760\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.54      0.67      0.60      1640\n",
      "          2       0.54      0.22      0.31      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.45      4898\n",
      "\n",
      "RMSE:\n",
      "0.8879668326900131\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553   109    82\n",
      "    2  213   175   250\n",
      "    3   11    30   176\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.56      0.27      0.37       638\n",
      "          3       0.35      0.81      0.49       217\n",
      "\n",
      "avg / total       0.60      0.57      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7804682611686925\n",
      "1.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1104   242   294\n",
      "    2  818   466   914\n",
      "    3  142   160   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.67      0.60      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.48      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8898043242208957\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554   107    83\n",
      "    2  212   173   253\n",
      "    3   11    32   174\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.55      0.27      0.36       638\n",
      "          3       0.34      0.80      0.48       217\n",
      "\n",
      "avg / total       0.60      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7828684767618647\n",
      "2.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1102   243   295\n",
      "    2  820   461   917\n",
      "    3  143   159   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.67      0.59      1640\n",
      "          2       0.53      0.21      0.30      2198\n",
      "          3       0.38      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8912944967579461\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554   107    83\n",
      "    2  213   168   257\n",
      "    3   11    32   174\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.55      0.26      0.36       638\n",
      "          3       0.34      0.80      0.48       217\n",
      "\n",
      "avg / total       0.60      0.56      0.55      1599\n",
      "\n",
      "RMSE:\n",
      "0.7848630493620582\n",
      "2.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1105   237   298\n",
      "    2  824   457   917\n",
      "    3  144   158   758\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.67      0.60      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.38      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8927821820017444\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  552   107    85\n",
      "    2  214   165   259\n",
      "    3   11    32   174\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.54      0.26      0.35       638\n",
      "          3       0.34      0.80      0.47       217\n",
      "\n",
      "avg / total       0.59      0.56      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.789233365878645\n",
      "2.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1111   229   300\n",
      "    2  827   454   917\n",
      "    3  146   157   757\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.54      0.21      0.30      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.893924870530357\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554   106    84\n",
      "    2  216   163   259\n",
      "    3   11    32   174\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.73       744\n",
      "          2       0.54      0.26      0.35       638\n",
      "          3       0.34      0.80      0.47       217\n",
      "\n",
      "avg / total       0.59      0.56      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.7880438650279914\n",
      "2.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1107   229   304\n",
      "    2  829   449   920\n",
      "    3  146   157   757\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.59      1640\n",
      "          2       0.54      0.20      0.30      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8963197746473334\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553   105    86\n",
      "    2  219   158   261\n",
      "    3   11    32   174\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.54      0.25      0.34       638\n",
      "          3       0.33      0.80      0.47       217\n",
      "\n",
      "avg / total       0.59      0.55      0.54      1599\n",
      "\n",
      "RMSE:\n",
      "0.7927911601675278\n",
      "2.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1110   227   303\n",
      "    2  835   446   917\n",
      "    3  146   158   756\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8960919643057081\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   105    88\n",
      "    2  224   153   261\n",
      "    3   11    31   175\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.53      0.24      0.33       638\n",
      "          3       0.33      0.81      0.47       217\n",
      "\n",
      "avg / total       0.58      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.797510196844714\n",
      "2.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1114   223   303\n",
      "    2  836   444   918\n",
      "    3  148   157   755\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8966613816373059\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551   104    89\n",
      "    2  224   152   262\n",
      "    3   11    27   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.54      0.24      0.33       638\n",
      "          3       0.34      0.82      0.48       217\n",
      "\n",
      "avg / total       0.59      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.797510196844714\n",
      "2.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1113   225   302\n",
      "    2  836   439   923\n",
      "    3  148   158   754\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.53      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8971166552800646\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553   100    91\n",
      "    2  223   152   263\n",
      "    3   11    26   180\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.55      0.24      0.33       638\n",
      "          3       0.34      0.83      0.48       217\n",
      "\n",
      "avg / total       0.59      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.7986855993938882\n",
      "2.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1117   223   300\n",
      "    2  840   435   923\n",
      "    3  147   159   754\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.53      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8960919643057081\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  552    98    94\n",
      "    2  224   151   263\n",
      "    3   11    26   180\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.55      0.24      0.33       638\n",
      "          3       0.34      0.83      0.48       217\n",
      "\n",
      "avg / total       0.59      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.8029806885855979\n",
      "2.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   223   299\n",
      "    2  838   438   922\n",
      "    3  146   157   757\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.54      0.20      0.29      2198\n",
      "          3       0.38      0.71      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8946097830587743\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551    97    96\n",
      "    2  224   149   265\n",
      "    3   11    26   180\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.55      0.23      0.33       638\n",
      "          3       0.33      0.83      0.47       217\n",
      "\n",
      "avg / total       0.59      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.8064778385455118\n",
      "2.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   225   297\n",
      "    2  841   437   920\n",
      "    3  144   155   761\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.53      0.20      0.29      2198\n",
      "          3       0.38      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8928965166608546\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  551    97    96\n",
      "    2  221   149   268\n",
      "    3   11    26   180\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.55      0.23      0.33       638\n",
      "          3       0.33      0.83      0.47       217\n",
      "\n",
      "avg / total       0.59      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.8064778385455118\n",
      "3.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   223   297\n",
      "    2  850   428   920\n",
      "    3  143   152   765\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.68      0.60      1640\n",
      "          2       0.53      0.19      0.29      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8928965166608546\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553    96    95\n",
      "    2  220   150   268\n",
      "    3   11    23   183\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.74      0.72       744\n",
      "          2       0.56      0.24      0.33       638\n",
      "          3       0.34      0.84      0.48       217\n",
      "\n",
      "avg / total       0.60      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.8029806885855979\n",
      "3.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   219   295\n",
      "    2  853   424   921\n",
      "    3  144   150   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.19      0.28      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.44      4898\n",
      "\n",
      "RMSE:\n",
      "0.8922102889304382\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554    96    94\n",
      "    2  221   146   271\n",
      "    3   11    23   183\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.55      0.23      0.32       638\n",
      "          3       0.33      0.84      0.48       217\n",
      "\n",
      "avg / total       0.59      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.8029806885855979\n",
      "3.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   218   296\n",
      "    2  860   419   919\n",
      "    3  145   150   765\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.19      0.28      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8935822174018682\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  554    92    98\n",
      "    2  222   145   271\n",
      "    3   11    23   183\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.56      0.23      0.32       638\n",
      "          3       0.33      0.84      0.48       217\n",
      "\n",
      "avg / total       0.60      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.8080272690585473\n",
      "3.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1128   218   294\n",
      "    2  865   412   921\n",
      "    3  145   149   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.19      0.28      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8933537089676493\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  553    94    97\n",
      "    2  224   144   270\n",
      "    3   11    22   184\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.74      0.72       744\n",
      "          2       0.55      0.23      0.32       638\n",
      "          3       0.33      0.85      0.48       217\n",
      "\n",
      "avg / total       0.59      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.8072529255466513\n",
      "3.4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   216   293\n",
      "    2  869   407   922\n",
      "    3  146   148   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.19      0.27      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8935822174018682\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  557    92    95\n",
      "    2  224   143   271\n",
      "    3   11    23   183\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.75      0.73       744\n",
      "          2       0.55      0.22      0.32       638\n",
      "          3       0.33      0.84      0.48       217\n",
      "\n",
      "avg / total       0.59      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.8041480950977132\n",
      "3.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   217   292\n",
      "    2  872   406   920\n",
      "    3  146   148   766\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.39      0.72      0.50      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8933537089676493\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  558    92    94\n",
      "    2  229   134   275\n",
      "    3   11    24   182\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.75      0.72       744\n",
      "          2       0.54      0.21      0.30       638\n",
      "          3       0.33      0.84      0.47       217\n",
      "\n",
      "avg / total       0.58      0.55      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.8064778385455118\n",
      "3.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1136   211   293\n",
      "    2  870   405   923\n",
      "    3  146   145   769\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8928965166608546\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559    91    94\n",
      "    2  233   128   277\n",
      "    3   12    24   181\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.75      0.72       744\n",
      "          2       0.53      0.20      0.29       638\n",
      "          3       0.33      0.83      0.47       217\n",
      "\n",
      "avg / total       0.58      0.54      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.8099598890616007\n",
      "3.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   209   292\n",
      "    2  874   402   922\n",
      "    3  147   142   771\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.69      0.60      1640\n",
      "          2       0.53      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8926678326984253\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565    85    94\n",
      "    2  233   125   280\n",
      "    3   12    25   180\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.76      0.73       744\n",
      "          2       0.53      0.20      0.29       638\n",
      "          3       0.32      0.83      0.47       217\n",
      "\n",
      "avg / total       0.58      0.54      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.8091873949525498\n",
      "3.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   206   292\n",
      "    2  876   400   922\n",
      "    3  148   139   773\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8926678326984253\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566    82    96\n",
      "    2  236   123   279\n",
      "    3   12    27   178\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.76      0.73       744\n",
      "          2       0.53      0.19      0.28       638\n",
      "          3       0.32      0.82      0.46       217\n",
      "\n",
      "avg / total       0.58      0.54      0.51      1599\n",
      "\n",
      "RMSE:\n",
      "0.8126578357302251\n",
      "3.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   206   292\n",
      "    2  879   397   922\n",
      "    3  148   137   775\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8927821820017444\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    77    98\n",
      "    2  239   120   279\n",
      "    3   12    26   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.73       744\n",
      "          2       0.54      0.19      0.28       638\n",
      "          3       0.32      0.82      0.46       217\n",
      "\n",
      "avg / total       0.58      0.54      0.51      1599\n",
      "\n",
      "RMSE:\n",
      "0.8145794696161941\n",
      "4.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   200   291\n",
      "    2  884   393   921\n",
      "    3  149   135   776\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8923246968669128\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  570    74   100\n",
      "    2  241   112   285\n",
      "    3   13    26   178\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.53      0.18      0.26       638\n",
      "          3       0.32      0.82      0.46       217\n",
      "\n",
      "avg / total       0.58      0.54      0.51      1599\n",
      "\n",
      "RMSE:\n",
      "0.8210793853813323\n",
      "4.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1151   196   293\n",
      "    2  888   389   921\n",
      "    3  152   132   776\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8942673923657237\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574    71    99\n",
      "    2  244   110   284\n",
      "    3   14    26   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.53      0.17      0.26       638\n",
      "          3       0.32      0.82      0.46       217\n",
      "\n",
      "avg / total       0.58      0.54      0.50      1599\n",
      "\n",
      "RMSE:\n",
      "0.8206984624263001\n",
      "4.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   195   293\n",
      "    2  890   387   921\n",
      "    3  152   131   777\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.18      0.27      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8942673923657237\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576    66   102\n",
      "    2  247   108   283\n",
      "    3   16    24   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.55      0.17      0.26       638\n",
      "          3       0.31      0.82      0.45       217\n",
      "\n",
      "avg / total       0.58      0.54      0.50      1599\n",
      "\n",
      "RMSE:\n",
      "0.8263938705413374\n",
      "4.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   190   294\n",
      "    2  889   384   925\n",
      "    3  152   131   777\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.70      0.60      1640\n",
      "          2       0.54      0.17      0.26      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8944956673898288\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577    63   104\n",
      "    2  249   104   285\n",
      "    3   16    23   178\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.78      0.73       744\n",
      "          2       0.55      0.16      0.25       638\n",
      "          3       0.31      0.82      0.45       217\n",
      "\n",
      "avg / total       0.58      0.54      0.50      1599\n",
      "\n",
      "RMSE:\n",
      "0.8294154304223181\n",
      "4.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1158   188   294\n",
      "    2  898   371   929\n",
      "    3  152   129   779\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.54      0.17      0.26      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8955221849104592\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576    62   106\n",
      "    2  253    98   287\n",
      "    3   16    25   176\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.53      0.15      0.24       638\n",
      "          3       0.31      0.81      0.45       217\n",
      "\n",
      "avg / total       0.57      0.53      0.49      1599\n",
      "\n",
      "RMSE:\n",
      "0.8350513871984399\n",
      "4.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   183   294\n",
      "    2  903   365   930\n",
      "    3  153   128   779\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.54      0.17      0.25      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.43      4898\n",
      "\n",
      "RMSE:\n",
      "0.8959780374138478\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576    60   108\n",
      "    2  256    92   290\n",
      "    3   16    24   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.52      0.14      0.23       638\n",
      "          3       0.31      0.82      0.45       217\n",
      "\n",
      "avg / total       0.57      0.53      0.49      1599\n",
      "\n",
      "RMSE:\n",
      "0.8391603653797438\n",
      "4.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1165   181   294\n",
      "    2  912   356   930\n",
      "    3  154   127   779\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.54      0.16      0.25      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8971166552800646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574    58   112\n",
      "    2  258    89   291\n",
      "    3   16    22   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.53      0.14      0.22       638\n",
      "          3       0.31      0.82      0.45       217\n",
      "\n",
      "avg / total       0.57      0.53      0.48      1599\n",
      "\n",
      "RMSE:\n",
      "0.8447313074958598\n",
      "4.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1166   181   293\n",
      "    2  917   351   930\n",
      "    3  155   126   779\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.53      0.16      0.25      2198\n",
      "          3       0.39      0.73      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8975716979952398\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573    56   115\n",
      "    2  258    88   292\n",
      "    3   16    22   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.53      0.14      0.22       638\n",
      "          3       0.31      0.82      0.45       217\n",
      "\n",
      "avg / total       0.57      0.53      0.48      1599\n",
      "\n",
      "RMSE:\n",
      "0.8487934268276889\n",
      "4.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1169   176   295\n",
      "    2  920   347   931\n",
      "    3  156   124   780\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.54      0.16      0.24      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8985947015922615\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573    58   113\n",
      "    2  260    86   292\n",
      "    3   16    22   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.77      0.72       744\n",
      "          2       0.52      0.13      0.21       638\n",
      "          3       0.31      0.82      0.45       217\n",
      "\n",
      "avg / total       0.56      0.52      0.48      1599\n",
      "\n",
      "RMSE:\n",
      "0.8473185457363234\n",
      "4.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1169   174   297\n",
      "    2  925   342   931\n",
      "    3  154   124   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.71      0.60      1640\n",
      "          2       0.53      0.16      0.24      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.898935444081254\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  572    59   113\n",
      "    2  262    82   294\n",
      "    3   17    21   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.77      0.72       744\n",
      "          2       0.51      0.13      0.21       638\n",
      "          3       0.31      0.82      0.45       217\n",
      "\n",
      "avg / total       0.56      0.52      0.48      1599\n",
      "\n",
      "RMSE:\n",
      "0.8502657495766041\n",
      "5.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1173   172   295\n",
      "    2  930   335   933\n",
      "    3  156   122   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.53      0.15      0.24      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8992760574603537\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573    57   114\n",
      "    2  262    81   295\n",
      "    3   18    20   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.77      0.72       744\n",
      "          2       0.51      0.13      0.20       638\n",
      "          3       0.30      0.82      0.44       217\n",
      "\n",
      "avg / total       0.56      0.52      0.48      1599\n",
      "\n",
      "RMSE:\n",
      "0.852469465798526\n",
      "5.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1177   169   294\n",
      "    2  933   332   933\n",
      "    3  160   117   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.54      0.15      0.24      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.9000703207408192\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574    56   114\n",
      "    2  262    82   294\n",
      "    3   19    20   178\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.77      0.72       744\n",
      "          2       0.52      0.13      0.21       638\n",
      "          3       0.30      0.82      0.44       217\n",
      "\n",
      "avg / total       0.56      0.52      0.48      1599\n",
      "\n",
      "RMSE:\n",
      "0.8532027730014776\n",
      "5.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   164   292\n",
      "    2  940   323   935\n",
      "    3  162   116   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.54      0.15      0.23      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.9004105048111982\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568    57   119\n",
      "    2  260    82   296\n",
      "    3   20    22   175\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.76      0.71       744\n",
      "          2       0.51      0.13      0.21       638\n",
      "          3       0.30      0.81      0.43       217\n",
      "\n",
      "avg / total       0.56      0.52      0.47      1599\n",
      "\n",
      "RMSE:\n",
      "0.8630414389404082\n",
      "5.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   167   289\n",
      "    2  942   323   933\n",
      "    3  163   115   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.53      0.15      0.23      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.50      0.47      0.42      4898\n",
      "\n",
      "RMSE:\n",
      "0.8997300080483062\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567    60   117\n",
      "    2  260    80   298\n",
      "    3   21    23   173\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.76      0.71       744\n",
      "          2       0.49      0.13      0.20       638\n",
      "          3       0.29      0.80      0.43       217\n",
      "\n",
      "avg / total       0.55      0.51      0.47      1599\n",
      "\n",
      "RMSE:\n",
      "0.8637657709511977\n",
      "5.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1186   167   287\n",
      "    2  947   316   935\n",
      "    3  165   114   781\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.52      0.72      0.60      1640\n",
      "          2       0.53      0.14      0.23      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9004105048111982\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567    62   115\n",
      "    2  261    81   296\n",
      "    3   22    24   171\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.76      0.71       744\n",
      "          2       0.49      0.13      0.20       638\n",
      "          3       0.29      0.79      0.43       217\n",
      "\n",
      "avg / total       0.54      0.51      0.47      1599\n",
      "\n",
      "RMSE:\n",
      "0.8630414389404082\n",
      "5.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   168   288\n",
      "    2  951   311   936\n",
      "    3  166   111   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.14      0.22      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9016567483208721\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564    61   119\n",
      "    2  264    76   298\n",
      "    3   23    23   171\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.76      0.71       744\n",
      "          2       0.47      0.12      0.19       638\n",
      "          3       0.29      0.79      0.42       217\n",
      "\n",
      "avg / total       0.54      0.51      0.46      1599\n",
      "\n",
      "RMSE:\n",
      "0.8713349042257381\n",
      "5.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1183   170   287\n",
      "    2  953   312   933\n",
      "    3  166   110   784\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.53      0.14      0.22      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.47      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9012037682629831\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565    58   121\n",
      "    2  264    74   300\n",
      "    3   23    22   172\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.76      0.71       744\n",
      "          2       0.48      0.12      0.19       638\n",
      "          3       0.29      0.79      0.42       217\n",
      "\n",
      "avg / total       0.54      0.51      0.46      1599\n",
      "\n",
      "RMSE:\n",
      "0.8734854667009843\n",
      "5.7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1186   167   287\n",
      "    2  960   303   935\n",
      "    3  169   110   781\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.52      0.14      0.22      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9032403895456933\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568    54   122\n",
      "    2  268    70   300\n",
      "    3   24    20   173\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.76      0.71       744\n",
      "          2       0.49      0.11      0.18       638\n",
      "          3       0.29      0.80      0.43       217\n",
      "\n",
      "avg / total       0.54      0.51      0.46      1599\n",
      "\n",
      "RMSE:\n",
      "0.8756307473779094\n",
      "5.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   168   288\n",
      "    2  957   305   936\n",
      "    3  169   109   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.72      0.60      1640\n",
      "          2       0.52      0.14      0.22      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9034663974034893\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    51   124\n",
      "    2  271    63   304\n",
      "    3   24    19   174\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.76      0.71       744\n",
      "          2       0.47      0.10      0.16       638\n",
      "          3       0.29      0.80      0.42       217\n",
      "\n",
      "avg / total       0.53      0.50      0.45      1599\n",
      "\n",
      "RMSE:\n",
      "0.8795501721424551\n",
      "5.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1192   159   289\n",
      "    2  968   295   935\n",
      "    3  168   108   784\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.52      0.13      0.21      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.41      4898\n",
      "\n",
      "RMSE:\n",
      "0.9034663974034893\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    50   125\n",
      "    2  274    58   306\n",
      "    3   24    17   176\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.76      0.71       744\n",
      "          2       0.46      0.09      0.15       638\n",
      "          3       0.29      0.81      0.43       217\n",
      "\n",
      "avg / total       0.53      0.50      0.45      1599\n",
      "\n",
      "RMSE:\n",
      "0.8816806964721311\n",
      "6.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1194   157   289\n",
      "    2  973   284   941\n",
      "    3  170   108   782\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.52      0.13      0.21      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.905385186341815\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  572    44   128\n",
      "    2  279    50   309\n",
      "    3   24    16   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.77      0.71       744\n",
      "          2       0.45      0.08      0.13       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.52      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8862792628920048\n",
      "6.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1198   153   289\n",
      "    2  979   277   942\n",
      "    3  170   107   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.52      0.13      0.20      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9056106589356083\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573    43   128\n",
      "    2  280    49   309\n",
      "    3   25    15   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.77      0.71       744\n",
      "          2       0.46      0.08      0.13       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.53      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8873370861404786\n",
      "6.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1198   154   288\n",
      "    2  984   272   942\n",
      "    3  170   107   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9058360754067872\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  572    44   128\n",
      "    2  276    53   309\n",
      "    3   28    12   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.77      0.71       744\n",
      "          2       0.49      0.08      0.14       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.54      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8894489584321491\n",
      "6.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1202   150   288\n",
      "    2  989   267   942\n",
      "    3  170   107   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.73      0.60      1640\n",
      "          2       0.51      0.12      0.20      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9059487626094881\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571    45   128\n",
      "    2  277    52   309\n",
      "    3   28    12   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.77      0.70       744\n",
      "          2       0.48      0.08      0.14       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.53      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8901518024441795\n",
      "6.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1206   146   288\n",
      "    2  991   263   944\n",
      "    3  173   104   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.51      0.12      0.19      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9069623173877128\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    47   128\n",
      "    2  280    49   309\n",
      "    3   28    12   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.45      0.08      0.13       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.52      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.891906489348008\n",
      "6.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1210   142   288\n",
      "    2  994   259   945\n",
      "    3  176   101   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.52      0.12      0.19      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.40      4898\n",
      "\n",
      "RMSE:\n",
      "0.9079747407548945\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568    48   128\n",
      "    2  279    49   310\n",
      "    3   28    12   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.45      0.08      0.13       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.52      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8922570126428715\n",
      "6.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1212   138   290\n",
      "    2  999   250   949\n",
      "    3  177   100   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.51      0.11      0.19      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9097718226531251\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568    48   128\n",
      "    2  279    49   310\n",
      "    3   28    12   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.45      0.08      0.13       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.52      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8922570126428715\n",
      "6.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1215   135   290\n",
      "    2 1005   243   950\n",
      "    3  178    99   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.51      0.11      0.18      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9105569307026513\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    47   128\n",
      "    2  279    49   310\n",
      "    3   28    12   177\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.45      0.08      0.13       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.52      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.891906489348008\n",
      "6.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1214   134   292\n",
      "    2 1008   239   951\n",
      "    3  181    96   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.51      0.11      0.18      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9127963756262796\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    47   128\n",
      "    2  278    50   310\n",
      "    3   28    11   178\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.46      0.08      0.13       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.53      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8912050291613606\n",
      "6.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1218   131   291\n",
      "    2 1007   239   952\n",
      "    3  184    93   783\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.51      0.74      0.60      1640\n",
      "          2       0.52      0.11      0.18      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9130200180100412\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    43   132\n",
      "    2  278    47   313\n",
      "    3   28    10   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.47      0.07      0.13       638\n",
      "          3       0.29      0.82      0.43       217\n",
      "\n",
      "avg / total       0.53      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8961037195395452\n",
      "7.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1222   124   294\n",
      "    2 1013   233   952\n",
      "    3  186    90   784\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.52      0.11      0.18      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9148071888281853\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    40   135\n",
      "    2  278    47   313\n",
      "    3   28    10   179\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.48      0.07      0.13       638\n",
      "          3       0.29      0.82      0.42       217\n",
      "\n",
      "avg / total       0.53      0.50      0.44      1599\n",
      "\n",
      "RMSE:\n",
      "0.8992387858607122\n",
      "7.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1223   124   293\n",
      "    2 1013   231   954\n",
      "    3  188    88   784\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.52      0.11      0.17      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.91525343626391\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    34   141\n",
      "    2  278    44   316\n",
      "    3   28     8   181\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.51      0.07      0.12       638\n",
      "          3       0.28      0.83      0.42       217\n",
      "\n",
      "avg / total       0.55      0.50      0.43      1599\n",
      "\n",
      "RMSE:\n",
      "0.9058216273156766\n",
      "7.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1227   120   293\n",
      "    2 1019   224   955\n",
      "    3  190    85   785\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.52      0.10      0.17      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.39      4898\n",
      "\n",
      "RMSE:\n",
      "0.9161452790443395\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    34   141\n",
      "    2  278    44   316\n",
      "    3   28     8   181\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.51      0.07      0.12       638\n",
      "          3       0.28      0.83      0.42       217\n",
      "\n",
      "avg / total       0.55      0.50      0.43      1599\n",
      "\n",
      "RMSE:\n",
      "0.9058216273156766\n",
      "7.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1227   120   293\n",
      "    2 1026   214   958\n",
      "    3  195    77   788\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.52      0.10      0.16      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.46      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9185933820530462\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    26   149\n",
      "    2  278    39   321\n",
      "    3   28     3   186\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.57      0.06      0.11       638\n",
      "          3       0.28      0.86      0.43       217\n",
      "\n",
      "avg / total       0.57      0.50      0.43      1599\n",
      "\n",
      "RMSE:\n",
      "0.9140690353446286\n",
      "7.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1224   123   293\n",
      "    2 1036   204   958\n",
      "    3  196    76   788\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.51      0.09      0.16      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9203697305954412\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    26   149\n",
      "    2  278    39   321\n",
      "    3   28     3   186\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.57      0.06      0.11       638\n",
      "          3       0.28      0.86      0.43       217\n",
      "\n",
      "avg / total       0.57      0.50      0.43      1599\n",
      "\n",
      "RMSE:\n",
      "0.9140690353446286\n",
      "7.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1225   121   294\n",
      "    2 1042   196   960\n",
      "    3  196    75   789\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.09      0.15      2198\n",
      "          3       0.39      0.74      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9213674216532473\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569    22   153\n",
      "    2  278    30   330\n",
      "    3   28     3   186\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.76      0.70       744\n",
      "          2       0.55      0.05      0.09       638\n",
      "          3       0.28      0.86      0.42       217\n",
      "\n",
      "avg / total       0.56      0.49      0.42      1599\n",
      "\n",
      "RMSE:\n",
      "0.9212249506125089\n",
      "7.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1225   122   293\n",
      "    2 1044   195   959\n",
      "    3  198    72   790\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.09      0.15      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9216997453508536\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571    13   160\n",
      "    2  283    20   335\n",
      "    3   28     1   188\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.77      0.70       744\n",
      "          2       0.59      0.03      0.06       638\n",
      "          3       0.28      0.87      0.42       217\n",
      "\n",
      "avg / total       0.57      0.49      0.41      1599\n",
      "\n",
      "RMSE:\n",
      "0.9303445399968437\n",
      "7.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1226   119   295\n",
      "    2 1047   188   963\n",
      "    3  199    70   791\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.09      0.15      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9232490076322399\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571    13   160\n",
      "    2  283    20   335\n",
      "    3   28     1   188\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.65      0.77      0.70       744\n",
      "          2       0.59      0.03      0.06       638\n",
      "          3       0.28      0.87      0.42       217\n",
      "\n",
      "avg / total       0.57      0.49      0.41      1599\n",
      "\n",
      "RMSE:\n",
      "0.9303445399968437\n",
      "7.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1228   118   294\n",
      "    2 1048   188   962\n",
      "    3  198    71   791\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.09      0.15      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9223640335418442\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571    13   160\n",
      "    2  290    13   335\n",
      "    3   28     1   188\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.77      0.70       744\n",
      "          2       0.48      0.02      0.04       638\n",
      "          3       0.28      0.87      0.42       217\n",
      "\n",
      "avg / total       0.53      0.48      0.40      1599\n",
      "\n",
      "RMSE:\n",
      "0.9326943224803032\n",
      "7.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1229   116   295\n",
      "    2 1049   186   963\n",
      "    3  201    67   792\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.14      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.38      4898\n",
      "\n",
      "RMSE:\n",
      "0.9236911767225471\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571    13   160\n",
      "    2  290    13   335\n",
      "    3   28     1   188\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.77      0.70       744\n",
      "          2       0.48      0.02      0.04       638\n",
      "          3       0.28      0.87      0.42       217\n",
      "\n",
      "avg / total       0.53      0.48      0.40      1599\n",
      "\n",
      "RMSE:\n",
      "0.9326943224803032\n",
      "8.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1229   118   293\n",
      "    2 1052   184   962\n",
      "    3  201    65   794\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.14      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9230278436555053\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  578     6   160\n",
      "    2  295     8   335\n",
      "    3   28     1   188\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.78      0.70       744\n",
      "          2       0.53      0.01      0.02       638\n",
      "          3       0.28      0.87      0.42       217\n",
      "\n",
      "avg / total       0.55      0.48      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "0.9320235605650777\n",
      "8.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1234   112   294\n",
      "    2 1054   182   962\n",
      "    3  203    63   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.75      0.60      1640\n",
      "          2       0.51      0.08      0.14      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9236911767225471\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  578    19   147\n",
      "    2  295    47   296\n",
      "    3   28    23   166\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.78      0.70       744\n",
      "          2       0.53      0.07      0.13       638\n",
      "          3       0.27      0.76      0.40       217\n",
      "\n",
      "avg / total       0.55      0.49      0.43      1599\n",
      "\n",
      "RMSE:\n",
      "0.9130421834548391\n",
      "8.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1233   113   294\n",
      "    2 1056   178   964\n",
      "    3  203    62   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.14      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9241331342486598\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  579    33   132\n",
      "    2  296    81   261\n",
      "    3   28    43   146\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.78      0.70       744\n",
      "          2       0.52      0.13      0.20       638\n",
      "          3       0.27      0.67      0.39       217\n",
      "\n",
      "avg / total       0.54      0.50      0.46      1599\n",
      "\n",
      "RMSE:\n",
      "0.8922570126428715\n",
      "8.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1234   111   295\n",
      "    2 1063   170   965\n",
      "    3  203    62   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9252371044598088\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581    74    89\n",
      "    2  299   174   165\n",
      "    3   28   102    87\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.78      0.70       744\n",
      "          2       0.50      0.27      0.35       638\n",
      "          3       0.26      0.40      0.31       217\n",
      "\n",
      "avg / total       0.53      0.53      0.51      1599\n",
      "\n",
      "RMSE:\n",
      "0.8324260226452472\n",
      "8.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1237   108   295\n",
      "    2 1063   168   967\n",
      "    3  205    60   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.925788595898454\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581    88    75\n",
      "    2  299   202   137\n",
      "    3   28   121    68\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.78      0.70       744\n",
      "          2       0.49      0.32      0.39       638\n",
      "          3       0.24      0.31      0.27       217\n",
      "\n",
      "avg / total       0.53      0.53      0.52      1599\n",
      "\n",
      "RMSE:\n",
      "0.8130425258515245\n",
      "8.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1237   110   293\n",
      "    2 1062   167   969\n",
      "    3  205    58   797\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9250164158211395\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  582   100    62\n",
      "    2  301   233   104\n",
      "    3   29   138    50\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.78      0.70       744\n",
      "          2       0.49      0.37      0.42       638\n",
      "          3       0.23      0.23      0.23       217\n",
      "\n",
      "avg / total       0.53      0.54      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.7935796150219343\n",
      "8.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1237   110   293\n",
      "    2 1064   169   965\n",
      "    3  205    61   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9251267667211229\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  582   122    40\n",
      "    2  301   265    72\n",
      "    3   29   155    33\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.78      0.70       744\n",
      "          2       0.49      0.42      0.45       638\n",
      "          3       0.23      0.15      0.18       217\n",
      "\n",
      "avg / total       0.52      0.55      0.53      1599\n",
      "\n",
      "RMSE:\n",
      "0.7609940505454714\n",
      "8.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1238   108   294\n",
      "    2 1065   169   964\n",
      "    3  205    61   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.50      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9253474290419048\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610    94    40\n",
      "    2  377   189    72\n",
      "    3   71   113    33\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.82      0.68       744\n",
      "          2       0.48      0.30      0.37       638\n",
      "          3       0.23      0.15      0.18       217\n",
      "\n",
      "avg / total       0.49      0.52      0.49      1599\n",
      "\n",
      "RMSE:\n",
      "0.8294154304223181\n",
      "8.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1238   109   293\n",
      "    2 1065   166   967\n",
      "    3  205    61   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.49      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9253474290419048\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  638   106     0\n",
      "    2  447   191     0\n",
      "    3  109   108     0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.86      0.66       744\n",
      "          2       0.47      0.30      0.37       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.44      0.52      0.45      1599\n",
      "\n",
      "RMSE:\n",
      "0.8282836371767579\n",
      "8.9\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1237   112   291\n",
      "    2 1065   165   968\n",
      "    3  206    60   794\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.49      0.08      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9252371044598088\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  638   106     0\n",
      "    2  447   191     0\n",
      "    3  109   108     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.53      0.86      0.66       744\n",
      "          2       0.47      0.30      0.37       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.44      0.52      0.45      1599\n",
      "\n",
      "RMSE:\n",
      "0.8282836371767579\n",
      "9.0\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1238   112   290\n",
      "    2 1065   164   969\n",
      "    3  208    57   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.49      0.07      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9254577404721163\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  665    79     0\n",
      "    2  508   130     0\n",
      "    3  146    71     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.50      0.89      0.64       744\n",
      "          2       0.46      0.20      0.28       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.42      0.50      0.41      1599\n",
      "\n",
      "RMSE:\n",
      "0.8813259667468609\n",
      "9.1\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1238   114   288\n",
      "    2 1069   162   967\n",
      "    3  212    53   795\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.75      0.60      1640\n",
      "          2       0.49      0.07      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9263397590096685\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  682    62     0\n",
      "    2  534   104     0\n",
      "    3  167    50     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.92      0.64       744\n",
      "          2       0.48      0.16      0.24       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.42      0.49      0.40      1599\n",
      "\n",
      "RMSE:\n",
      "0.9065117772270844\n",
      "9.2\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1241   109   290\n",
      "    2 1070   161   967\n",
      "    3  210    54   796\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.76      0.60      1640\n",
      "          2       0.50      0.07      0.13      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9260091005093928\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  703    41     0\n",
      "    2  568    70     0\n",
      "    3  184    33     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.48      0.94      0.64       744\n",
      "          2       0.49      0.11      0.18       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.42      0.48      0.37      1599\n",
      "\n",
      "RMSE:\n",
      "0.9283257067894753\n",
      "9.3\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1244   106   290\n",
      "    2 1082   154   962\n",
      "    3  216    46   798\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.76      0.59      1640\n",
      "          2       0.50      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.47      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9282112655705348\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  744     0     0\n",
      "    2  638     0     0\n",
      "    3  217     0     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      1.00      0.64       744\n",
      "          2       0.00      0.00      0.00       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.22      0.47      0.30      1599\n",
      "\n",
      "RMSE:\n",
      "0.970483719160565\n",
      "9.4\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1257    92   291\n",
      "    2 1092   145   961\n",
      "    3  221    42   797\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.52      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.48      0.45      0.36      4898\n",
      "\n",
      "RMSE:\n",
      "0.9298594668074489\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  744     0     0\n",
      "    2  638     0     0\n",
      "    3  217     0     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      1.00      0.64       744\n",
      "          2       0.00      0.00      0.00       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.22      0.47      0.30      1599\n",
      "\n",
      "RMSE:\n",
      "0.970483719160565\n",
      "9.5\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    88   293\n",
      "    2 1092   150   956\n",
      "    3  222    39   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9298594668074489\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  744     0     0\n",
      "    2  638     0     0\n",
      "    3  217     0     0\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      1.00      0.64       744\n",
      "          2       0.00      0.00      0.00       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.22      0.47      0.30      1599\n",
      "\n",
      "RMSE:\n",
      "0.970483719160565\n",
      "9.6\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    88   293\n",
      "    2 1092   150   956\n",
      "    3  222    39   799\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9298594668074489\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  744     0     0\n",
      "    2  638     0     0\n",
      "    3  217     0     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      1.00      0.64       744\n",
      "          2       0.00      0.00      0.00       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.22      0.47      0.30      1599\n",
      "\n",
      "RMSE:\n",
      "0.970483719160565\n",
      "9.7\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    86   295\n",
      "    2 1092   147   959\n",
      "    3  222    38   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.36      4898\n",
      "\n",
      "RMSE:\n",
      "0.9307373140332179\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  744     0     0\n",
      "    2  638     0     0\n",
      "    3  217     0     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      1.00      0.64       744\n",
      "          2       0.00      0.00      0.00       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.22      0.47      0.30      1599\n",
      "\n",
      "RMSE:\n",
      "0.970483719160565\n",
      "9.8\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    89   292\n",
      "    2 1092   150   956\n",
      "    3  222    38   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.51      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9294202322686254\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  744     0     0\n",
      "    2  638     0     0\n",
      "    3  217     0     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      1.00      0.64       744\n",
      "          2       0.00      0.00      0.00       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.22      0.47      0.30      1599\n",
      "\n",
      "RMSE:\n",
      "0.970483719160565\n",
      "9.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1259    91   290\n",
      "    2 1092   151   955\n",
      "    3  222    38   800\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.49      0.77      0.60      1640\n",
      "          2       0.54      0.07      0.12      2198\n",
      "          3       0.39      0.75      0.52      1060\n",
      "\n",
      "avg / total       0.49      0.45      0.37      4898\n",
      "\n",
      "RMSE:\n",
      "0.9286510719281068\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  744     0     0\n",
      "    2  638     0     0\n",
      "    3  217     0     0\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.47      1.00      0.64       744\n",
      "          2       0.00      0.00      0.00       638\n",
      "          3       0.00      0.00      0.00       217\n",
      "\n",
      "avg / total       0.22      0.47      0.30      1599\n",
      "\n",
      "RMSE:\n",
      "0.970483719160565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\D060379\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "for t in range (0,10000,100):\n",
    "    t = t/1000\n",
    "    print(t)\n",
    "    run_kncs_report(white_norm_input.values,white_targetclass,t)\n",
    "    run_kncs_report(red_norm_input.values,red_targetclass,t)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "0.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.4\n",
      "#____________________red STD normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "1.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.0\n",
      "#____________________red STD normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "2.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "3.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "4.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "5.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "6.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "7.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "8.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.0\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.1\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.2\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.3\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.4\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.5\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.6\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.7\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.8\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n",
      "9.9\n",
      "#____________________red STD normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  541   139    64\n",
      "    2  219   223   196\n",
      "    3   11    42   164\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.55      0.35      0.43       638\n",
      "          3       0.39      0.76      0.51       217\n",
      "\n",
      "avg / total       0.60      0.58      0.57      1599\n",
      "\n",
      "RMSE:\n",
      "0.7485654406174548\n",
      "#____________________red MinMax normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   109    74\n",
      "    2  241   200   197\n",
      "    3   11    44   162\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.57      0.31      0.40       638\n",
      "          3       0.37      0.75      0.50       217\n",
      "\n",
      "avg / total       0.60      0.58      0.56      1599\n",
      "\n",
      "RMSE:\n",
      "0.763045804203175\n",
      "#____________________red log normed____________________#\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  427    84   233\n",
      "    2  290    96   252\n",
      "    3   66    25   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.55      0.57      0.56       744\n",
      "          2       0.47      0.15      0.23       638\n",
      "          3       0.21      0.58      0.30       217\n",
      "\n",
      "avg / total       0.47      0.41      0.39      1599\n",
      "\n",
      "RMSE:\n",
      "1.0747543605795422\n"
     ]
    }
   ],
   "source": [
    "for t in range (0,10000,100):\n",
    "    t = t/1000\n",
    "    print(t)\n",
    "    print(\"#____________________red STD normed____________________#\")\n",
    "    run_kncs_report(red_norm.values, red_targetclass)\n",
    "    print(\"#____________________red MinMax normed____________________#\")\n",
    "    run_kncs_report(mm_red_norm.values, red_targetclass)\n",
    "    print(\"#____________________red log normed____________________#\")\n",
    "    run_kncs_report(log_red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_knnw_report(inputs, targets):\n",
    "    print(\"_______________________________________________________________________________________________\")\n",
    "    print(\"KNN with inverse distance as weight:\")\n",
    "    for n_neighbour in range(1,31):\n",
    "        print(str(n_neighbour) + \" neighbours:\")\n",
    "        knn_estimator = KNeighborsClassifier(n_neighbour,weights='distance')\n",
    "        print(str(n_neighbour)+ \" neighbours//\")\n",
    "        predicted = cross_val_predict(knn_estimator,inputs,targets,cv=cv)\n",
    "        print(confusion_matrix_report(targets,predicted))\n",
    "        print(classification_report(targets,predicted))\n",
    "        try:\n",
    "            print(\"RMSE:\")\n",
    "            print(root_mean_squared_error(targets,predicted))\n",
    "        except(Error):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red STD normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   155    13\n",
      "    2  150   407    81\n",
      "    3   17    70   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.77      0.77       744\n",
      "          2       0.64      0.64      0.64       638\n",
      "          3       0.58      0.60      0.59       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.6001875879364265\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   155    13\n",
      "    2  151   406    81\n",
      "    3   17    70   130\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.77      0.77       744\n",
      "          2       0.64      0.64      0.64       638\n",
      "          3       0.58      0.60      0.59       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.6007083581757781\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  586   142    16\n",
      "    2  138   421    79\n",
      "    3   19    77   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.56      0.56      0.56       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.6001875879364265\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  587   145    12\n",
      "    2  145   421    72\n",
      "    3   18    75   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.79      0.79       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.60      0.57      0.58       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5902056541548656\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   129    10\n",
      "    2  142   432    64\n",
      "    3   16    77   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.68      0.68      0.68       638\n",
      "          3       0.63      0.57      0.60       217\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.568068383696318\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  604   129    11\n",
      "    2  138   438    62\n",
      "    3   20    73   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.68      0.69      0.69       638\n",
      "          3       0.63      0.57      0.60       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5735465083568029\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   120    11\n",
      "    2  141   440    57\n",
      "    3   20    76   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.69      0.69      0.69       638\n",
      "          3       0.64      0.56      0.60       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5691682267080039\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  611   124     9\n",
      "    2  139   442    57\n",
      "    3   15    79   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.69      0.69       638\n",
      "          3       0.65      0.57      0.61       217\n",
      "\n",
      "avg / total       0.73      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5563887852034651\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  622   113     9\n",
      "    2  142   441    55\n",
      "    3   15    81   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.84      0.82       744\n",
      "          2       0.69      0.69      0.69       638\n",
      "          3       0.65      0.56      0.60       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5518743999732558\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  614   124     6\n",
      "    2  140   442    56\n",
      "    3   13    83   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.83      0.81       744\n",
      "          2       0.68      0.69      0.69       638\n",
      "          3       0.66      0.56      0.60       217\n",
      "\n",
      "avg / total       0.73      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5473227808080846\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  618   119     7\n",
      "    2  144   441    53\n",
      "    3   13    85   119\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.83      0.81       744\n",
      "          2       0.68      0.69      0.69       638\n",
      "          3       0.66      0.55      0.60       217\n",
      "\n",
      "avg / total       0.73      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5484642268462742\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   125     9\n",
      "    2  142   447    49\n",
      "    3   14    82   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.68      0.56      0.61       217\n",
      "\n",
      "avg / total       0.73      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5535716086954976\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  616   121     7\n",
      "    2  139   451    48\n",
      "    3   15    80   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.83      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.69      0.56      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5456061342980069\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  616   120     8\n",
      "    2  138   447    53\n",
      "    3   17    80   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.83      0.81       744\n",
      "          2       0.69      0.70      0.70       638\n",
      "          3       0.66      0.55      0.60       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5541361897792044\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  619   115    10\n",
      "    2  140   448    50\n",
      "    3   14    80   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.83      0.82       744\n",
      "          2       0.70      0.70      0.70       638\n",
      "          3       0.67      0.57      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5484642268462742\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  616   121     7\n",
      "    2  147   443    48\n",
      "    3   15    81   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.83      0.81       744\n",
      "          2       0.69      0.69      0.69       638\n",
      "          3       0.69      0.56      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5507400217954517\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  614   124     6\n",
      "    2  144   447    47\n",
      "    3   13    81   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.83      0.81       744\n",
      "          2       0.69      0.70      0.69       638\n",
      "          3       0.70      0.57      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5433088351080272\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  607   131     6\n",
      "    2  148   442    48\n",
      "    3   15    78   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.80       744\n",
      "          2       0.68      0.69      0.69       638\n",
      "          3       0.70      0.57      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5530064512141136\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   134     4\n",
      "    2  144   448    46\n",
      "    3   14    79   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.71      0.57      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   129     3\n",
      "    2  139   454    45\n",
      "    3   16    78   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.72      0.57      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.540423478357459\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   130     5\n",
      "    2  143   453    42\n",
      "    3   17    79   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.71      0.70       638\n",
      "          3       0.72      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5490340599629268\n",
      "22 neighbours:\n",
      "22 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  611   129     4\n",
      "    2  154   441    43\n",
      "    3   15    81   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.68      0.69      0.68       638\n",
      "          3       0.72      0.56      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5496033022723462\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  616   123     5\n",
      "    2  151   447    40\n",
      "    3   15    81   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.83      0.81       744\n",
      "          2       0.69      0.70      0.69       638\n",
      "          3       0.73      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  614   125     5\n",
      "    2  153   443    42\n",
      "    3   15    81   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.83      0.80       744\n",
      "          2       0.68      0.69      0.69       638\n",
      "          3       0.72      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5484642268462742\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   126     5\n",
      "    2  148   445    45\n",
      "    3   13    86   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.70      0.54      0.61       217\n",
      "\n",
      "avg / total       0.73      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5461789492949248\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  617   122     5\n",
      "    2  148   446    44\n",
      "    3   14    86   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.83      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.70      0.54      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5456061342980069\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  619   120     5\n",
      "    2  142   455    41\n",
      "    3   14    86   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.83      0.82       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.72      0.54      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5392650129772822\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  617   123     4\n",
      "    2  146   449    43\n",
      "    3   15    85   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.83      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.71      0.54      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5438840696101834\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   127     5\n",
      "    2  146   451    41\n",
      "    3   14    87   116\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.72      0.53      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5461789492949248\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   127     4\n",
      "    2  148   449    41\n",
      "    3   13    88   116\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.72      0.53      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5433088351080272\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red STD normed____________________#\")\n",
    "run_knnw_report(f_red_norm.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red MinMax normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   152    15\n",
      "    2  139   420    79\n",
      "    3   16    68   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.59      0.61      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5928487737550271\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   152    15\n",
      "    2  140   419    79\n",
      "    3   16    68   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.59      0.61      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5933759848629978\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  583   148    13\n",
      "    2  133   427    78\n",
      "    3   17    69   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.78      0.79       744\n",
      "          2       0.66      0.67      0.67       638\n",
      "          3       0.59      0.60      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5854179672445431\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  584   146    14\n",
      "    2  132   433    73\n",
      "    3   19    71   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.79       744\n",
      "          2       0.67      0.68      0.67       638\n",
      "          3       0.59      0.59      0.59       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5886140854486008\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   136    11\n",
      "    2  132   441    65\n",
      "    3   17    76   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.68      0.69      0.68       638\n",
      "          3       0.62      0.57      0.59       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5708140177867163\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   133    11\n",
      "    2  127   448    63\n",
      "    3   18    78   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.62      0.56      0.59       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5686185711218377\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   135    10\n",
      "    2  138   441    59\n",
      "    3   19    78   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.63      0.55      0.59       217\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5735465083568029\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   135    10\n",
      "    2  134   446    58\n",
      "    3   12    79   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.65      0.58      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5558264921995841\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  602   133     9\n",
      "    2  141   445    52\n",
      "    3   13    83   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.66      0.56      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5575116698677923\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   126    10\n",
      "    2  137   446    55\n",
      "    3   14    81   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.65      0.56      0.60       217\n",
      "\n",
      "avg / total       0.73      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5563887852034651\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   125     9\n",
      "    2  144   443    51\n",
      "    3   14    81   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.69      0.69       638\n",
      "          3       0.67      0.56      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5552636297846285\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   130     8\n",
      "    2  139   446    53\n",
      "    3   14    86   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.66      0.54      0.59       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5569505105208908\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  607   129     8\n",
      "    2  139   445    54\n",
      "    3   15    82   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.66      0.55      0.60       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5569505105208908\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   131     7\n",
      "    2  132   455    51\n",
      "    3   13    81   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.71      0.70       638\n",
      "          3       0.68      0.57      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   129     6\n",
      "    2  133   455    50\n",
      "    3   13    78   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.69      0.58      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5398445564147902\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  611   129     4\n",
      "    2  136   454    48\n",
      "    3   13    82   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.71      0.70       638\n",
      "          3       0.70      0.56      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5381040535833211\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   128     3\n",
      "    2  138   451    49\n",
      "    3   13    78   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.71      0.58      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5346060486629776\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   136     2\n",
      "    2  142   448    48\n",
      "    3   12    83   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.71      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5392650129772822\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   137     2\n",
      "    2  139   453    46\n",
      "    3   14    79   124\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.72      0.57      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5392650129772822\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  604   138     2\n",
      "    2  139   450    49\n",
      "    3   14    79   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.71      0.57      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5415794657283098\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   137     2\n",
      "    2  139   451    48\n",
      "    3   14    78   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.71      0.58      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5398445564147902\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   132     2\n",
      "    2  141   449    48\n",
      "    3   15    80   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.71      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5415794657283098\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  611   130     3\n",
      "    2  141   450    47\n",
      "    3   15    81   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.71      0.56      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5427329909238503\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   130     2\n",
      "    2  143   448    47\n",
      "    3   15    80   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.71      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5410017808004594\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   129     3\n",
      "    2  142   448    48\n",
      "    3   13    86   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.70      0.54      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5415794657283098\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   130     4\n",
      "    2  145   445    48\n",
      "    3   13    84   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.70      0.55      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   131     4\n",
      "    2  139   454    45\n",
      "    3   11    88   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.71      0.54      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5381040535833211\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   132     4\n",
      "    2  143   452    43\n",
      "    3   14    85   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.72      0.54      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   130     5\n",
      "    2  145   449    44\n",
      "    3   14    86   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.70      0.54      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5484642268462742\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   131     5\n",
      "    2  144   450    44\n",
      "    3   16    87   114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.70      0.53      0.60       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5535716086954976\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red MinMax normed____________________#\")\n",
    "run_knnw_report(f_mm_red.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________red log normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   162    19\n",
      "    2  159   395    84\n",
      "    3   18    77   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.76      0.76       744\n",
      "          2       0.62      0.62      0.62       638\n",
      "          3       0.54      0.56      0.55       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6276912040603917\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   162    19\n",
      "    2  159   395    84\n",
      "    3   18    77   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.76      0.76       744\n",
      "          2       0.62      0.62      0.62       638\n",
      "          3       0.54      0.56      0.55       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6276912040603917\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   151    16\n",
      "    2  160   401    77\n",
      "    3   17    82   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.78      0.77       744\n",
      "          2       0.63      0.63      0.63       638\n",
      "          3       0.56      0.54      0.55       217\n",
      "\n",
      "avg / total       0.68      0.69      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.61358398228325\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   142    13\n",
      "    2  172   392    74\n",
      "    3   16    83   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.79      0.77       744\n",
      "          2       0.64      0.61      0.62       638\n",
      "          3       0.58      0.54      0.56       217\n",
      "\n",
      "avg / total       0.68      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6058914426489055\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   142    11\n",
      "    2  168   403    67\n",
      "    3   13    89   115\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.79      0.78       744\n",
      "          2       0.64      0.63      0.63       638\n",
      "          3       0.60      0.53      0.56       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.5928487737550271\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   133    13\n",
      "    2  174   399    65\n",
      "    3   14    85   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.80      0.78       744\n",
      "          2       0.65      0.63      0.64       638\n",
      "          3       0.60      0.54      0.57       217\n",
      "\n",
      "avg / total       0.69      0.70      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.5944290042980063\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   137     8\n",
      "    2  164   411    63\n",
      "    3   13    89   115\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.81      0.79       744\n",
      "          2       0.65      0.64      0.64       638\n",
      "          3       0.62      0.53      0.57       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5795126373173466\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   139     7\n",
      "    2  162   415    61\n",
      "    3   14    89   114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.80      0.79       744\n",
      "          2       0.65      0.65      0.65       638\n",
      "          3       0.63      0.53      0.57       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5784324637085301\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   141     9\n",
      "    2  157   420    61\n",
      "    3   13    94   110\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.80      0.79       744\n",
      "          2       0.64      0.66      0.65       638\n",
      "          3       0.61      0.51      0.55       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5816669668183675\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   139     8\n",
      "    2  159   423    56\n",
      "    3   14    92   111\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.80      0.79       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.63      0.51      0.57       217\n",
      "\n",
      "avg / total       0.70      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5778916197719315\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  595   140     9\n",
      "    2  161   423    54\n",
      "    3   15    90   112\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.80      0.79       744\n",
      "          2       0.65      0.66      0.66       638\n",
      "          3       0.64      0.52      0.57       217\n",
      "\n",
      "avg / total       0.70      0.71      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5816669668183675\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  596   140     8\n",
      "    2  164   424    50\n",
      "    3   14    95   108\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.80      0.79       744\n",
      "          2       0.64      0.66      0.65       638\n",
      "          3       0.65      0.50      0.56       217\n",
      "\n",
      "avg / total       0.70      0.71      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5795126373173466\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   140     6\n",
      "    2  163   425    50\n",
      "    3   15    93   109\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.80      0.79       744\n",
      "          2       0.65      0.67      0.66       638\n",
      "          3       0.66      0.50      0.57       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5757231632698596\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   133     5\n",
      "    2  161   428    49\n",
      "    3   15    92   110\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.81      0.79       744\n",
      "          2       0.66      0.67      0.66       638\n",
      "          3       0.67      0.51      0.58       217\n",
      "\n",
      "avg / total       0.71      0.72      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5675176628846487\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   128     6\n",
      "    2  166   426    46\n",
      "    3   14    92   111\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.82      0.80       744\n",
      "          2       0.66      0.67      0.66       638\n",
      "          3       0.68      0.51      0.58       217\n",
      "\n",
      "avg / total       0.71      0.72      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5658622845517925\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  611   127     6\n",
      "    2  163   429    46\n",
      "    3   15    91   111\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.82      0.80       744\n",
      "          2       0.66      0.67      0.67       638\n",
      "          3       0.68      0.51      0.58       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.565309414576549\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  607   133     4\n",
      "    2  162   431    45\n",
      "    3   15    95   107\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.82      0.79       744\n",
      "          2       0.65      0.68      0.66       638\n",
      "          3       0.69      0.49      0.57       217\n",
      "\n",
      "avg / total       0.71      0.72      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.565309414576549\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   128     6\n",
      "    2  164   431    43\n",
      "    3   16    90   111\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.82      0.80       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.69      0.51      0.59       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5664146148780654\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   129     3\n",
      "    2  159   439    40\n",
      "    3   13    96   108\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.66      0.69      0.67       638\n",
      "          3       0.72      0.50      0.59       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5524407155660547\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   132     3\n",
      "    2  161   435    42\n",
      "    3   14    96   107\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.70      0.49      0.58       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5586322974706716\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  614   127     3\n",
      "    2  164   433    41\n",
      "    3   14    97   106\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.83      0.80       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.71      0.49      0.58       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5575116698677923\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   133     3\n",
      "    2  160   439    39\n",
      "    3   14    97   106\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.66      0.69      0.67       638\n",
      "          3       0.72      0.49      0.58       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5575116698677923\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   126     5\n",
      "    2  163   436    39\n",
      "    3   15    95   107\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.82      0.80       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.71      0.49      0.58       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5608668355809016\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   131     5\n",
      "    2  160   443    35\n",
      "    3   16    96   105\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.72      0.48      0.58       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5625369142220038\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   127     5\n",
      "    2  159   442    37\n",
      "    3   18    96   103\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.71      0.47      0.57       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.565309414576549\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   130     5\n",
      "    2  157   443    38\n",
      "    3   19    94   104\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.82      0.80       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.71      0.48      0.57       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5675176628846487\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   127     5\n",
      "    2  161   441    36\n",
      "    3   18    98   101\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.82      0.80       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.71      0.47      0.56       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5669664071325218\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   127     5\n",
      "    2  165   437    36\n",
      "    3   18   100    99\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.82      0.80       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.71      0.46      0.55       217\n",
      "\n",
      "avg / total       0.72      0.72      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.570265948512201\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  614   126     4\n",
      "    2  164   438    36\n",
      "    3   18   103    96\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.83      0.80       744\n",
      "          2       0.66      0.69      0.67       638\n",
      "          3       0.71      0.44      0.54       217\n",
      "\n",
      "avg / total       0.72      0.72      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5686185711218377\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   127     4\n",
      "    2  167   435    36\n",
      "    3   18   102    97\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.82      0.80       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.71      0.45      0.55       217\n",
      "\n",
      "avg / total       0.71      0.72      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.570265948512201\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________red log normed____________________#\")\n",
    "run_knnw_report(f_log_red.values, red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white STD normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   420    67\n",
      "    2  372  1543   283\n",
      "    3   57   277   726\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.69      0.70      0.70      2198\n",
      "          3       0.67      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6142449477688314\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   420    67\n",
      "    2  372  1543   283\n",
      "    3   57   277   726\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.69      0.70      0.70      2198\n",
      "          3       0.67      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6142449477688314\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1159   413    68\n",
      "    2  380  1543   275\n",
      "    3   47   298   715\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.71      0.72      1640\n",
      "          2       0.68      0.70      0.69      2198\n",
      "          3       0.68      0.67      0.68      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6105777809772572\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1168   404    68\n",
      "    2  365  1571   262\n",
      "    3   44   302   714\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.73      1640\n",
      "          2       0.69      0.71      0.70      2198\n",
      "          3       0.68      0.67      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.70      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.6030072994458471\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1168   404    68\n",
      "    2  365  1593   240\n",
      "    3   42   294   724\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.73      1640\n",
      "          2       0.70      0.72      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5965396336404474\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1181   395    64\n",
      "    2  366  1583   249\n",
      "    3   38   309   713\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.72      0.73      1640\n",
      "          2       0.69      0.72      0.71      2198\n",
      "          3       0.69      0.67      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5937953309510001\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1179   400    61\n",
      "    2  358  1596   244\n",
      "    3   38   306   716\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.72      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.589828026510688\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1193   390    57\n",
      "    2  349  1609   240\n",
      "    3   37   310   713\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.73      0.74      1640\n",
      "          2       0.70      0.73      0.71      2198\n",
      "          3       0.71      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5830391643887284\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1177   401    62\n",
      "    2  355  1613   230\n",
      "    3   34   298   728\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.72      0.73      1640\n",
      "          2       0.70      0.73      0.72      2198\n",
      "          3       0.71      0.69      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5835641885062709\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1184   403    53\n",
      "    2  341  1613   244\n",
      "    3   36   307   717\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.71      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.580582774199355\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1171   410    59\n",
      "    2  343  1630   225\n",
      "    3   35   297   728\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.73      1640\n",
      "          2       0.70      0.74      0.72      2198\n",
      "          3       0.72      0.69      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.580582774199355\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1174   412    54\n",
      "    2  337  1636   225\n",
      "    3   37   289   734\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.70      0.74      0.72      2198\n",
      "          3       0.72      0.69      0.71      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.576347463367379\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1173   416    51\n",
      "    2  343  1633   222\n",
      "    3   35   289   736\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.70      0.74      0.72      2198\n",
      "          3       0.73      0.69      0.71      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5740402895104287\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1170   425    45\n",
      "    2  331  1640   227\n",
      "    3   36   294   730\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.74      1640\n",
      "          2       0.70      0.75      0.72      2198\n",
      "          3       0.73      0.69      0.71      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5717238052000471\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1175   419    46\n",
      "    2  325  1640   233\n",
      "    3   35   303   722\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.72      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.572259210785023\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1170   424    46\n",
      "    2  319  1644   235\n",
      "    3   34   306   720\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.72      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.572259210785023\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1171   424    45\n",
      "    2  333  1638   227\n",
      "    3   34   310   716\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.72      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5733285219837305\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1173   422    45\n",
      "    2  332  1648   218\n",
      "    3   36   305   719\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.72      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.73      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5717238052000471\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1168   429    43\n",
      "    2  337  1643   218\n",
      "    3   32   310   718\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.74      1640\n",
      "          2       0.69      0.75      0.72      2198\n",
      "          3       0.73      0.68      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5704725713611284\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1177   419    44\n",
      "    2  322  1666   210\n",
      "    3   33   318   709\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.74      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.73      0.73      4898\n",
      "\n",
      "RMSE:\n",
      "0.5674223737793694\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1177   420    43\n",
      "    2  323  1664   211\n",
      "    3   30   319   711\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.74      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.73      0.73      4898\n",
      "\n",
      "RMSE:\n",
      "0.5652593835416719\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1180   413    47\n",
      "    2  320  1668   210\n",
      "    3   31   325   704\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.73      0.66      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.73      0.73      4898\n",
      "\n",
      "RMSE:\n",
      "0.5679618342470648\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1175   419    46\n",
      "    2  321  1668   209\n",
      "    3   31   324   705\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.72      0.74      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.73      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5681415405746901\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1167   428    45\n",
      "    2  308  1689   201\n",
      "    3   30   324   706\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.71      0.74      1640\n",
      "          2       0.69      0.77      0.73      2198\n",
      "          3       0.74      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.73      0.73      4898\n",
      "\n",
      "RMSE:\n",
      "0.5645365451596054\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1170   418    52\n",
      "    2  319  1680   199\n",
      "    3   30   325   705\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.69      0.76      0.73      2198\n",
      "          3       0.74      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.73      0.73      4898\n",
      "\n",
      "RMSE:\n",
      "0.5695771500410791\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1165   427    48\n",
      "    2  322  1682   194\n",
      "    3   29   330   701\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.69      0.77      0.73      2198\n",
      "          3       0.74      0.66      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5681415405746901\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   432    45\n",
      "    2  325  1678   195\n",
      "    3   30   338   692\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.74      0.65      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5697563468836568\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   433    45\n",
      "    2  321  1677   200\n",
      "    3   28   337   695\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.74      0.66      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5685007828113926\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   429    48\n",
      "    2  324  1672   202\n",
      "    3   26   339   695\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.74      0.66      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5697563468836568\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1157   438    45\n",
      "    2  322  1684   192\n",
      "    3   23   346   691\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.71      0.74      1640\n",
      "          2       0.68      0.77      0.72      2198\n",
      "          3       0.74      0.65      0.70      1060\n",
      "\n",
      "avg / total       0.73      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.566161633730484\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white STD normed____________________#\")\n",
    "run_knnw_report(white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white MinMax normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   412    75\n",
      "    2  380  1537   281\n",
      "    3   57   288   715\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.69      0.70      0.69      2198\n",
      "          3       0.67      0.67      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6210214323487594\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1153   412    75\n",
      "    2  380  1537   281\n",
      "    3   57   288   715\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.69      0.70      0.69      2198\n",
      "          3       0.67      0.67      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6210214323487594\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1171   388    81\n",
      "    2  361  1558   279\n",
      "    3   54   288   718\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.73      1640\n",
      "          2       0.70      0.71      0.70      2198\n",
      "          3       0.67      0.68      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6155730465037192\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1168   402    70\n",
      "    2  351  1574   273\n",
      "    3   48   291   721\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.69      0.72      0.71      2198\n",
      "          3       0.68      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.6043600937415616\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1160   415    65\n",
      "    2  360  1576   262\n",
      "    3   46   287   727\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.72      1640\n",
      "          2       0.69      0.72      0.70      2198\n",
      "          3       0.69      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.6008025121753221\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1165   407    68\n",
      "    2  360  1582   256\n",
      "    3   44   289   727\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.73      1640\n",
      "          2       0.69      0.72      0.71      2198\n",
      "          3       0.69      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5994416893358706\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1155   418    67\n",
      "    2  342  1597   259\n",
      "    3   40   292   728\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.69      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.595854742905275\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1161   416    63\n",
      "    2  345  1609   244\n",
      "    3   36   297   727\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.70      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5887886811630648\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1158   418    64\n",
      "    2  331  1618   249\n",
      "    3   37   293   730\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.71      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5882683198761134\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   429    62\n",
      "    2  331  1615   252\n",
      "    3   34   297   729\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.70      0.69      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5879211564821267\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1155   423    62\n",
      "    2  332  1618   248\n",
      "    3   34   301   725\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5870523498060642\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1154   425    61\n",
      "    2  327  1618   253\n",
      "    3   35   301   724\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5874000266797793\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   424    64\n",
      "    2  325  1610   263\n",
      "    3   34   306   720\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.69      0.68      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5908655436300585\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   426    58\n",
      "    2  331  1610   257\n",
      "    3   31   306   723\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.73      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5849619490439683\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   433    60\n",
      "    2  332  1616   250\n",
      "    3   29   315   716\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.68      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5867044669015549\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   437    61\n",
      "    2  334  1615   249\n",
      "    3   30   311   719\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.68      0.73      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5882683198761134\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   427    67\n",
      "    2  331  1626   241\n",
      "    3   29   315   716\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5887886811630648\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   425    66\n",
      "    2  331  1622   245\n",
      "    3   26   314   720\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.74      0.71      2198\n",
      "          3       0.70      0.68      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.586182255434572\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   426    62\n",
      "    2  332  1624   242\n",
      "    3   24   330   706\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.68      0.74      0.71      2198\n",
      "          3       0.70      0.67      0.68      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5846128222154678\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   433    64\n",
      "    2  333  1632   233\n",
      "    3   27   321   712\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.68      0.74      0.71      2198\n",
      "          3       0.71      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5863563775995395\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   431    63\n",
      "    2  335  1630   233\n",
      "    3   24   326   710\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.68      0.74      0.71      2198\n",
      "          3       0.71      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5844381805917904\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1151   426    63\n",
      "    2  329  1638   231\n",
      "    3   25   326   709\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.69      0.75      0.71      2198\n",
      "          3       0.71      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5828640512553632\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1140   433    67\n",
      "    2  331  1633   234\n",
      "    3   26   322   712\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.68      0.74      0.71      2198\n",
      "          3       0.70      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5877474978883274\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1134   442    64\n",
      "    2  329  1644   225\n",
      "    3   24   328   708\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.69      0.73      1640\n",
      "          2       0.68      0.75      0.71      2198\n",
      "          3       0.71      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5849619490439683\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   436    62\n",
      "    2  333  1635   230\n",
      "    3   25   327   708\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.70      0.73      1640\n",
      "          2       0.68      0.74      0.71      2198\n",
      "          3       0.71      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.71      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5846128222154678\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1138   437    65\n",
      "    2  330  1644   224\n",
      "    3   22   332   706\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.69      0.73      1640\n",
      "          2       0.68      0.75      0.71      2198\n",
      "          3       0.71      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.71      0.71      4898\n",
      "\n",
      "RMSE:\n",
      "0.5840887406917362\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   434    61\n",
      "    2  322  1660   216\n",
      "    3   21   328   711\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.72      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5765245558476275\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1143   439    58\n",
      "    2  321  1658   219\n",
      "    3   20   330   710\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.68      0.75      0.72      2198\n",
      "          3       0.72      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5752837636664714\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   437    56\n",
      "    2  321  1661   216\n",
      "    3   20   328   712\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.68      0.76      0.72      2198\n",
      "          3       0.72      0.67      0.70      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5726158697232213\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1151   431    58\n",
      "    2  322  1665   211\n",
      "    3   21   333   706\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.70      0.73      1640\n",
      "          2       0.69      0.76      0.72      2198\n",
      "          3       0.72      0.67      0.69      1060\n",
      "\n",
      "avg / total       0.72      0.72      0.72      4898\n",
      "\n",
      "RMSE:\n",
      "0.5738624303924459\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white MinMax normed____________________#\")\n",
    "run_knnw_report(mm_white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#____________________white log normed____________________#\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1151   402    87\n",
      "    2  420  1485   293\n",
      "    3   69   299   692\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.70      0.70      1640\n",
      "          2       0.68      0.68      0.68      2198\n",
      "          3       0.65      0.65      0.65      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6450489898178324\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1151   402    87\n",
      "    2  420  1485   293\n",
      "    3   69   299   692\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.70      0.70      1640\n",
      "          2       0.68      0.68      0.68      2198\n",
      "          3       0.65      0.65      0.65      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6450489898178324\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1122   422    96\n",
      "    2  405  1520   273\n",
      "    3   60   302   698\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.68      0.70      1640\n",
      "          2       0.68      0.69      0.68      2198\n",
      "          3       0.65      0.66      0.66      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6431471213350043\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1128   429    83\n",
      "    2  391  1529   278\n",
      "    3   64   295   701\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.69      0.70      1640\n",
      "          2       0.68      0.70      0.69      2198\n",
      "          3       0.66      0.66      0.66      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6359644614625606\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1135   430    75\n",
      "    2  374  1541   283\n",
      "    3   53   289   718\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.68      0.70      0.69      2198\n",
      "          3       0.67      0.68      0.67      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.620857032231425\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1135   427    78\n",
      "    2  355  1570   273\n",
      "    3   52   306   702\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.68      0.71      0.70      2198\n",
      "          3       0.67      0.66      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6197050102380721\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1134   438    68\n",
      "    2  359  1566   273\n",
      "    3   48   320   692\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.67      0.71      0.69      2198\n",
      "          3       0.67      0.65      0.66      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6152412905936062\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   442    59\n",
      "    2  360  1574   264\n",
      "    3   49   322   689\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.67      0.72      0.69      2198\n",
      "          3       0.68      0.65      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6095738157363386\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1124   460    56\n",
      "    2  359  1589   250\n",
      "    3   43   328   689\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.67      0.72      0.69      2198\n",
      "          3       0.69      0.65      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6050353566267652\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   461    53\n",
      "    2  357  1604   237\n",
      "    3   43   336   681\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.67      0.73      0.70      2198\n",
      "          3       0.70      0.64      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.601990708726656\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1120   462    58\n",
      "    2  355  1610   233\n",
      "    3   39   339   682\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.68      0.71      1640\n",
      "          2       0.67      0.73      0.70      2198\n",
      "          3       0.70      0.64      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6023297629403728\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1113   467    60\n",
      "    2  352  1617   229\n",
      "    3   39   348   673\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.68      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.63      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6048666115791026\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1112   476    52\n",
      "    2  336  1628   234\n",
      "    3   37   351   672\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.68      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.63      0.67      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5982484301331669\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1119   468    53\n",
      "    2  341  1624   233\n",
      "    3   39   360   661\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.68      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.62      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6011422365520177\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1124   461    55\n",
      "    2  348  1618   232\n",
      "    3   38   358   664\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.63      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6013120267648518\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1125   462    53\n",
      "    2  346  1620   232\n",
      "    3   35   362   663\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.69      0.72      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.63      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5984190414100229\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1121   465    54\n",
      "    2  341  1632   225\n",
      "    3   37   362   661\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.68      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.62      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5989305836388442\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1123   466    51\n",
      "    2  348  1618   232\n",
      "    3   38   369   653\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.68      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.62      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6013120267648518\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1115   473    52\n",
      "    2  338  1631   229\n",
      "    3   34   369   657\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.68      0.71      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.62      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5982484301331669\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1112   478    50\n",
      "    2  335  1641   222\n",
      "    3   34   382   644\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.68      0.71      1640\n",
      "          2       0.66      0.75      0.70      2198\n",
      "          3       0.70      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5982484301331669\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1110   479    51\n",
      "    2  325  1647   226\n",
      "    3   33   376   651\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.68      0.71      1640\n",
      "          2       0.66      0.75      0.70      2198\n",
      "          3       0.70      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5963684846959866\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1103   488    49\n",
      "    2  323  1652   223\n",
      "    3   29   382   649\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.67      0.71      1640\n",
      "          2       0.66      0.75      0.70      2198\n",
      "          3       0.70      0.61      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5939672213384336\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1108   485    47\n",
      "    2  321  1652   225\n",
      "    3   31   382   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.68      0.71      1640\n",
      "          2       0.66      0.75      0.70      2198\n",
      "          3       0.70      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5934514008144424\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1108   487    45\n",
      "    2  324  1652   222\n",
      "    3   33   386   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.68      0.71      1640\n",
      "          2       0.65      0.75      0.70      2198\n",
      "          3       0.71      0.60      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5944825942955568\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1100   496    44\n",
      "    2  326  1655   217\n",
      "    3   33   395   632\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.67      0.71      1640\n",
      "          2       0.65      0.75      0.70      2198\n",
      "          3       0.71      0.60      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5963684846959866\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1098   493    49\n",
      "    2  323  1657   218\n",
      "    3   33   389   638\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.67      0.71      1640\n",
      "          2       0.65      0.75      0.70      2198\n",
      "          3       0.70      0.60      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5979070615289761\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1099   496    45\n",
      "    2  324  1655   219\n",
      "    3   31   400   629\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.67      0.71      1640\n",
      "          2       0.65      0.75      0.70      2198\n",
      "          3       0.70      0.59      0.64      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5965396336404474\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1096   500    44\n",
      "    2  321  1668   209\n",
      "    3   30   401   629\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.67      0.71      1640\n",
      "          2       0.65      0.76      0.70      2198\n",
      "          3       0.71      0.59      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5937953309510001\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1100   497    43\n",
      "    2  319  1669   210\n",
      "    3   30   396   634\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.67      0.71      1640\n",
      "          2       0.65      0.76      0.70      2198\n",
      "          3       0.71      0.60      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.591556210778327\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1101   498    41\n",
      "    2  324  1676   198\n",
      "    3   30   390   640\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.67      0.71      1640\n",
      "          2       0.65      0.76      0.70      2198\n",
      "          3       0.73      0.60      0.66      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5880947637962552\n"
     ]
    }
   ],
   "source": [
    "print(\"#____________________white log normed____________________#\")\n",
    "run_knnw_report(log_white_norm.values, white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1044   451   145\n",
      "    2  430  1436   332\n",
      "    3  113   329   618\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.64      0.65      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.56      0.58      0.57      1060\n",
      "\n",
      "avg / total       0.63      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.7249280106751942\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1044   451   145\n",
      "    2  430  1436   332\n",
      "    3  113   329   618\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.64      0.65      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.56      0.58      0.57      1060\n",
      "\n",
      "avg / total       0.63      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.7249280106751942\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1036   479   125\n",
      "    2  417  1487   294\n",
      "    3   98   336   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.63      0.65      1640\n",
      "          2       0.65      0.68      0.66      2198\n",
      "          3       0.60      0.59      0.59      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "0.7026171689305275\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1043   479   118\n",
      "    2  428  1485   285\n",
      "    3  103   338   619\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.64      0.65      1640\n",
      "          2       0.65      0.68      0.66      2198\n",
      "          3       0.61      0.58      0.59      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "0.7020357727457922\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1025   509   106\n",
      "    2  415  1502   281\n",
      "    3   96   346   618\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.62      0.65      1640\n",
      "          2       0.64      0.68      0.66      2198\n",
      "          3       0.61      0.58      0.60      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "0.6939921852036405\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1035   506    99\n",
      "    2  425  1516   257\n",
      "    3   92   347   621\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.63      0.65      1640\n",
      "          2       0.64      0.69      0.66      2198\n",
      "          3       0.64      0.59      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6851096665543456\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1020   526    94\n",
      "    2  421  1516   261\n",
      "    3   96   358   606\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.62      0.64      1640\n",
      "          2       0.63      0.69      0.66      2198\n",
      "          3       0.63      0.57      0.60      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "0.6891209685309898\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1042   503    95\n",
      "    2  407  1541   250\n",
      "    3  100   365   595\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.67      0.64      0.65      1640\n",
      "          2       0.64      0.70      0.67      2198\n",
      "          3       0.63      0.56      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6860030940148582\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1050   494    96\n",
      "    2  402  1551   245\n",
      "    3   98   361   601\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.64      0.66      1640\n",
      "          2       0.64      0.71      0.67      2198\n",
      "          3       0.64      0.57      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6819734532480539\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1048   498    94\n",
      "    2  400  1567   231\n",
      "    3   94   371   595\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.64      0.66      1640\n",
      "          2       0.64      0.71      0.68      2198\n",
      "          3       0.65      0.56      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6780704254260649\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1058   488    94\n",
      "    2  388  1580   230\n",
      "    3   90   377   593\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.65      0.67      1640\n",
      "          2       0.65      0.72      0.68      2198\n",
      "          3       0.65      0.56      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6730839902886193\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1055   498    87\n",
      "    2  397  1568   233\n",
      "    3   87   388   585\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.64      0.66      1640\n",
      "          2       0.64      0.71      0.67      2198\n",
      "          3       0.65      0.55      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.672021505032247\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1052   504    84\n",
      "    2  393  1579   226\n",
      "    3   87   389   584\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.64      0.66      1640\n",
      "          2       0.64      0.72      0.68      2198\n",
      "          3       0.65      0.55      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6695866365013083\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1056   497    87\n",
      "    2  389  1578   231\n",
      "    3   86   394   580\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.64      0.67      1640\n",
      "          2       0.64      0.72      0.68      2198\n",
      "          3       0.65      0.55      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6706529792211311\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1062   496    82\n",
      "    2  394  1580   224\n",
      "    3   90   394   576\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.65      0.67      1640\n",
      "          2       0.64      0.72      0.68      2198\n",
      "          3       0.65      0.54      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6695866365013083\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1060   500    80\n",
      "    2  394  1579   225\n",
      "    3   87   391   582\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.65      0.67      1640\n",
      "          2       0.64      0.72      0.68      2198\n",
      "          3       0.66      0.55      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6668367824332128\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1057   508    75\n",
      "    2  408  1565   225\n",
      "    3   85   398   577\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.64      0.66      1640\n",
      "          2       0.63      0.71      0.67      2198\n",
      "          3       0.66      0.54      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6669898495263417\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1061   504    75\n",
      "    2  400  1575   223\n",
      "    3   89   398   573\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.65      0.67      1640\n",
      "          2       0.64      0.72      0.67      2198\n",
      "          3       0.66      0.54      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6672958783791159\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1056   505    79\n",
      "    2  398  1593   207\n",
      "    3   84   401   575\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.64      0.66      1640\n",
      "          2       0.64      0.72      0.68      2198\n",
      "          3       0.67      0.54      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6645365452151601\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1059   506    75\n",
      "    2  388  1602   208\n",
      "    3   83   411   566\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.65      0.67      1640\n",
      "          2       0.64      0.73      0.68      2198\n",
      "          3       0.67      0.53      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6617657066902496\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1058   511    71\n",
      "    2  401  1600   197\n",
      "    3   86   419   555\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.65      0.66      1640\n",
      "          2       0.63      0.73      0.68      2198\n",
      "          3       0.67      0.52      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6634603719661462\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1050   515    75\n",
      "    2  391  1618   189\n",
      "    3   80   423   557\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.64      0.66      1640\n",
      "          2       0.63      0.74      0.68      2198\n",
      "          3       0.68      0.53      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6606850201073139\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1043   526    71\n",
      "    2  391  1625   182\n",
      "    3   82   418   560\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.64      0.66      1640\n",
      "          2       0.63      0.74      0.68      2198\n",
      "          3       0.69      0.53      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6592929630343207\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1037   543    60\n",
      "    2  393  1623   182\n",
      "    3   87   414   559\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.63      0.66      1640\n",
      "          2       0.63      0.74      0.68      2198\n",
      "          3       0.70      0.53      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6578979604915541\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1032   547    61\n",
      "    2  391  1621   186\n",
      "    3   88   416   556\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.63      0.66      1640\n",
      "          2       0.63      0.74      0.68      2198\n",
      "          3       0.69      0.52      0.60      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6603759276833293\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1036   540    64\n",
      "    2  393  1619   186\n",
      "    3   87   421   552\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.63      0.66      1640\n",
      "          2       0.63      0.74      0.68      2198\n",
      "          3       0.69      0.52      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6616114309668126\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1040   544    56\n",
      "    2  392  1623   183\n",
      "    3   85   426   549\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.63      0.66      1640\n",
      "          2       0.63      0.74      0.68      2198\n",
      "          3       0.70      0.52      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6561889299589981\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1040   540    60\n",
      "    2  397  1617   184\n",
      "    3   88   423   549\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.63      0.66      1640\n",
      "          2       0.63      0.74      0.68      2198\n",
      "          3       0.69      0.52      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6603759276833293\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1026   552    62\n",
      "    2  406  1615   177\n",
      "    3   85   432   543\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.63      0.65      1640\n",
      "          2       0.62      0.73      0.67      2198\n",
      "          3       0.69      0.51      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6633064903980399\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1035   549    56\n",
      "    2  406  1613   179\n",
      "    3   86   436   538\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.63      0.65      1640\n",
      "          2       0.62      0.73      0.67      2198\n",
      "          3       0.70      0.51      0.59      1060\n",
      "\n",
      "avg / total       0.66      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6606850201073139\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(white_input.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  520   191    33\n",
      "    2  190   380    68\n",
      "    3   30    74   113\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.70      0.70       744\n",
      "          2       0.59      0.60      0.59       638\n",
      "          3       0.53      0.52      0.52       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6961881381511136\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  520   191    33\n",
      "    2  190   380    68\n",
      "    3   30    74   113\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.70      0.70       744\n",
      "          2       0.59      0.60      0.59       638\n",
      "          3       0.53      0.52      0.52       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6961881381511136\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  536   182    26\n",
      "    2  200   369    69\n",
      "    3   33    68   116\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.72      0.71       744\n",
      "          2       0.60      0.58      0.59       638\n",
      "          3       0.55      0.53      0.54       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6871463499986359\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  540   183    21\n",
      "    2  201   371    66\n",
      "    3   27    75   115\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.59      0.58      0.59       638\n",
      "          3       0.57      0.53      0.55       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6696306842456534\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  544   180    20\n",
      "    2  206   362    70\n",
      "    3   32    75   110\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.73      0.71       744\n",
      "          2       0.59      0.57      0.58       638\n",
      "          3       0.55      0.51      0.53       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6798263398896478\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  544   181    19\n",
      "    2  208   371    59\n",
      "    3   31    73   113\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.73      0.71       744\n",
      "          2       0.59      0.58      0.59       638\n",
      "          3       0.59      0.52      0.55       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6714959543887628\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  548   180    16\n",
      "    2  223   358    57\n",
      "    3   34    75   108\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.74      0.71       744\n",
      "          2       0.58      0.56      0.57       638\n",
      "          3       0.60      0.50      0.54       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6779839886978022\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   177    12\n",
      "    2  219   364    55\n",
      "    3   36    78   103\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.71       744\n",
      "          2       0.59      0.57      0.58       638\n",
      "          3       0.61      0.47      0.53       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6714959543887628\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   176    13\n",
      "    2  221   366    51\n",
      "    3   37    74   106\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.75      0.71       744\n",
      "          2       0.59      0.57      0.58       638\n",
      "          3       0.62      0.49      0.55       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6719614629052536\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   176    13\n",
      "    2  213   377    48\n",
      "    3   38    77   102\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.60      0.59      0.59       638\n",
      "          3       0.63      0.47      0.54       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6700974885437159\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  558   177     9\n",
      "    2  219   370    49\n",
      "    3   34    80   103\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.59      0.58      0.58       638\n",
      "          3       0.64      0.47      0.54       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6602252917735247\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   176     9\n",
      "    2  213   382    43\n",
      "    3   35    85    97\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.59      0.60      0.60       638\n",
      "          3       0.65      0.45      0.53       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6583280887371149\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   174     9\n",
      "    2  215   380    43\n",
      "    3   37    86    94\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.75      0.72       744\n",
      "          2       0.59      0.60      0.59       638\n",
      "          3       0.64      0.43      0.52       217\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6625891564490792\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568   167     9\n",
      "    2  212   381    45\n",
      "    3   39    85    93\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.76      0.73       744\n",
      "          2       0.60      0.60      0.60       638\n",
      "          3       0.63      0.43      0.51       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6621170586645606\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   166     7\n",
      "    2  225   373    40\n",
      "    3   40    86    91\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.60      0.58      0.59       638\n",
      "          3       0.66      0.42      0.51       217\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6640034358734768\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  572   165     7\n",
      "    2  222   385    31\n",
      "    3   38    89    90\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.60      0.60      0.60       638\n",
      "          3       0.70      0.41      0.52       217\n",
      "\n",
      "avg / total       0.66      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6554719881158179\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   166     7\n",
      "    2  225   381    32\n",
      "    3   40    87    90\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.60      0.60      0.60       638\n",
      "          3       0.70      0.41      0.52       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6606987413085704\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  572   165     7\n",
      "    2  223   385    30\n",
      "    3   41    86    90\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.61      0.60      0.60       638\n",
      "          3       0.71      0.41      0.52       217\n",
      "\n",
      "avg / total       0.66      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6597515024826716\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   163     6\n",
      "    2  233   375    30\n",
      "    3   37    90    90\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.60      0.59      0.59       638\n",
      "          3       0.71      0.41      0.52       217\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6559488684903696\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  579   158     7\n",
      "    2  222   384    32\n",
      "    3   40    87    90\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.78      0.73       744\n",
      "          2       0.61      0.60      0.61       638\n",
      "          3       0.70      0.41      0.52       217\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6554719881158179\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  580   156     8\n",
      "    2  226   385    27\n",
      "    3   42    86    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.78      0.73       744\n",
      "          2       0.61      0.60      0.61       638\n",
      "          3       0.72      0.41      0.52       217\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6592773727035149\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   163     7\n",
      "    2  217   393    28\n",
      "    3   42    86    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.61      0.62      0.61       638\n",
      "          3       0.72      0.41      0.52       217\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6569015906605667\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   162     7\n",
      "    2  219   388    31\n",
      "    3   46    85    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.73       744\n",
      "          2       0.61      0.61      0.61       638\n",
      "          3       0.69      0.40      0.50       217\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6658844692053987\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   162     8\n",
      "    2  222   387    29\n",
      "    3   44    86    87\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.61      0.61      0.61       638\n",
      "          3       0.70      0.40      0.51       217\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6649446176865927\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   163     8\n",
      "    2  221   391    26\n",
      "    3   45    86    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.61      0.61      0.61       638\n",
      "          3       0.72      0.40      0.51       217\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6654147093802949\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  572   165     7\n",
      "    2  221   392    25\n",
      "    3   48    83    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.77      0.72       744\n",
      "          2       0.61      0.61      0.61       638\n",
      "          3       0.73      0.40      0.51       217\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6682283147812745\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   162     7\n",
      "    2  212   401    25\n",
      "    3   44    88    85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.62      0.63      0.62       638\n",
      "          3       0.73      0.39      0.51       217\n",
      "\n",
      "avg / total       0.67      0.66      0.66      1599\n",
      "\n",
      "RMSE:\n",
      "0.6573774339614009\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  580   158     6\n",
      "    2  213   401    24\n",
      "    3   43    90    84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.78      0.73       744\n",
      "          2       0.62      0.63      0.62       638\n",
      "          3       0.74      0.39      0.51       217\n",
      "\n",
      "avg / total       0.67      0.67      0.66      1599\n",
      "\n",
      "RMSE:\n",
      "0.6526033879690964\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   162     6\n",
      "    2  216   396    26\n",
      "    3   45    87    85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.77      0.73       744\n",
      "          2       0.61      0.62      0.62       638\n",
      "          3       0.73      0.39      0.51       217\n",
      "\n",
      "avg / total       0.66      0.66      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6592773727035149\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  583   155     6\n",
      "    2  215   399    24\n",
      "    3   44    87    86\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.78      0.74       744\n",
      "          2       0.62      0.63      0.62       638\n",
      "          3       0.74      0.40      0.52       217\n",
      "\n",
      "avg / total       0.67      0.67      0.66      1599\n",
      "\n",
      "RMSE:\n",
      "0.6526033879690964\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(red_input.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   157    24\n",
      "    2  162   404    72\n",
      "    3   24    64   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.76      0.75       744\n",
      "          2       0.65      0.63      0.64       638\n",
      "          3       0.57      0.59      0.58       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6361036805684829\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   157    24\n",
      "    2  162   404    72\n",
      "    3   24    64   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.76      0.75       744\n",
      "          2       0.65      0.63      0.64       638\n",
      "          3       0.57      0.59      0.58       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6361036805684829\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  562   162    20\n",
      "    2  157   420    61\n",
      "    3   21    63   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.76      0.76       744\n",
      "          2       0.65      0.66      0.65       638\n",
      "          3       0.62      0.61      0.62       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.6161268194625503\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   165    15\n",
      "    2  153   424    61\n",
      "    3   20    69   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.76       744\n",
      "          2       0.64      0.66      0.65       638\n",
      "          3       0.63      0.59      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.606407314553894\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   169    12\n",
      "    2  154   423    61\n",
      "    3   17    69   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.76       744\n",
      "          2       0.64      0.66      0.65       638\n",
      "          3       0.64      0.60      0.62       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5965294666886896\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  562   167    15\n",
      "    2  148   426    64\n",
      "    3   16    72   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.76       744\n",
      "          2       0.64      0.67      0.65       638\n",
      "          3       0.62      0.59      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5996663654430289\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  562   169    13\n",
      "    2  143   428    67\n",
      "    3   15    69   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.76      0.77       744\n",
      "          2       0.64      0.67      0.66       638\n",
      "          3       0.62      0.61      0.62       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5917929425096692\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   169    11\n",
      "    2  138   434    66\n",
      "    3   14    74   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.76      0.77       744\n",
      "          2       0.64      0.68      0.66       638\n",
      "          3       0.63      0.59      0.61       217\n",
      "\n",
      "avg / total       0.71      0.70      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5848835828636667\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   155    13\n",
      "    2  138   436    64\n",
      "    3   14    77   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.77      0.78       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.62      0.58      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5822043036228546\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  572   159    13\n",
      "    2  146   428    64\n",
      "    3   12    77   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.77      0.78       744\n",
      "          2       0.64      0.67      0.66       638\n",
      "          3       0.62      0.59      0.61       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5843487097907776\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   153    14\n",
      "    2  141   436    61\n",
      "    3   14    78   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.62      0.58      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5838133466826988\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  580   151    13\n",
      "    2  140   441    57\n",
      "    3   16    74   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.64      0.59      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.58005196980943\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  582   146    16\n",
      "    2  138   440    60\n",
      "    3   10    78   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.78      0.79       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.63      0.59      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5735465083568029\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  587   143    14\n",
      "    2  147   432    59\n",
      "    3   12    78   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.64      0.59      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5762660423751748\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   145    14\n",
      "    2  146   437    55\n",
      "    3   11    78   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.65      0.59      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.572455077285278\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  584   146    14\n",
      "    2  145   439    54\n",
      "    3   16    74   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.78      0.78       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.65      0.59      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5805908012956227\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   142    14\n",
      "    2  139   445    54\n",
      "    3   11    82   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.79      0.79       744\n",
      "          2       0.67      0.70      0.68       638\n",
      "          3       0.65      0.57      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5686185711218377\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  593   139    12\n",
      "    2  141   445    52\n",
      "    3   15    76   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.79       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.66      0.58      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.568068383696318\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   142    11\n",
      "    2  146   441    51\n",
      "    3   11    79   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.67      0.59      0.63       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5625369142220038\n",
      "20 neighbours:\n",
      "20 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   143    12\n",
      "    2  144   443    51\n",
      "    3   14    78   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.66      0.58      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.570265948512201\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  593   139    12\n",
      "    2  142   443    53\n",
      "    3   10    86   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.65      0.56      0.60       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5636475508693359\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  593   139    12\n",
      "    2  141   445    52\n",
      "    3   10    81   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.67      0.70      0.68       638\n",
      "          3       0.66      0.58      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5597506815680955\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   139    11\n",
      "    2  135   447    56\n",
      "    3   10    80   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.65      0.59      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5558264921995841\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   143    10\n",
      "    2  143   440    55\n",
      "    3   11    81   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.66      0.58      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5625369142220038\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  592   142    10\n",
      "    2  138   451    49\n",
      "    3    9    84   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.68      0.57      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5530064512141136\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   140    10\n",
      "    2  143   447    48\n",
      "    3   10    80   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.69      0.59      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5541361897792044\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   139     8\n",
      "    2  146   445    47\n",
      "    3    9    87   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.80       744\n",
      "          2       0.66      0.70      0.68       638\n",
      "          3       0.69      0.56      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5518743999732558\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   138     8\n",
      "    2  147   444    47\n",
      "    3   11    84   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.80       744\n",
      "          2       0.67      0.70      0.68       638\n",
      "          3       0.69      0.56      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5547001962252291\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  594   141     9\n",
      "    2  146   448    44\n",
      "    3    9    84   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.80       744\n",
      "          2       0.67      0.70      0.68       638\n",
      "          3       0.70      0.57      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5518743999732558\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  596   140     8\n",
      "    2  150   447    41\n",
      "    3    9    85   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.80       744\n",
      "          2       0.67      0.70      0.68       638\n",
      "          3       0.72      0.57      0.63       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5501719556083909\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(red_norm.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   166    23\n",
      "    2  161   414    63\n",
      "    3   24    64   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.75      0.75       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.60      0.59      0.60       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6336410167329005\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   166    23\n",
      "    2  161   414    63\n",
      "    3   24    64   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.75      0.75       744\n",
      "          2       0.64      0.65      0.65       638\n",
      "          3       0.60      0.59      0.60       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6336410167329005\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  552   172    20\n",
      "    2  145   431    62\n",
      "    3   22    63   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.74      0.75       744\n",
      "          2       0.65      0.68      0.66       638\n",
      "          3       0.62      0.61      0.61       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.6176474967721622\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   170    15\n",
      "    2  153   432    53\n",
      "    3   21    59   137\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.76      0.75      0.76       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.67      0.63      0.65       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.6017485465880458\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  563   167    14\n",
      "    2  144   435    59\n",
      "    3   20    65   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.76      0.77       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.64      0.61      0.63       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5975769292454981\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  557   172    15\n",
      "    2  144   437    57\n",
      "    3   21    64   132\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.75      0.76       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.65      0.61      0.63       217\n",
      "\n",
      "avg / total       0.71      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.6027869400206114\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   158    13\n",
      "    2  145   432    61\n",
      "    3   15    77   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.77      0.78       744\n",
      "          2       0.65      0.68      0.66       638\n",
      "          3       0.63      0.58      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5880826053533632\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  578   154    12\n",
      "    2  140   441    57\n",
      "    3   15    74   128\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.69      0.67       638\n",
      "          3       0.65      0.59      0.62       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5773502691896257\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   155    12\n",
      "    2  149   432    57\n",
      "    3   14    77   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.78      0.78       744\n",
      "          2       0.65      0.68      0.66       638\n",
      "          3       0.65      0.58      0.61       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5822043036228546\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  580   151    13\n",
      "    2  154   433    51\n",
      "    3   14    78   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.78      0.78       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.66      0.58      0.62       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5822043036228546\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   158    12\n",
      "    2  154   427    57\n",
      "    3   16    79   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.77      0.77      0.77       744\n",
      "          2       0.64      0.67      0.66       638\n",
      "          3       0.64      0.56      0.60       217\n",
      "\n",
      "avg / total       0.70      0.70      0.70      1599\n",
      "\n",
      "RMSE:\n",
      "0.5917929425096692\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  578   154    12\n",
      "    2  149   435    54\n",
      "    3   14    80   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.78      0.78       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.65      0.57      0.61       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5816669668183675\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  590   144    10\n",
      "    2  154   429    55\n",
      "    3   11    84   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.79      0.79       744\n",
      "          2       0.65      0.67      0.66       638\n",
      "          3       0.65      0.56      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5708140177867163\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  583   150    11\n",
      "    2  149   432    57\n",
      "    3   14    78   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.78      0.78       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.65      0.58      0.61       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5778916197719315\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   146    10\n",
      "    2  152   433    53\n",
      "    3   11    82   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.79      0.79       744\n",
      "          2       0.66      0.68      0.67       638\n",
      "          3       0.66      0.57      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5686185711218377\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   146    10\n",
      "    2  148   436    54\n",
      "    3   11    84   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.66      0.56      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.568068383696318\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   143    10\n",
      "    2  148   434    56\n",
      "    3   10    86   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.65      0.68      0.67       638\n",
      "          3       0.65      0.56      0.60       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5664146148780654\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   144    11\n",
      "    2  145   441    52\n",
      "    3   10    84   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.66      0.69      0.67       638\n",
      "          3       0.66      0.57      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5642020493318807\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   134    10\n",
      "    2  145   440    53\n",
      "    3   10    86   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.66      0.56      0.60       217\n",
      "\n",
      "avg / total       0.73      0.73      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5580722649514734\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  587   146    11\n",
      "    2  147   439    52\n",
      "    3   10    85   122\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.79      0.79       744\n",
      "          2       0.66      0.69      0.67       638\n",
      "          3       0.66      0.56      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5669664071325218\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  601   132    11\n",
      "    2  145   439    54\n",
      "    3   10    83   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.66      0.57      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5580722649514734\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  595   137    12\n",
      "    2  148   441    49\n",
      "    3   11    82   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.79       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.67      0.57      0.62       217\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5636475508693359\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   134    11\n",
      "    2  148   438    52\n",
      "    3   12    86   119\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.65      0.55      0.60       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5658622845517925\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   136    11\n",
      "    2  151   437    50\n",
      "    3   13    83   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.80      0.79       744\n",
      "          2       0.67      0.68      0.68       638\n",
      "          3       0.66      0.56      0.61       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.568068383696318\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   132    12\n",
      "    2  145   444    49\n",
      "    3   12    87   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.70      0.68       638\n",
      "          3       0.66      0.54      0.60       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5642020493318807\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  596   137    11\n",
      "    2  143   449    46\n",
      "    3   14    84   119\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.80      0.80       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.68      0.55      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5647560033674607\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   134    10\n",
      "    2  142   450    46\n",
      "    3   15    82   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.68      0.55      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5614240804630911\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  603   132     9\n",
      "    2  148   447    43\n",
      "    3   14    84   119\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.70      0.55      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5586322974706716\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  604   131     9\n",
      "    2  150   443    45\n",
      "    3   13    85   119\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.69      0.55      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5586322974706716\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  601   134     9\n",
      "    2  153   443    42\n",
      "    3   13    90   114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.78      0.81      0.80       744\n",
      "          2       0.66      0.69      0.68       638\n",
      "          3       0.69      0.53      0.60       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.563092506371473\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(mm_red_norm.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   162    27\n",
      "    2  171   392    75\n",
      "    3   21    67   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.75      0.74       744\n",
      "          2       0.63      0.61      0.62       638\n",
      "          3       0.56      0.59      0.58       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "0.6458604414412116\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  555   162    27\n",
      "    2  171   392    75\n",
      "    3   21    67   129\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.75      0.74       744\n",
      "          2       0.63      0.61      0.62       638\n",
      "          3       0.56      0.59      0.58       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "0.6458604414412116\n",
      "3 neighbours:\n",
      "3 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   155    29\n",
      "    2  187   383    68\n",
      "    3   22    73   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.75      0.74       744\n",
      "          2       0.63      0.60      0.61       638\n",
      "          3       0.56      0.56      0.56       217\n",
      "\n",
      "avg / total       0.66      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "0.6554719881158179\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   162    22\n",
      "    2  182   384    72\n",
      "    3   22    72   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.75      0.74       744\n",
      "          2       0.62      0.60      0.61       638\n",
      "          3       0.57      0.57      0.57       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "0.6444063447939946\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   162    22\n",
      "    2  175   388    75\n",
      "    3   19    76   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.75      0.75       744\n",
      "          2       0.62      0.61      0.61       638\n",
      "          3       0.56      0.56      0.56       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "0.6385568469441362\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  561   165    18\n",
      "    2  178   401    59\n",
      "    3   18    79   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.75      0.75       744\n",
      "          2       0.62      0.63      0.63       638\n",
      "          3       0.61      0.55      0.58       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6251954041004442\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  559   170    15\n",
      "    2  176   402    60\n",
      "    3   20    79   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.75      0.75       744\n",
      "          2       0.62      0.63      0.62       638\n",
      "          3       0.61      0.54      0.58       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "0.6251954041004442\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  562   165    17\n",
      "    2  185   393    60\n",
      "    3   17    83   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.76      0.75       744\n",
      "          2       0.61      0.62      0.61       638\n",
      "          3       0.60      0.54      0.57       217\n",
      "\n",
      "avg / total       0.67      0.67      0.67      1599\n",
      "\n",
      "RMSE:\n",
      "0.627192838595508\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  569   158    17\n",
      "    2  175   404    59\n",
      "    3   17    86   114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.76      0.76       744\n",
      "          2       0.62      0.63      0.63       638\n",
      "          3       0.60      0.53      0.56       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6196692615791841\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568   160    16\n",
      "    2  181   404    53\n",
      "    3   19    87   111\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.76      0.75       744\n",
      "          2       0.62      0.63      0.63       638\n",
      "          3       0.62      0.51      0.56       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.623191567522495\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   154    17\n",
      "    2  181   408    49\n",
      "    3   19    86   112\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.77      0.76       744\n",
      "          2       0.63      0.64      0.63       638\n",
      "          3       0.63      0.52      0.57       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6196692615791841\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   153    15\n",
      "    2  180   409    49\n",
      "    3   19    87   111\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.77      0.76       744\n",
      "          2       0.63      0.64      0.64       638\n",
      "          3       0.63      0.51      0.57       217\n",
      "\n",
      "avg / total       0.68      0.69      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6151109460271793\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   155    13\n",
      "    2  176   416    46\n",
      "    3   21    84   112\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.77      0.76       744\n",
      "          2       0.64      0.65      0.64       638\n",
      "          3       0.65      0.52      0.58       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6110305630392845\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581   150    13\n",
      "    2  175   416    47\n",
      "    3   21    86   110\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.78      0.76       744\n",
      "          2       0.64      0.65      0.64       638\n",
      "          3       0.65      0.51      0.57       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6094933767976688\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  568   163    13\n",
      "    2  176   419    43\n",
      "    3   23    84   110\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.76      0.75       744\n",
      "          2       0.63      0.66      0.64       638\n",
      "          3       0.66      0.51      0.57       217\n",
      "\n",
      "avg / total       0.69      0.69      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6176474967721622\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  583   150    11\n",
      "    2  172   421    45\n",
      "    3   22    86   109\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.78      0.77       744\n",
      "          2       0.64      0.66      0.65       638\n",
      "          3       0.66      0.50      0.57       217\n",
      "\n",
      "avg / total       0.69      0.70      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6048583789091339\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   161    10\n",
      "    2  178   411    49\n",
      "    3   19    88   110\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.77      0.76       744\n",
      "          2       0.62      0.64      0.63       638\n",
      "          3       0.65      0.51      0.57       217\n",
      "\n",
      "avg / total       0.68      0.68      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6084664285082937\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  580   153    11\n",
      "    2  179   412    47\n",
      "    3   19    89   109\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.78      0.76       744\n",
      "          2       0.63      0.65      0.64       638\n",
      "          3       0.65      0.50      0.57       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.606407314553894\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  576   158    10\n",
      "    2  173   415    50\n",
      "    3   20    90   107\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.77      0.76       744\n",
      "          2       0.63      0.65      0.64       638\n",
      "          3       0.64      0.49      0.56       217\n",
      "\n",
      "avg / total       0.69      0.69      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6079523038465643\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  582   156     6\n",
      "    2  179   413    46\n",
      "    3   20    91   106\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.78      0.76       744\n",
      "          2       0.63      0.65      0.64       638\n",
      "          3       0.67      0.49      0.57       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6001875879364265\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  581   155     8\n",
      "    2  176   416    46\n",
      "    3   20    92   105\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.78      0.76       744\n",
      "          2       0.63      0.65      0.64       638\n",
      "          3       0.66      0.48      0.56       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6027869400206114\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  587   151     6\n",
      "    2  175   418    45\n",
      "    3   21    93   103\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.79      0.77       744\n",
      "          2       0.63      0.66      0.64       638\n",
      "          3       0.67      0.47      0.56       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.5980999726097406\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  585   154     5\n",
      "    2  172   420    46\n",
      "    3   25    90   102\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.79      0.77       744\n",
      "          2       0.63      0.66      0.65       638\n",
      "          3       0.67      0.47      0.55       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6033054665165114\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  592   148     4\n",
      "    2  175   420    43\n",
      "    3   24    95    98\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.80      0.77       744\n",
      "          2       0.63      0.66      0.65       638\n",
      "          3       0.68      0.45      0.54       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.5986225589677235\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  595   144     5\n",
      "    2  180   416    42\n",
      "    3   24    97    96\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.80      0.77       744\n",
      "          2       0.63      0.65      0.64       638\n",
      "          3       0.67      0.44      0.53       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6017485465880458\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  584   156     4\n",
      "    2  180   418    40\n",
      "    3   23   100    94\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.78      0.76       744\n",
      "          2       0.62      0.66      0.64       638\n",
      "          3       0.68      0.43      0.53       217\n",
      "\n",
      "avg / total       0.69      0.69      0.68      1599\n",
      "\n",
      "RMSE:\n",
      "0.6043411848180563\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  589   151     4\n",
      "    2  179   419    40\n",
      "    3   23    98    96\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.79      0.77       744\n",
      "          2       0.63      0.66      0.64       638\n",
      "          3       0.69      0.44      0.54       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6001875879364265\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  586   154     4\n",
      "    2  179   420    39\n",
      "    3   26    93    98\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.79      0.76       744\n",
      "          2       0.63      0.66      0.64       638\n",
      "          3       0.70      0.45      0.55       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6048583789091339\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  590   149     5\n",
      "    2  180   422    36\n",
      "    3   24    96    97\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.79      0.77       744\n",
      "          2       0.63      0.66      0.65       638\n",
      "          3       0.70      0.45      0.55       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.6007083581757781\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  586   153     5\n",
      "    2  176   424    38\n",
      "    3   26    97    94\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.79      0.77       744\n",
      "          2       0.63      0.66      0.65       638\n",
      "          3       0.69      0.43      0.53       217\n",
      "\n",
      "avg / total       0.69      0.69      0.69      1599\n",
      "\n",
      "RMSE:\n",
      "0.606407314553894\n"
     ]
    }
   ],
   "source": [
    "run_knnw_report(log_red_norm.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   414    95\n",
      "    2  441  1419   338\n",
      "    3   82   325   653\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.69      0.69      1640\n",
      "          2       0.66      0.65      0.65      2198\n",
      "          3       0.60      0.62      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6741448010182188\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1285   319    36\n",
      "    2  796  1242   160\n",
      "    3  183   503   374\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.78      0.66      1640\n",
      "          2       0.60      0.57      0.58      2198\n",
      "          3       0.66      0.35      0.46      1060\n",
      "\n",
      "avg / total       0.60      0.59      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7361072054292438\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1032   525    83\n",
      "    2  596  1266   336\n",
      "    3  150   396   514\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.63      0.60      1640\n",
      "          2       0.58      0.58      0.58      2198\n",
      "          3       0.55      0.48      0.52      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.754055321802119\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   429    72\n",
      "    2  664  1267   267\n",
      "    3  122   522   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.69      0.64      1640\n",
      "          2       0.57      0.58      0.57      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7366617118773167\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1032   543    65\n",
      "    2  572  1320   306\n",
      "    3  111   467   482\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.63      0.62      1640\n",
      "          2       0.57      0.60      0.58      2198\n",
      "          3       0.57      0.45      0.50      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7274583081089594\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1103   454    83\n",
      "    2  629  1294   275\n",
      "    3   99   528   433\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.67      0.64      1640\n",
      "          2       0.57      0.59      0.58      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7305389923016928\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   557    78\n",
      "    2  525  1349   324\n",
      "    3   82   504   474\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.56      0.61      0.59      2198\n",
      "          3       0.54      0.45      0.49      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7215404780706953\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1053   528    59\n",
      "    2  582  1330   286\n",
      "    3   91   545   424\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7202660458517116\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1006   566    68\n",
      "    2  539  1331   328\n",
      "    3   95   520   445\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.61      0.61      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.42      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7292802853399679\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1045   532    63\n",
      "    2  560  1351   287\n",
      "    3   84   576   400\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.38      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7205494478087149\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   577    58\n",
      "    2  536  1363   299\n",
      "    3   80   555   425\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.54      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7171412326525626\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1051   530    59\n",
      "    2  573  1339   286\n",
      "    3   81   583   396\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7189893546633582\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1019   565    56\n",
      "    2  536  1345   317\n",
      "    3   76   559   425\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.61      0.58      2198\n",
      "          3       0.53      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7151456061924379\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1051   538    51\n",
      "    2  547  1372   279\n",
      "    3   71   573   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.64      0.64      1640\n",
      "          2       0.55      0.62      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7036334563059045\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   571    53\n",
      "    2  525  1390   283\n",
      "    3   69   563   428\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.56      0.40      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7043584780915559\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1039   553    48\n",
      "    2  526  1396   276\n",
      "    3   70   580   410\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.63      1640\n",
      "          2       0.55      0.64      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7010171691604549\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   569    49\n",
      "    2  522  1386   290\n",
      "    3   67   580   413\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7036334563059045\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1039   554    47\n",
      "    2  522  1396   280\n",
      "    3   66   585   409\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.64      1640\n",
      "          2       0.55      0.64      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.6989755088296373\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   575    49\n",
      "    2  514  1389   295\n",
      "    3   61   584   415\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7011627745559728\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1018   577    45\n",
      "    2  521  1386   291\n",
      "    3   64   595   401\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7029076866890369\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   414    95\n",
      "    2  441  1419   338\n",
      "    3   82   325   653\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.69      0.69      1640\n",
      "          2       0.66      0.65      0.65      2198\n",
      "          3       0.60      0.62      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6741448010182188\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   398    92\n",
      "    2  461  1412   325\n",
      "    3   89   330   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.70      0.69      1640\n",
      "          2       0.66      0.64      0.65      2198\n",
      "          3       0.61      0.60      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6759594605620941\n",
      "3 neighbours:\n",
      "3 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   430    92\n",
      "    2  436  1435   327\n",
      "    3   75   334   651\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.68      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.61      0.61      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6694341631675539\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1128   428    84\n",
      "    2  421  1458   319\n",
      "    3   67   347   646\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.69      0.69      1640\n",
      "          2       0.65      0.66      0.66      2198\n",
      "          3       0.62      0.61      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6577427775762\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1132   433    75\n",
      "    2  397  1489   312\n",
      "    3   63   349   648\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.69      0.70      1640\n",
      "          2       0.66      0.68      0.67      2198\n",
      "          3       0.63      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.645839782060122\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1140   425    75\n",
      "    2  373  1515   310\n",
      "    3   60   353   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.70      0.71      1640\n",
      "          2       0.66      0.69      0.67      2198\n",
      "          3       0.63      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6391667196821216\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1137   429    74\n",
      "    2  369  1528   301\n",
      "    3   58   350   652\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.63      0.62      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6353220729537081\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1138   429    73\n",
      "    2  369  1532   297\n",
      "    3   54   357   649\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.64      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6325846441166855\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   427    66\n",
      "    2  371  1526   301\n",
      "    3   52   363   645\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.66      0.69      0.68      2198\n",
      "          3       0.64      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6283749222197228\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   439    62\n",
      "    2  369  1546   283\n",
      "    3   53   365   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.65      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6254439011609174\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1134   444    62\n",
      "    2  375  1545   278\n",
      "    3   50   363   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.66      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6241368069398342\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   436    57\n",
      "    2  364  1558   276\n",
      "    3   53   364   643\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.66      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6195402607973731\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   438    57\n",
      "    2  369  1555   274\n",
      "    3   52   371   637\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.66      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.620857032231425\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1141   444    55\n",
      "    2  356  1576   266\n",
      "    3   49   369   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6147433210335923\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1140   445    55\n",
      "    2  357  1582   259\n",
      "    3   47   370   643\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6127473958915753\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   443    52\n",
      "    2  359  1580   259\n",
      "    3   47   375   638\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6115800981186873\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   444    52\n",
      "    2  365  1570   263\n",
      "    3   46   374   640\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6125807752505908\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   437    51\n",
      "    2  363  1568   267\n",
      "    3   46   375   639\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.69      2198\n",
      "          3       0.67      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6112461750262976\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1159   428    53\n",
      "    2  360  1579   259\n",
      "    3   43   376   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6073928648597745\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   440    53\n",
      "    2  355  1584   259\n",
      "    3   43   377   640\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6087359131880589\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1141   448    51\n",
      "    2  348  1591   259\n",
      "    3   44   375   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.607896855706986\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   445    49\n",
      "    2  353  1588   257\n",
      "    3   43   372   645\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.68      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6053727056112299\n",
      "23 neighbours:\n",
      "23 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   449    49\n",
      "    2  352  1600   246\n",
      "    3   43   370   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.69      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6036840755280375\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   440    50\n",
      "    2  347  1600   251\n",
      "    3   42   376   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.68      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6031765646560429\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   445    49\n",
      "    2  338  1611   249\n",
      "    3   42   370   648\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.70      2198\n",
      "          3       0.68      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6004625955924267\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   447    49\n",
      "    2  339  1616   243\n",
      "    3   41   374   645\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.69      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5999523596167601\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   443    53\n",
      "    2  339  1621   238\n",
      "    3   41   375   644\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.69      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6013120267648518\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   441    50\n",
      "    2  339  1626   233\n",
      "    3   41   377   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.73      1640\n",
      "          2       0.67      0.74      0.70      2198\n",
      "          3       0.69      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5984190414100229\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   448    47\n",
      "    2  341  1627   230\n",
      "    3   41   378   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.60      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5975654979126814\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   443    47\n",
      "    2  341  1625   232\n",
      "    3   38   380   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.73      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5953405577875872\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(f_mm_white.values,white_targetclass)\n",
    "run_knnw_report(f_mm_white.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   414    95\n",
      "    2  441  1419   338\n",
      "    3   82   325   653\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.69      0.69      1640\n",
      "          2       0.66      0.65      0.65      2198\n",
      "          3       0.60      0.62      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6741448010182188\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1285   319    36\n",
      "    2  796  1242   160\n",
      "    3  183   503   374\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.78      0.66      1640\n",
      "          2       0.60      0.57      0.58      2198\n",
      "          3       0.66      0.35      0.46      1060\n",
      "\n",
      "avg / total       0.60      0.59      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7361072054292438\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1032   525    83\n",
      "    2  596  1266   336\n",
      "    3  150   396   514\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.58      0.63      0.60      1640\n",
      "          2       0.58      0.58      0.58      2198\n",
      "          3       0.55      0.48      0.52      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.754055321802119\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   429    72\n",
      "    2  664  1267   267\n",
      "    3  122   522   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.69      0.64      1640\n",
      "          2       0.57      0.58      0.57      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7366617118773167\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1032   543    65\n",
      "    2  572  1320   306\n",
      "    3  111   467   482\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.63      0.62      1640\n",
      "          2       0.57      0.60      0.58      2198\n",
      "          3       0.57      0.45      0.50      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7274583081089594\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1103   454    83\n",
      "    2  629  1294   275\n",
      "    3   99   528   433\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.67      0.64      1640\n",
      "          2       0.57      0.59      0.58      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7305389923016928\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   557    78\n",
      "    2  525  1349   324\n",
      "    3   82   504   474\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.56      0.61      0.59      2198\n",
      "          3       0.54      0.45      0.49      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7215404780706953\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1053   528    59\n",
      "    2  582  1330   286\n",
      "    3   91   545   424\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7202660458517116\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1006   566    68\n",
      "    2  539  1331   328\n",
      "    3   95   520   445\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.61      0.61      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.42      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7292802853399679\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1045   532    63\n",
      "    2  560  1351   287\n",
      "    3   84   576   400\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.38      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7205494478087149\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   577    58\n",
      "    2  536  1363   299\n",
      "    3   80   555   425\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.54      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7171412326525626\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1051   530    59\n",
      "    2  573  1339   286\n",
      "    3   81   583   396\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.64      0.63      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.53      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7189893546633582\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1019   565    56\n",
      "    2  536  1345   317\n",
      "    3   76   559   425\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.61      0.58      2198\n",
      "          3       0.53      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7151456061924379\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1051   538    51\n",
      "    2  547  1372   279\n",
      "    3   71   573   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.64      0.64      1640\n",
      "          2       0.55      0.62      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7036334563059045\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   571    53\n",
      "    2  525  1390   283\n",
      "    3   69   563   428\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.56      0.40      0.47      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7043584780915559\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1039   553    48\n",
      "    2  526  1396   276\n",
      "    3   70   580   410\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.63      1640\n",
      "          2       0.55      0.64      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.7010171691604549\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   569    49\n",
      "    2  522  1386   290\n",
      "    3   67   580   413\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.63      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7036334563059045\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1039   554    47\n",
      "    2  522  1396   280\n",
      "    3   66   585   409\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.63      0.64      1640\n",
      "          2       0.55      0.64      0.59      2198\n",
      "          3       0.56      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.58      4898\n",
      "\n",
      "RMSE:\n",
      "0.6989755088296373\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   575    49\n",
      "    2  514  1389   295\n",
      "    3   61   584   415\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.55      0.63      0.59      2198\n",
      "          3       0.55      0.39      0.46      1060\n",
      "\n",
      "avg / total       0.58      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7011627745559728\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1018   577    45\n",
      "    2  521  1386   291\n",
      "    3   64   595   401\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.64      0.62      0.63      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7029076866890369\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1131   414    95\n",
      "    2  441  1419   338\n",
      "    3   82   325   653\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.69      0.69      1640\n",
      "          2       0.66      0.65      0.65      2198\n",
      "          3       0.60      0.62      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6741448010182188\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   398    92\n",
      "    2  461  1412   325\n",
      "    3   89   330   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.70      0.69      1640\n",
      "          2       0.66      0.64      0.65      2198\n",
      "          3       0.61      0.60      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6759594605620941\n",
      "3 neighbours:\n",
      "3 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1118   430    92\n",
      "    2  436  1435   327\n",
      "    3   75   334   651\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.68      1640\n",
      "          2       0.65      0.65      0.65      2198\n",
      "          3       0.61      0.61      0.61      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6694341631675539\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1128   428    84\n",
      "    2  421  1458   319\n",
      "    3   67   347   646\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.69      0.69      1640\n",
      "          2       0.65      0.66      0.66      2198\n",
      "          3       0.62      0.61      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6577427775762\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1132   433    75\n",
      "    2  397  1489   312\n",
      "    3   63   349   648\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.69      0.70      1640\n",
      "          2       0.66      0.68      0.67      2198\n",
      "          3       0.63      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.645839782060122\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1140   425    75\n",
      "    2  373  1515   310\n",
      "    3   60   353   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.70      0.71      1640\n",
      "          2       0.66      0.69      0.67      2198\n",
      "          3       0.63      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6391667196821216\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1137   429    74\n",
      "    2  369  1528   301\n",
      "    3   58   350   652\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.63      0.62      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6353220729537081\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1138   429    73\n",
      "    2  369  1532   297\n",
      "    3   54   357   649\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.64      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6325846441166855\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   427    66\n",
      "    2  371  1526   301\n",
      "    3   52   363   645\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.66      0.69      0.68      2198\n",
      "          3       0.64      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6283749222197228\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1139   439    62\n",
      "    2  369  1546   283\n",
      "    3   53   365   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.65      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6254439011609174\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1134   444    62\n",
      "    2  375  1545   278\n",
      "    3   50   363   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.66      0.70      0.68      2198\n",
      "          3       0.66      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6241368069398342\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   436    57\n",
      "    2  364  1558   276\n",
      "    3   53   364   643\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.66      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6195402607973731\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   438    57\n",
      "    2  369  1555   274\n",
      "    3   52   371   637\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.70      0.71      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.66      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.620857032231425\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1141   444    55\n",
      "    2  356  1576   266\n",
      "    3   49   369   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.61      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6147433210335923\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1140   445    55\n",
      "    2  357  1582   259\n",
      "    3   47   370   643\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6127473958915753\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   443    52\n",
      "    2  359  1580   259\n",
      "    3   47   375   638\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6115800981186873\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   444    52\n",
      "    2  365  1570   263\n",
      "    3   46   374   640\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.68      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6125807752505908\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1152   437    51\n",
      "    2  363  1568   267\n",
      "    3   46   375   639\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.71      0.69      2198\n",
      "          3       0.67      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6112461750262976\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1159   428    53\n",
      "    2  360  1579   259\n",
      "    3   43   376   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.71      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6073928648597745\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   440    53\n",
      "    2  355  1584   259\n",
      "    3   43   377   640\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6087359131880589\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1141   448    51\n",
      "    2  348  1591   259\n",
      "    3   44   375   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.67      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.607896855706986\n",
      "22 neighbours:\n",
      "22 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   445    49\n",
      "    2  353  1588   257\n",
      "    3   43   372   645\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.68      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6053727056112299\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1142   449    49\n",
      "    2  352  1600   246\n",
      "    3   43   370   647\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.69      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6036840755280375\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   440    50\n",
      "    2  347  1600   251\n",
      "    3   42   376   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.68      0.61      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6031765646560429\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1146   445    49\n",
      "    2  338  1611   249\n",
      "    3   42   370   648\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.70      2198\n",
      "          3       0.68      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6004625955924267\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   447    49\n",
      "    2  339  1616   243\n",
      "    3   41   374   645\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.69      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5999523596167601\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1144   443    53\n",
      "    2  339  1621   238\n",
      "    3   41   375   644\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.69      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.6013120267648518\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   441    50\n",
      "    2  339  1626   233\n",
      "    3   41   377   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.73      1640\n",
      "          2       0.67      0.74      0.70      2198\n",
      "          3       0.69      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5984190414100229\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1145   448    47\n",
      "    2  341  1627   230\n",
      "    3   41   378   641\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.72      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.60      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5975654979126814\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   443    47\n",
      "    2  341  1625   232\n",
      "    3   38   380   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.73      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.61      0.65      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5953405577875872\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(f_mm_white.values,white_targetclass)\n",
    "run_knnw_report(f_mm_white.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1090   455    95\n",
      "    2  459  1372   367\n",
      "    3  102   330   628\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.66      0.66      1640\n",
      "          2       0.64      0.62      0.63      2198\n",
      "          3       0.58      0.59      0.58      1060\n",
      "\n",
      "avg / total       0.63      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.6998512354317896\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1278   325    37\n",
      "    2  807  1229   162\n",
      "    3  203   507   350\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.56      0.78      0.65      1640\n",
      "          2       0.60      0.56      0.58      2198\n",
      "          3       0.64      0.33      0.44      1060\n",
      "\n",
      "avg / total       0.59      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.750799220278691\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1013   532    95\n",
      "    2  599  1254   345\n",
      "    3  155   412   493\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.57      0.62      0.59      1640\n",
      "          2       0.57      0.57      0.57      2198\n",
      "          3       0.53      0.47      0.49      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7678726585594571\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   423    91\n",
      "    2  656  1273   269\n",
      "    3  111   533   416\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.69      0.64      1640\n",
      "          2       0.57      0.58      0.58      2198\n",
      "          3       0.54      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7409450665670629\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  994   560    86\n",
      "    2  564  1353   281\n",
      "    3  105   485   470\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.61      0.60      1640\n",
      "          2       0.56      0.62      0.59      2198\n",
      "          3       0.56      0.44      0.50      1060\n",
      "\n",
      "avg / total       0.57      0.58      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7361072054292438\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1062   490    88\n",
      "    2  642  1285   271\n",
      "    3  108   519   433\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.59      0.65      0.62      1640\n",
      "          2       0.56      0.58      0.57      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7432835233476071\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  974   585    81\n",
      "    2  560  1325   313\n",
      "    3   86   511   463\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.59      0.60      1640\n",
      "          2       0.55      0.60      0.57      2198\n",
      "          3       0.54      0.44      0.48      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7337458779951597\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1035   537    68\n",
      "    2  620  1309   269\n",
      "    3   82   553   425\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.60      0.63      0.61      1640\n",
      "          2       0.55      0.60      0.57      2198\n",
      "          3       0.56      0.40      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7256317561187315\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  983   586    71\n",
      "    2  549  1355   294\n",
      "    3   87   525   448\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.60      0.60      1640\n",
      "          2       0.55      0.62      0.58      2198\n",
      "          3       0.55      0.42      0.48      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7266158546611806\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1026   545    69\n",
      "    2  577  1341   280\n",
      "    3   76   563   421\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.63      0.62      1640\n",
      "          2       0.55      0.61      0.58      2198\n",
      "          3       0.55      0.40      0.46      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.7208327383436658\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  982   594    64\n",
      "    2  530  1378   290\n",
      "    3   77   548   435\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.60      0.61      1640\n",
      "          2       0.55      0.63      0.58      2198\n",
      "          3       0.55      0.41      0.47      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.718136966272786\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1023   556    61\n",
      "    2  574  1344   280\n",
      "    3   77   572   411\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.62      0.62      1640\n",
      "          2       0.54      0.61      0.58      2198\n",
      "          3       0.55      0.39      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.719273259651585\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  991   594    55\n",
      "    2  532  1380   286\n",
      "    3   71   582   407\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.60      0.61      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.54      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7141457017299102\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1029   561    50\n",
      "    2  572  1354   272\n",
      "    3   70   607   383\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.63      0.62      1640\n",
      "          2       0.54      0.62      0.57      2198\n",
      "          3       0.54      0.36      0.43      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7132875251310331\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1005   581    54\n",
      "    2  535  1385   278\n",
      "    3   71   589   400\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.62      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.38      0.45      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.57      4898\n",
      "\n",
      "RMSE:\n",
      "0.71199832079853\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1017   570    53\n",
      "    2  565  1359   274\n",
      "    3   61   604   395\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.54      0.62      0.57      2198\n",
      "          3       0.55      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7099882388503623\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1001   592    47\n",
      "    2  550  1376   272\n",
      "    3   66   601   393\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.61      0.61      1640\n",
      "          2       0.54      0.63      0.58      2198\n",
      "          3       0.55      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7097006195398559\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1022   574    44\n",
      "    2  575  1360   263\n",
      "    3   63   615   382\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.62      0.62      1640\n",
      "          2       0.53      0.62      0.57      2198\n",
      "          3       0.55      0.36      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7079724498818805\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  988   609    43\n",
      "    2  537  1397   264\n",
      "    3   65   604   391\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.62      0.60      0.61      1640\n",
      "          2       0.54      0.64      0.58      2198\n",
      "          3       0.56      0.37      0.44      1060\n",
      "\n",
      "avg / total       0.57      0.57      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7066735491753771\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1016   582    42\n",
      "    2  570  1366   262\n",
      "    3   68   619   373\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.61      0.62      0.62      1640\n",
      "          2       0.53      0.62      0.57      2198\n",
      "          3       0.55      0.35      0.43      1060\n",
      "\n",
      "avg / total       0.56      0.56      0.56      4898\n",
      "\n",
      "RMSE:\n",
      "0.7105631282067815\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1090   455    95\n",
      "    2  459  1372   367\n",
      "    3  102   330   628\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.66      0.66      1640\n",
      "          2       0.64      0.62      0.63      2198\n",
      "          3       0.58      0.59      0.58      1060\n",
      "\n",
      "avg / total       0.63      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.6998512354317896\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1103   444    93\n",
      "    2  474  1370   354\n",
      "    3  104   333   623\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.66      0.67      0.66      1640\n",
      "          2       0.64      0.62      0.63      2198\n",
      "          3       0.58      0.59      0.58      1060\n",
      "\n",
      "avg / total       0.63      0.63      0.63      4898\n",
      "\n",
      "RMSE:\n",
      "0.6989755088296373\n",
      "3 neighbours:\n",
      "3 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1101   445    94\n",
      "    2  447  1418   333\n",
      "    3   82   357   621\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.67      0.67      1640\n",
      "          2       0.64      0.65      0.64      2198\n",
      "          3       0.59      0.59      0.59      1060\n",
      "\n",
      "avg / total       0.64      0.64      0.64      4898\n",
      "\n",
      "RMSE:\n",
      "0.6831698988226949\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1115   447    78\n",
      "    2  432  1431   335\n",
      "    3   75   359   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.69      0.68      0.68      1640\n",
      "          2       0.64      0.65      0.65      2198\n",
      "          3       0.60      0.59      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6679075154262929\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1105   457    78\n",
      "    2  413  1470   315\n",
      "    3   70   361   629\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.67      0.68      1640\n",
      "          2       0.64      0.67      0.66      2198\n",
      "          3       0.62      0.59      0.60      1060\n",
      "\n",
      "avg / total       0.65      0.65      0.65      4898\n",
      "\n",
      "RMSE:\n",
      "0.6606850201073139\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1112   457    71\n",
      "    2  395  1492   311\n",
      "    3   65   360   635\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.68      0.69      1640\n",
      "          2       0.65      0.68      0.66      2198\n",
      "          3       0.62      0.60      0.61      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6496221850110053\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1114   457    69\n",
      "    2  398  1497   303\n",
      "    3   59   359   642\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.68      0.69      1640\n",
      "          2       0.65      0.68      0.66      2198\n",
      "          3       0.63      0.61      0.62      1060\n",
      "\n",
      "avg / total       0.66      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6436231153224521\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1117   459    64\n",
      "    2  384  1510   304\n",
      "    3   54   376   630\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.68      0.70      1640\n",
      "          2       0.64      0.69      0.66      2198\n",
      "          3       0.63      0.59      0.61      1060\n",
      "\n",
      "avg / total       0.67      0.66      0.66      4898\n",
      "\n",
      "RMSE:\n",
      "0.6382077293150342\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1128   445    67\n",
      "    2  390  1530   278\n",
      "    3   52   382   626\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.69      0.70      1640\n",
      "          2       0.65      0.70      0.67      2198\n",
      "          3       0.64      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.67      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.634357270463928\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1126   448    66\n",
      "    2  375  1547   276\n",
      "    3   45   388   627\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.65      0.70      0.68      2198\n",
      "          3       0.65      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.67      0.67      4898\n",
      "\n",
      "RMSE:\n",
      "0.6278873688638488\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1124   459    57\n",
      "    2  354  1568   276\n",
      "    3   43   387   630\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.65      0.71      0.68      2198\n",
      "          3       0.65      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.618880824462763\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1133   448    59\n",
      "    2  363  1559   276\n",
      "    3   45   381   634\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.65      0.71      0.68      2198\n",
      "          3       0.65      0.60      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6201989959763277\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1136   449    55\n",
      "    2  361  1565   272\n",
      "    3   44   383   633\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.65      0.71      0.68      2198\n",
      "          3       0.66      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6164016550986295\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1134   449    57\n",
      "    2  362  1574   262\n",
      "    3   44   387   629\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.65      0.72      0.68      2198\n",
      "          3       0.66      0.59      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6168982860279365\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1133   450    57\n",
      "    2  361  1572   265\n",
      "    3   39   394   627\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.69      0.71      1640\n",
      "          2       0.65      0.72      0.68      2198\n",
      "          3       0.66      0.59      0.62      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6152412905936062\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1134   456    50\n",
      "    2  369  1573   256\n",
      "    3   41   387   632\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.69      0.71      1640\n",
      "          2       0.65      0.72      0.68      2198\n",
      "          3       0.67      0.60      0.63      1060\n",
      "\n",
      "avg / total       0.68      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6115800981186873\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1140   453    47\n",
      "    2  370  1576   252\n",
      "    3   38   385   637\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.65      0.72      0.68      2198\n",
      "          3       0.68      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.68      0.68      4898\n",
      "\n",
      "RMSE:\n",
      "0.6062152567574661\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1147   448    45\n",
      "    2  365  1587   246\n",
      "    3   39   382   639\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.69      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6023297629403728\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   447    43\n",
      "    2  361  1591   246\n",
      "    3   40   384   636\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.72      0.69      2198\n",
      "          3       0.69      0.60      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6011422365520177\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1150   445    45\n",
      "    2  360  1597   241\n",
      "    3   40   390   630\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.69      0.59      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6021602596971288\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1148   450    42\n",
      "    2  358  1601   239\n",
      "    3   40   390   630\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.69      0.59      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.6002925651216265\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   450    41\n",
      "    2  356  1609   233\n",
      "    3   39   397   624\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.66      0.73      0.69      2198\n",
      "          3       0.69      0.59      0.64      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5987601181213346\n",
      "23 neighbours:\n",
      "23 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1149   451    40\n",
      "    2  353  1617   228\n",
      "    3   41   402   617\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.74      0.70      0.72      1640\n",
      "          2       0.65      0.74      0.69      2198\n",
      "          3       0.70      0.58      0.63      1060\n",
      "\n",
      "avg / total       0.69      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5991010006528603\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1156   446    38\n",
      "    2  345  1623   230\n",
      "    3   41   407   612\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.70      0.73      1640\n",
      "          2       0.66      0.74      0.69      2198\n",
      "          3       0.70      0.58      0.63      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5967107334958632\n",
      "25 neighbours:\n",
      "25 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1161   443    36\n",
      "    2  343  1633   222\n",
      "    3   37   409   614\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.70      0.58      0.64      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5906927506614185\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1161   445    34\n",
      "    2  349  1627   222\n",
      "    3   37   411   612\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.71      0.58      0.63      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5910382860818211\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1164   441    35\n",
      "    2  347  1631   220\n",
      "    3   34   411   615\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.71      0.58      0.64      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5882683198761134\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   443    35\n",
      "    2  348  1631   219\n",
      "    3   34   410   616\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.66      0.74      0.70      2198\n",
      "          3       0.71      0.58      0.64      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.70      4898\n",
      "\n",
      "RMSE:\n",
      "0.5884418247670344\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1162   445    33\n",
      "    2  352  1633   213\n",
      "    3   33   417   610\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.65      0.74      0.70      2198\n",
      "          3       0.71      0.58      0.64      1060\n",
      "\n",
      "avg / total       0.70      0.70      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5875737879693897\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1 1163   442    35\n",
      "    2  355  1626   217\n",
      "    3   33   417   610\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.75      0.71      0.73      1640\n",
      "          2       0.65      0.74      0.69      2198\n",
      "          3       0.71      0.58      0.63      1060\n",
      "\n",
      "avg / total       0.70      0.69      0.69      4898\n",
      "\n",
      "RMSE:\n",
      "0.5896549295072508\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(f_log_white.values,white_targetclass)\n",
    "run_knnw_report(f_log_white.values,white_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_______________________________________________________________________________________________\n",
      "KNN, no weights\n",
      "1 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   152    15\n",
      "    2  139   420    79\n",
      "    3   16    68   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.59      0.61      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5928487737550271\n",
      "2 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  641    99     4\n",
      "    2  268   334    36\n",
      "    3   37   122    58\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.68      0.86      0.76       744\n",
      "          2       0.60      0.52      0.56       638\n",
      "          3       0.59      0.27      0.37       217\n",
      "\n",
      "avg / total       0.64      0.65      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6564254024206326\n",
      "3 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  560   170    14\n",
      "    2  192   362    84\n",
      "    3   39    89    89\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.75      0.73       744\n",
      "          2       0.58      0.57      0.58       638\n",
      "          3       0.48      0.41      0.44       217\n",
      "\n",
      "avg / total       0.63      0.63      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6834961443652051\n",
      "4 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  607   118    19\n",
      "    2  220   365    53\n",
      "    3   29   113    75\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.82      0.76       744\n",
      "          2       0.61      0.57      0.59       638\n",
      "          3       0.51      0.35      0.41       217\n",
      "\n",
      "avg / total       0.64      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6597515024826716\n",
      "5 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  565   169    10\n",
      "    2  184   390    64\n",
      "    3   27   107    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.73      0.76      0.74       744\n",
      "          2       0.59      0.61      0.60       638\n",
      "          3       0.53      0.38      0.44       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6482766879698075\n",
      "6 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  598   136    10\n",
      "    2  227   357    54\n",
      "    3   30   114    73\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.70      0.80      0.75       744\n",
      "          2       0.59      0.56      0.57       638\n",
      "          3       0.53      0.34      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6573774339614009\n",
      "7 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566   168    10\n",
      "    2  194   379    65\n",
      "    3   24   109    84\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.58      0.59      0.59       638\n",
      "          3       0.53      0.39      0.45       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6482766879698075\n",
      "8 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  596   142     6\n",
      "    2  223   361    54\n",
      "    3   21   124    72\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.58      0.57      0.57       638\n",
      "          3       0.55      0.33      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6380669682015703\n",
      "9 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  564   170    10\n",
      "    2  204   378    56\n",
      "    3   25   113    79\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.76      0.73       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.54      0.36      0.44       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6535609869991703\n",
      "10 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  590   149     5\n",
      "    2  219   363    56\n",
      "    3   20   129    68\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.53      0.31      0.39       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6390463501566458\n",
      "11 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   162     5\n",
      "    2  209   371    58\n",
      "    3   24   112    81\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.78      0.74       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.56      0.37      0.45       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6410006249027402\n",
      "12 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  592   145     7\n",
      "    2  220   361    57\n",
      "    3   21   124    72\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.80      0.75       744\n",
      "          2       0.57      0.57      0.57       638\n",
      "          3       0.53      0.33      0.41       217\n",
      "\n",
      "avg / total       0.63      0.64      0.63      1599\n",
      "\n",
      "RMSE:\n",
      "0.6414882633337861\n",
      "13 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  574   163     7\n",
      "    2  208   374    56\n",
      "    3   20   115    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.77      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.57      0.38      0.45       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6375767130633383\n",
      "14 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  588   150     6\n",
      "    2  217   370    51\n",
      "    3   20   120    77\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.79      0.75       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.57      0.35      0.44       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6336410167329005\n",
      "15 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  571   168     5\n",
      "    2  200   387    51\n",
      "    3   21   114    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.77      0.74       744\n",
      "          2       0.58      0.61      0.59       638\n",
      "          3       0.59      0.38      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6311687442672026\n",
      "16 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  591   149     4\n",
      "    2  214   371    53\n",
      "    3   19   115    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.79      0.75       744\n",
      "          2       0.58      0.58      0.58       638\n",
      "          3       0.59      0.38      0.46       217\n",
      "\n",
      "avg / total       0.65      0.65      0.65      1599\n",
      "\n",
      "RMSE:\n",
      "0.6241942899207995\n",
      "17 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  567   174     3\n",
      "    2  202   385    51\n",
      "    3   19   115    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.57      0.60      0.59       638\n",
      "          3       0.61      0.38      0.47       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6276912040603917\n",
      "18 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  575   165     4\n",
      "    2  210   377    51\n",
      "    3   20   115    82\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.57      0.59      0.58       638\n",
      "          3       0.60      0.38      0.46       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6311687442672026\n",
      "19 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  566   174     4\n",
      "    2  202   385    51\n",
      "    3   20   114    83\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.72      0.76      0.74       744\n",
      "          2       0.57      0.60      0.59       638\n",
      "          3       0.60      0.38      0.47       217\n",
      "\n",
      "avg / total       0.64      0.65      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6311687442672026\n",
      "20 neighbours:\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  573   167     4\n",
      "    2  219   369    50\n",
      "    3   20   112    85\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.71      0.77      0.74       744\n",
      "          2       0.57      0.58      0.57       638\n",
      "          3       0.61      0.39      0.48       217\n",
      "\n",
      "avg / total       0.64      0.64      0.64      1599\n",
      "\n",
      "RMSE:\n",
      "0.6346272290288927\n",
      "_______________________________________________________________________________________________\n",
      "KNN with inverse distance as weight:\n",
      "1 neighbours:\n",
      "1 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   152    15\n",
      "    2  139   420    79\n",
      "    3   16    68   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.59      0.61      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5928487737550271\n",
      "2 neighbours:\n",
      "2 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  577   152    15\n",
      "    2  140   419    79\n",
      "    3   16    68   133\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.78       744\n",
      "          2       0.66      0.66      0.66       638\n",
      "          3       0.59      0.61      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5933759848629978\n",
      "3 neighbours:\n",
      "3 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  583   148    13\n",
      "    2  133   427    78\n",
      "    3   17    69   131\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.78      0.79       744\n",
      "          2       0.66      0.67      0.67       638\n",
      "          3       0.59      0.60      0.60       217\n",
      "\n",
      "avg / total       0.71      0.71      0.71      1599\n",
      "\n",
      "RMSE:\n",
      "0.5854179672445431\n",
      "4 neighbours:\n",
      "4 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  584   146    14\n",
      "    2  132   433    73\n",
      "    3   19    71   127\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.78      0.79       744\n",
      "          2       0.67      0.68      0.67       638\n",
      "          3       0.59      0.59      0.59       217\n",
      "\n",
      "avg / total       0.72      0.72      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5886140854486008\n",
      "5 neighbours:\n",
      "5 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  597   136    11\n",
      "    2  132   441    65\n",
      "    3   17    76   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.80      0.80       744\n",
      "          2       0.68      0.69      0.68       638\n",
      "          3       0.62      0.57      0.59       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5708140177867163\n",
      "6 neighbours:\n",
      "6 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  600   133    11\n",
      "    2  127   448    63\n",
      "    3   18    78   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.62      0.56      0.59       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5686185711218377\n",
      "7 neighbours:\n",
      "7 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   135    10\n",
      "    2  138   441    59\n",
      "    3   19    78   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.81      0.80       744\n",
      "          2       0.67      0.69      0.68       638\n",
      "          3       0.63      0.55      0.59       217\n",
      "\n",
      "avg / total       0.72      0.73      0.72      1599\n",
      "\n",
      "RMSE:\n",
      "0.5735465083568029\n",
      "8 neighbours:\n",
      "8 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  599   135    10\n",
      "    2  134   446    58\n",
      "    3   12    79   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.65      0.58      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5558264921995841\n",
      "9 neighbours:\n",
      "9 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  602   133     9\n",
      "    2  141   445    52\n",
      "    3   13    83   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.66      0.56      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5575116698677923\n",
      "10 neighbours:\n",
      "10 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   126    10\n",
      "    2  137   446    55\n",
      "    3   14    81   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.65      0.56      0.60       217\n",
      "\n",
      "avg / total       0.73      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5563887852034651\n",
      "11 neighbours:\n",
      "11 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   125     9\n",
      "    2  144   443    51\n",
      "    3   14    81   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.69      0.69       638\n",
      "          3       0.67      0.56      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5552636297846285\n",
      "12 neighbours:\n",
      "12 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   130     8\n",
      "    2  139   446    53\n",
      "    3   14    86   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.66      0.54      0.59       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5569505105208908\n",
      "13 neighbours:\n",
      "13 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  607   129     8\n",
      "    2  139   445    54\n",
      "    3   15    82   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.66      0.55      0.60       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5569505105208908\n",
      "14 neighbours:\n",
      "14 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   131     7\n",
      "    2  132   455    51\n",
      "    3   13    81   123\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.81      0.81       744\n",
      "          2       0.68      0.71      0.70       638\n",
      "          3       0.68      0.57      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "15 neighbours:\n",
      "15 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   129     6\n",
      "    2  133   455    50\n",
      "    3   13    78   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.81      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.69      0.58      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5398445564147902\n",
      "16 neighbours:\n",
      "16 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  611   129     4\n",
      "    2  136   454    48\n",
      "    3   13    82   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.71      0.70       638\n",
      "          3       0.70      0.56      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5381040535833211\n",
      "17 neighbours:\n",
      "17 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  613   128     3\n",
      "    2  138   451    49\n",
      "    3   13    78   126\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.69      0.71      0.70       638\n",
      "          3       0.71      0.58      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5346060486629776\n",
      "18 neighbours:\n",
      "18 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  606   136     2\n",
      "    2  142   448    48\n",
      "    3   12    83   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.67      0.70      0.69       638\n",
      "          3       0.71      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5392650129772822\n",
      "19 neighbours:\n",
      "19 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   137     2\n",
      "    2  139   453    46\n",
      "    3   14    79   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.72      0.57      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5392650129772822\n",
      "20 neighbours:\n",
      "20 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  604   138     2\n",
      "    2  139   450    49\n",
      "    3   14    79   124\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.71      0.57      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5415794657283098\n",
      "21 neighbours:\n",
      "21 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  605   137     2\n",
      "    2  139   451    48\n",
      "    3   14    78   125\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.81      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.71      0.58      0.64       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5398445564147902\n",
      "22 neighbours:\n",
      "22 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   132     2\n",
      "    2  141   449    48\n",
      "    3   15    80   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.71      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5415794657283098\n",
      "23 neighbours:\n",
      "23 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  611   130     3\n",
      "    2  141   450    47\n",
      "    3   15    81   121\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.71      0.56      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5427329909238503\n",
      "24 neighbours:\n",
      "24 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   130     2\n",
      "    2  143   448    47\n",
      "    3   15    80   122\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.71      0.56      0.63       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5410017808004594\n",
      "25 neighbours:\n",
      "25 neighbours//\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  612   129     3\n",
      "    2  142   448    48\n",
      "    3   13    86   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.70      0.54      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5415794657283098\n",
      "26 neighbours:\n",
      "26 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  610   130     4\n",
      "    2  145   445    48\n",
      "    3   13    84   120\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.70      0.55      0.62       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "27 neighbours:\n",
      "27 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   131     4\n",
      "    2  139   454    45\n",
      "    3   11    88   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.80      0.82      0.81       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.71      0.54      0.61       217\n",
      "\n",
      "avg / total       0.74      0.74      0.74      1599\n",
      "\n",
      "RMSE:\n",
      "0.5381040535833211\n",
      "28 neighbours:\n",
      "28 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   132     4\n",
      "    2  143   452    43\n",
      "    3   14    85   118\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.71      0.69       638\n",
      "          3       0.72      0.54      0.62       217\n",
      "\n",
      "avg / total       0.74      0.74      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5450327172879821\n",
      "29 neighbours:\n",
      "29 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  609   130     5\n",
      "    2  145   449    44\n",
      "    3   14    86   117\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.81       744\n",
      "          2       0.68      0.70      0.69       638\n",
      "          3       0.70      0.54      0.61       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5484642268462742\n",
      "30 neighbours:\n",
      "30 neighbours//\n",
      "      __Prediction___\n",
      "         1     2     3\n",
      "    1  608   131     5\n",
      "    2  144   450    44\n",
      "    3   16    87   114\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.79      0.82      0.80       744\n",
      "          2       0.67      0.71      0.69       638\n",
      "          3       0.70      0.53      0.60       217\n",
      "\n",
      "avg / total       0.73      0.73      0.73      1599\n",
      "\n",
      "RMSE:\n",
      "0.5535716086954976\n"
     ]
    }
   ],
   "source": [
    "run_knn_report(f_mm_red.values,red_targetclass)\n",
    "run_knnw_report(f_mm_red.values,red_targetclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
